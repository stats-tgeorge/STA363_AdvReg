[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Advanced Regression",
    "section": "",
    "text": "Instructor Dr.¬†Tyler George\n ¬† Cornell College, West 311\n ¬†  tgeorge@cornellcollege.edu \n\n\n\n\nAugust 28th - September 18th\n ¬† M-F,9am-11am and 1pm-3pm\n ¬† West 201\n ¬† Course Calendar\n\n\n\n\n ¬† MWTh 3:05pm-4:05pm and by appt.\n ¬† West 311\n ¬† Optional Appointment\nI am available far beyond these times listed. Please email me and we can set up a time to chat about class material or whatever you prefer! I will generally announce changes to office hours in class but I still suggest checking the Course Calendar to verify availability.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#ai-policy",
    "href": "syllabus.html#ai-policy",
    "title": "Advanced Regression",
    "section": "AI Policy",
    "text": "AI Policy\nThe beta release of Dall-E-Mini in July 2022 and ChatGPT in November 2022 are among many tools using artificial intelligence. There is a good possibility that using tools like these are going to become an important skill for careers in the not distant future (https://www.theguardian.com/commentisfree/2023/jan/07/chatgpt-bot-excel-ai-chatbot-tech).\nIn the meantime though, it‚Äôs going to take a while for society to figure out when using these tools is/isn‚Äôt acceptable.\nWork created by AI tools may not be considered original work and, instead, considered automated plagiarism. It is derived from previously created texts from other sources that the models were trained on, yet doesn‚Äôt cite sources. AI models have built-in biases (ie, they are trained on limited underlying sources; they reproduce, rather than challenge, errors in the sources) AI tools have limitations (ie, they lack critical thinking to evaluate and reflect on criteria; they lack abductive reasoning to make judgments with incomplete information at hand; they make up or use inaccurate information and may ‚Äúhallucinate‚Äù sources that do not exist)\nIn this course, all informal writing should be written without the use of AI. The purpose of informal writing is to help you think through your ideas, connect with your lived experiences, and to figure out your thoughts and opinions. Using AI here subverts that process.\nA final note: Other courses may have different AI policies, and it is important to be aware of the policy in each class.\n\nDISABILITIES AND ACCOMODATIONS POLICY\nCornell College makes reasonable accommodations for persons with disabilities. Students should notify the Office of Academic Support and Advising and their course instructor of any disability related accommodations within the first three days of the term for which the accommodations are required, due to the fast pace of the block format. For more information on the documentation required to establish the need for accommodations and the process of requesting the accommodations.\n\n\nACADEMIC HONESTY POLICY\nCornell College expects all members of the Cornell community to act with academic integrity. An important aspect of academic integrity is respecting the work of others. A student is expected to explicitly acknowledge ideas, claims, observations, or data of others, unless generally known. When a piece of work is submitted for credit, a student is asserting that the submission is her or his work unless there is a citation of a specific source. If there is no appropriate acknowledgment of sources, whether intended or not, this may constitute a violation of the College‚Äôs requirement for honesty in academic work and may be treated as a case of academic dishonesty. The procedures regarding how the College deals with cases of academic dishonesty appear in The Catalog, under the heading ‚ÄúAcademic Honesty.‚Äù\n\n\nIllness Policy\nIf you are experiencing COVID-19 symptoms, do not attend class. Perform a home test or contact Director of Student Health Services Lynn O‚ÄôBrien at student_health@cornellcollege.edu immediately to arrange a COVID-19 test at the Health Center. If you need to isolate due to COVID-19, or if you become unable to attend class for any other health reason, contact me as soon as possible to determine if you are able to continue in the class. A Withdrawal for Health Reasons may be required.\n\n\nMandatory Reporter Reminder\nIt is my goal that you feel supported and able to share information related to your life experiences during classroom discussions, in your written work, and in any one-on-one meetings with me. You should also know that all Cornell College faculty and staff are mandatory reporters. This means that I will keep information you share with me private to the greatest extent possible. However, I am required to share information regarding sexual assault, abuse, criminal behavior, or about a student who may be a danger to themselves or to others. If you wish to speak to someone confidentially who is not a mandatory reporter, you can schedule an appointment with one of the counselors in the Ebersole Health and Wellbeing Center or contact the College Chaplain, Rev.¬†Melea White, at mwhite@cornelllcollege.edu.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "slides/01-welcome_ch1.html#instructor",
    "href": "slides/01-welcome_ch1.html#instructor",
    "title": "Welcome and Chapter 1",
    "section": "Instructor",
    "text": "Instructor\n\nDr.¬†Tyler George: tgeorge@cornellcollege.edu"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#course-logistics",
    "href": "slides/01-welcome_ch1.html#course-logistics",
    "title": "Welcome and Chapter 1",
    "section": "Course logistics",
    "text": "Course logistics\n\nCourse Dates: August 26th to September 18th\nCourse sessions: M-F,9am-11am and 1pm-3pm\nExam Dates: September 6th and 18th"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#generalized-linear-models",
    "href": "slides/01-welcome_ch1.html#generalized-linear-models",
    "title": "Welcome and Chapter 1",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\nIn statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n\n\nLogistic regression\n\\[\\begin{aligned}\\pi = P(y = 1 | x) \\hspace{2mm} &\\Rightarrow \\hspace{2mm} \\text{Link function: } \\log\\big(\\frac{\\pi}{1-\\pi}\\big) \\\\\n&\\Rightarrow \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~x\\end{aligned}\\]\n\n\nWikipedia"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-were-covering-this-semester13",
    "href": "slides/01-welcome_ch1.html#what-were-covering-this-semester13",
    "title": "Welcome and Chapter 1",
    "section": "What we‚Äôre covering this semester(1/3)",
    "text": "What we‚Äôre covering this semester(1/3)\nGeneralized Linear Models (Ch 1 - 6)\n\nIntroduce models for non-normal response variables\nEstimation, interpretation, and inference\nMathematical details showing how GLMs are connected"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-were-covering-this-semester23",
    "href": "slides/01-welcome_ch1.html#what-were-covering-this-semester23",
    "title": "Welcome and Chapter 1",
    "section": "What we‚Äôre covering this semester(2/3)",
    "text": "What we‚Äôre covering this semester(2/3)\nModeling correlated data (Ch 7 - 9)\n\nIntroduce multilevel models for correlated and longitudinal data\nEstimation, interpretation, and inference\nMathematical details, particularly diving into covariance structures"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-were-covering-this-semester33",
    "href": "slides/01-welcome_ch1.html#what-were-covering-this-semester33",
    "title": "Welcome and Chapter 1",
    "section": "What we‚Äôre covering this semester(3/3)",
    "text": "What we‚Äôre covering this semester(3/3)\nMore Regression Models (ITSL Chapter 7) - Polynomial Regression - Regression Splines - Smoothing Splines - Generalized Additive Models (GAMS)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#meet-your-classmates",
    "href": "slides/01-welcome_ch1.html#meet-your-classmates",
    "title": "Welcome and Chapter 1",
    "section": "Meet your classmates!",
    "text": "Meet your classmates!\n\nCreate larger groups\nQuick introductions - Name, year, and major\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to December 1st.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Cornell Student\nNot clothes (we‚Äôre all wearing socks)\nNot body parts (we all have a nose)\n\n\n\nReporter will share list with the class"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-background-is-assumed-for-the-course",
    "href": "slides/01-welcome_ch1.html#what-background-is-assumed-for-the-course",
    "title": "Welcome and Chapter 1",
    "section": "What background is assumed for the course?",
    "text": "What background is assumed for the course?\n\nPre-reqs\n\nSTA 201, 202 and DSC 223\n\n\n\nBackground knowledge\n\n\n\nStatistical content\n\nLinear and logistic regression\nStatistical inference\nBasic understanding of random variables\n\n\n\n\nComputing\n\nUsing R for data analysis\nWriting reports using R Markdown or Quarto"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#course-toolkit-12",
    "href": "slides/01-welcome_ch1.html#course-toolkit-12",
    "title": "Welcome and Chapter 1",
    "section": "Course Toolkit (1/2)",
    "text": "Course Toolkit (1/2)\n\nWebsite\n\nhttps://stats-tgeorge.github.io/STA363_AdvReg/\nCentral hub for the course\nNotes\nLabs\nDatasets"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#course-toolkit-12-1",
    "href": "slides/01-welcome_ch1.html#course-toolkit-12-1",
    "title": "Welcome and Chapter 1",
    "section": "Course Toolkit (1/2)",
    "text": "Course Toolkit (1/2)\n\nMoodle:\n\nhttps://moodle.cornellcollege.edu/course/view.php?id=7908\nSubmissions\nGradebook\nAnnouncements"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#class-meetings",
    "href": "slides/01-welcome_ch1.html#class-meetings",
    "title": "Welcome and Chapter 1",
    "section": "Class Meetings",
    "text": "Class Meetings\nLectures\n\nSome traditional lecture\nIndividual and group labs\nBring fully-charged laptop\nMini-projects\nExams\n\n\nAttendance is expected (if you are healthy!)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#textbook",
    "href": "slides/01-welcome_ch1.html#textbook",
    "title": "Welcome and Chapter 1",
    "section": "Textbook",
    "text": "Textbook\n\n\n\n\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler\n\nAvailable online\nHard copies available for purchase"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#textbook-2",
    "href": "slides/01-welcome_ch1.html#textbook-2",
    "title": "Welcome and Chapter 1",
    "section": "Textbook 2",
    "text": "Textbook 2\nThe secondary text is: An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani ‚Äì it is freely available online. Chapter 7.\n\nHard copies available for purchase"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#using-r-rstudio",
    "href": "slides/01-welcome_ch1.html#using-r-rstudio",
    "title": "Welcome and Chapter 1",
    "section": "Using R / RStudio",
    "text": "Using R / RStudio\n\nRStudio Server is installed and should be used\nhttp://turing.cornellcollege.edu:8787/"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#activities-assessments",
    "href": "slides/01-welcome_ch1.html#activities-assessments",
    "title": "Welcome and Chapter 1",
    "section": "Activities & Assessments",
    "text": "Activities & Assessments\nReadings\n\nPrimarily from Beyond Multiple Linear Regression\nRecommend reading assigned text before lecture\n\n\nHomework - Primarily from Beyond Multiple Linear Regression - Individual assignments - Work together but must complete your own work. Discuss but don‚Äôt copy."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#activities-assessments-1",
    "href": "slides/01-welcome_ch1.html#activities-assessments-1",
    "title": "Welcome and Chapter 1",
    "section": "Activities & Assessments",
    "text": "Activities & Assessments\nMini-projects\nExamples:\n\nMini-project 01: Focused on models for non-normal response variables, such as count data\nMini-project 02: Focused on models for correlated data\n\n\n\nShort write up and short presentation\nTeam-based"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#exams",
    "href": "slides/01-welcome_ch1.html#exams",
    "title": "Welcome and Chapter 1",
    "section": "Exams",
    "text": "Exams\n\nTwo exams this block, September 6th and 18th.\nEach will have two components\n\nComponent 1 will be on these dates and you will get a choice of oral or written format.\nComponent 2 will be a take-home, open-book, open-note, exam.\nYou will have 12 hours or more to complete this component."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#grading",
    "href": "slides/01-welcome_ch1.html#grading",
    "title": "Welcome and Chapter 1",
    "section": "Grading",
    "text": "Grading\nFinal grades will be calculated as follows\n\n\n\nCategory\nPoints\n\n\n\n\nHomework\n200\n\n\nParticipation\n100\n\n\nLabs and Mini Projects\n300\n\n\nExams\n400\n\n\nTotal\n1000\n\n\n\nSee Syllabus on website for letter grade thresholds."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#resources",
    "href": "slides/01-welcome_ch1.html#resources",
    "title": "Welcome and Chapter 1",
    "section": "Resources",
    "text": "Resources\n\nOffice hours to meet with your instructor in West 311\n\nTypically MWTh 3:05pm-4:05pm and by appt.\nDouble check course calendar\nMake appointments by going to https://calendar.app.google/Li1dftFBXqzRnaX69\n\nEmail Tyler George for private questions regarding personal matters or grades.\n\nPlease put STA 363 in the subject line since I am also teaching capstone this semester\n\nCollege support at https://stats-tgeorge.github.io/personal_website/course-support.html."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#setup---r-packages",
    "href": "slides/01-welcome_ch1.html#setup---r-packages",
    "title": "Welcome and Chapter 1",
    "section": "Setup - R Packages",
    "text": "Setup - R Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#assumptions-for-linear-regression",
    "href": "slides/01-welcome_ch1.html#assumptions-for-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\nWhat are the assumptions for linear regression? . . .\nLinearity: Linear relationship between mean response and predictor variable(s)\n\nIndependence: Residuals are independent. There is no connection between how far any two points lie above or below regression line.\n\n\nNormality: Response follows a normal distribution at each level of the predictor (or combination of predictors)\n\n\nEqual variance: Variability (variance or standard deviation) of the response is equal for all levels of the predictor (or combination of predictors)\n\n\nUse residual plots to check that the conditions hold before using the model for statistical inference."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#assumptions-for-linear-regression-1",
    "href": "slides/01-welcome_ch1.html#assumptions-for-linear-regression-1",
    "title": "Welcome and Chapter 1",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinearity: Linear relationship between mean of the response \\(Y\\) and the predictor \\(X\\)\nIndependence: No connection between how any two points lie above or below the regression line\nNormality: Response, \\(Y\\), follows a normal distribution at each level of the predictor, \\(X\\) (indicated by red curves)\nEqual variance: Variance (or standard deviation) of the response, \\(Y\\), is equal for all levels of the predictor, \\(X\\)\n\n\n\n\nModified from Figure 1.1. in BMLR]"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#questions",
    "href": "slides/01-welcome_ch1.html#questions",
    "title": "Welcome and Chapter 1",
    "section": "Questions",
    "text": "Questions\nHow do we assess these conditions?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#beyond-linear-regression",
    "href": "slides/01-welcome_ch1.html#beyond-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Beyond linear regression",
    "text": "Beyond linear regression\n\nWhen we use linear least squares regression to draw conclusions, we do so under the assumption that L.I.N.E. are all met.\nGeneralized linear models require different assumptions and can accommodate violations in L.I.N.E.\n\nRelationship between response and predictor(s) can be nonlinear\nResponse variable can be non-normal\nVariance in response can differ at each level of predictor(s)\n\n\n\nBut the independence assumption must hold!\n\nMultilevel models will be used for data with correlated observations"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#review-of-multiple-linear-regression",
    "href": "slides/01-welcome_ch1.html#review-of-multiple-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Review of multiple linear regression",
    "text": "Review of multiple linear regression"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#data-kentucky-derby-winners",
    "href": "slides/01-welcome_ch1.html#data-kentucky-derby-winners",
    "title": "Welcome and Chapter 1",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\nToday‚Äôs data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017.\n\n\n\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)]\n\nAdditional variable\n\nwinner: Winning horse\n\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced]"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#data",
    "href": "slides/01-welcome_ch1.html#data",
    "title": "Welcome and Chapter 1",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")\n\n\nderby |&gt;\n  head(5) |&gt; kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n\n\n1898\nPlaudit\ngood\n51.16\n4\n\n\n1899\nManuel\nfast\n50.00\n5\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#data-analysis-life-cycle",
    "href": "slides/01-welcome_ch1.html#data-analysis-life-cycle",
    "title": "Welcome and Chapter 1",
    "section": "Data Analysis Life Cycle",
    "text": "Data Analysis Life Cycle"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#exploratory-data-analysis-eda",
    "href": "slides/01-welcome_ch1.html#exploratory-data-analysis-eda",
    "title": "Welcome and Chapter 1",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\n\nOnce you‚Äôre ready for the statistical analysis (explore), the first step should always be exploratory data analysis.\nThe EDA will help you\n\nbegin to understand the variables and observations\nidentify outliers or potential data entry errors\nbegin to see relationships between variables\nidentify the appropriate model and identify a strategy\n\nThe EDA is exploratory; formal modeling and statistical inference should be used to draw conclusions."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#plots-for-univariate-eda",
    "href": "slides/01-welcome_ch1.html#plots-for-univariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for univariate EDA",
    "text": "Plots for univariate EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = derby, aes(x = speed)) + \n  geom_histogram(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Winning speed (ft/s)\", y = \"Count\")\n\np2 &lt;- ggplot(data = derby, aes(x = starters)) + \n  geom_histogram(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Starters\", y = \"Count\")\n\np3 &lt;- ggplot(data = derby, aes(x = condition)) +\n   geom_bar(fill = \"forestgreen\", color = \"black\", aes(x = ))\n\np1 + (p2 / p3) + \n  plot_annotation(title = \"Univariate data analysis\")"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#plots-for-bivariate-eda",
    "href": "slides/01-welcome_ch1.html#plots-for-bivariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for bivariate EDA",
    "text": "Plots for bivariate EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np4 &lt;- ggplot(data = derby, aes(x = starters, y = speed)) + \n  geom_point() + \n  labs(x = \"Starters\", y = \"Speed (ft / s)\")\n\np5 &lt;- ggplot(data = derby, aes(x = year, y = speed)) + \n  geom_point() + \n  labs(x = \"Year\", y = \"Speed (ft / s)\")\n\np6 &lt;- ggplot(data = derby, aes(x = condition, y = speed)) + \n  geom_boxplot(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Conditions\", y = \"Speed (ft / s)\")\n\n(p4 + p5) + p6 +\n  plot_annotation(title = \"Bivariate data analysis\")"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#scatterplot-matrix",
    "href": "slides/01-welcome_ch1.html#scatterplot-matrix",
    "title": "Welcome and Chapter 1",
    "section": "Scatterplot matrix",
    "text": "Scatterplot matrix\nA scatterplot matrix helps quickly visualize relationships between many variable pairs. They are particularly useful to identify potentially correlated predictors.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#library(GGally)\nggpairs(data = derby, \n        columns = c(\"condition\", \"year\", \"starters\", \"speed\"))"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#plots-for-multivariate-eda",
    "href": "slides/01-welcome_ch1.html#plots-for-multivariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for multivariate EDA",
    "text": "Plots for multivariate EDA\nPlot the relationship between the response and a predictor based on levels of another predictor to assess potential interactions.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#library(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-1-main-effects-model",
    "href": "slides/01-welcome_ch1.html#model-1-main-effects-model",
    "title": "Welcome and Chapter 1",
    "section": "Model 1: Main effects model",
    "text": "Model 1: Main effects model\n\nOutputCode\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\n\n# Fit and display model\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\ntidy(model1) |&gt; \n  kable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#interpretation",
    "href": "slides/01-welcome_ch1.html#interpretation",
    "title": "Welcome and Chapter 1",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\\widehat{speed} = 8.197 - 0.005 ~ starters + 0.023 ~ year - 0.443 ~ good - 1.543 ~ slow\\]\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\nWrite out the interpretations for starters and conditiongood.\nDoes the intercept have a meaningful interpretation?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#centering",
    "href": "slides/01-welcome_ch1.html#centering",
    "title": "Welcome and Chapter 1",
    "section": "Centering",
    "text": "Centering\nCentering: Subtract a constant from each observation of a given variable\n\nDo this to make interpretation of model parameters more meaningful (particularly intercept)\nIn STA 202, we used mean-centering where we subtracted the mean from each observation of given variable\nHow does centering change the model?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#centering-year",
    "href": "slides/01-welcome_ch1.html#centering-year",
    "title": "Welcome and Chapter 1",
    "section": "Centering year",
    "text": "Centering year\n\nderby &lt;- derby |&gt;\n  mutate(yearnew = year - 1896) #1896 = starting year\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.175\n0.194\n269.079\n0.000\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyearnew\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\n\\[\\widehat{speed} = 52.175 - 0.005 ~ starters + 0.023 ~ yearnew - 0.443 ~ good - 1.543 ~ slow\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-1-check-model-assumptions",
    "href": "slides/01-welcome_ch1.html#model-1-check-model-assumptions",
    "title": "Welcome and Chapter 1",
    "section": "Model 1: Check model assumptions",
    "text": "Model 1: Check model assumptions\n\nPlotsQuestions\n\n\n\n#library(ggfortify)\nautoplot(model1Cent)\n\n\n\n\n\n\n\n\n\n\nWhich of the model assumptions (LINE) does this pass and/or fail?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-2-add-quadratic-effect-for-year",
    "href": "slides/01-welcome_ch1.html#model-2-add-quadratic-effect-for-year",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Add quadratic effect for year?",
    "text": "Model 2: Add quadratic effect for year?\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = derby, aes(x = yearnew, y = speed)) + \n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") + \n  geom_smooth(se = FALSE, color = \"red\", linetype = 2) + \n  labs(x = \"Years since 1896\", y = \"Speed (ft/s)\", \n       title = \"Speed vs. Years since 1896\")"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-2-add-yearnew2",
    "href": "slides/01-welcome_ch1.html#model-2-add-yearnew2",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Add \\(yearnew^2\\)",
    "text": "Model 2: Add \\(yearnew^2\\)\n\nPlotCode\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n51.4130\n0.1826\n281.5645\n0.0000\n\n\nstarters\n-0.0253\n0.0136\n-1.8588\n0.0656\n\n\nyearnew\n0.0700\n0.0061\n11.4239\n0.0000\n\n\nI(yearnew^2)\n-0.0004\n0.0000\n-8.0411\n0.0000\n\n\nconditiongood\n-0.4770\n0.1857\n-2.5689\n0.0115\n\n\nconditionslow\n-1.3927\n0.1305\n-10.6701\n0.0000\n\n\n\n\n\n\n\n\nmodel2 &lt;- lm(speed ~ starters + yearnew + I(yearnew^2) + condition, \n             data = derby)\ntidy(model2) |&gt; kable(digits = 4)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#interpreting-quadratic-effects",
    "href": "slides/01-welcome_ch1.html#interpreting-quadratic-effects",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting quadratic effects",
    "text": "Interpreting quadratic effects\n\\[\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x_1  + \\hat{\\beta}_2 ~ x_2 + \\hat{\\beta}_3 ~ x_2^2\\]\nGeneral interpretation: When \\(x_2\\) increases from a to b, \\(y\\) is expected to change by \\(\\hat{\\beta}_2(b - a) + \\hat{\\beta}_3(b^2 - a^2)\\), holding \\(x_1\\) constant."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#interpreting-quadratic-effects-1",
    "href": "slides/01-welcome_ch1.html#interpreting-quadratic-effects-1",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting quadratic effects",
    "text": "Interpreting quadratic effects\n\\[\\begin{aligned}\\widehat{speed} = &51.413 - 0.025 ~ starters + 0.070 ~ yearnew \\\\\n& - 0.0004 ~ yearnew^2 - 0.477 ~ good - 1.393 ~ slow\\end{aligned}\\]\n\nQuestions:\nInterpret the effect of year for the 5 most recent years (2013 - 2017)."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-2-check-model-assumptions",
    "href": "slides/01-welcome_ch1.html#model-2-check-model-assumptions",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Check model assumptions",
    "text": "Model 2: Check model assumptions"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-3-include-interaction-term",
    "href": "slides/01-welcome_ch1.html#model-3-include-interaction-term",
    "title": "Welcome and Chapter 1",
    "section": "Model 3: Include interaction term?",
    "text": "Model 3: Include interaction term?\nRecall from the EDA‚Ä¶\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-3-add-interaction-term",
    "href": "slides/01-welcome_ch1.html#model-3-add-interaction-term",
    "title": "Welcome and Chapter 1",
    "section": "Model 3: Add interaction term",
    "text": "Model 3: Add interaction term\n\\[\\begin{aligned}\\widehat{speed} = & 52.387 - 0.003 ~ starters + 0.020 ~ yearnew - 1.070 ~ good - 2.183 ~ slow \\\\ &+0.012 ~ yearnew \\times good + 0.012 ~ yearnew \\times slow \\end{aligned}\\]\n\nOutputCodeAssumptions\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n\n\n\nmodel3 &lt;- lm(speed ~ starters + yearnew + condition +\n               yearnew * condition, \n             data = derby)\ntidy(model3) |&gt; kable(digits = 4)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#interpreting-interaction-effects",
    "href": "slides/01-welcome_ch1.html#interpreting-interaction-effects",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting interaction effects",
    "text": "Interpreting interaction effects\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n\nWrite out the interpretation of‚Ä¶"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#which-model-would-you-choose",
    "href": "slides/01-welcome_ch1.html#which-model-would-you-choose",
    "title": "Welcome and Chapter 1",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\n\nModel 1: Main effectsModel 2: Main effects + \\(year^2\\)Model 3: Main effects + interactionCode\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.73\n0.721\n259.478\n276.302\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.827\n0.819\n207.429\n227.057\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\n\n# Model 1\nglance(model1Cent) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)\n\n# Model2\nglance(model2) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)\n\n# Model 3\nglance(model3) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-are-these-model-quality-metrics",
    "href": "slides/01-welcome_ch1.html#what-are-these-model-quality-metrics",
    "title": "Welcome and Chapter 1",
    "section": "What are these model quality metrics?",
    "text": "What are these model quality metrics?\n\nHow do we define RSquared?\nWhat is adj.r.squared?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#measures-of-model-performance",
    "href": "slides/01-welcome_ch1.html#measures-of-model-performance",
    "title": "Welcome and Chapter 1",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(\\color{#4187aa}{R^2}\\): Proportion of variability in the response explained by the model.\n\nWill always increase as predictors are added, so it shouldn‚Äôt be used to compare models\n\n\\(\\color{#4187aa}{Adj. R^2}\\): Similar to \\(R^2\\) with a penalty for extra terms\n\n\n\n\\(\\color{#4187aa}{AIC}\\): Likelihood-based approach balancing model performance and complexity\n\\(\\color{#4187aa}{BIC}\\): Similar to AIC with stronger penalty for extra terms\n\n\n\n\nNested F Test (extra sum of squares F test): Generalization of t-test for individual coefficients to perform significance tests on nested models"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#which-model-would-you-choose-1",
    "href": "slides/01-welcome_ch1.html#which-model-would-you-choose-1",
    "title": "Welcome and Chapter 1",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\nUse the glance function to get model statistics.\n\nOutputCode\n\n\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\n\nmodel1_glance &lt;- glance(model1Cent) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\nmodel2_glance &lt;- glance(model2) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\nmodel3_glance &lt;- glance(model3) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\n\nmodel1_glance |&gt;\n  bind_rows(model2_glance) |&gt;\n  bind_rows(model3_glance) |&gt;\n  bind_cols(model = c(\"Model1\", \"Model2\", \"Model3\")) |&gt;\n  select(model, everything()) |&gt;\nkable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#characteristics-of-a-good-final-model",
    "href": "slides/01-welcome_ch1.html#characteristics-of-a-good-final-model",
    "title": "Welcome and Chapter 1",
    "section": "Characteristics of a ‚Äúgood‚Äù final model",
    "text": "Characteristics of a ‚Äúgood‚Äù final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nunnecessary terms are removed\nAssumptions are met and influential points have been addressed\nmodel tells a ‚Äúpersuasive story parsimoniously‚Äù\n\n\n\nList from Section 1.6.7 of BMLR"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#inference-for-multiple-linear-regression",
    "href": "slides/01-welcome_ch1.html#inference-for-multiple-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Inference for multiple linear regression",
    "text": "Inference for multiple linear regression\nUse statistical inference to\n\nDetermine if predictors are statistically significant (not necessarily practically significant!)\nQuantify uncertainty in coefficient estimates\nQuantify uncertainty in model predictions\n\n\nIf L.I.N.E. assumptions are met, we can conduct inference using the \\(t\\) distribution and estimated standard errors"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#inference-for-regression",
    "href": "slides/01-welcome_ch1.html#inference-for-regression",
    "title": "Welcome and Chapter 1",
    "section": "Inference for regression",
    "text": "Inference for regression\n\nWhen L.I.N.E. conditions are metWe can\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse least squares regression to get the estimates \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), and \\(\\hat{\\sigma}^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\n. . .\n\\[\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#acknowledgements",
    "href": "slides/01-welcome_ch1.html#acknowledgements",
    "title": "Welcome and Chapter 1",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html",
    "href": "slides/01-welcome_ch1_o.html",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Dr.¬†Tyler George: tgeorge@cornellcollege.edu\n\n\n\n\n\nCourse Dates: August 26th to September 18th\nCourse sessions: M-F,9am-11am and 1pm-3pm\nExam Dates: September 6th and 18th\n\n\n\n\nIn statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n\n\nWikipedia\n. . .\nLogistic regression\n\\[\\begin{aligned}\\pi = P(y = 1 | x) \\hspace{2mm} &\\Rightarrow \\hspace{2mm} \\text{Link function: } \\log\\big(\\frac{\\pi}{1-\\pi}\\big) \\\\\n&\\Rightarrow \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~x\\end{aligned}\\]\n\n\n\nGeneralized Linear Models (Ch 1 - 6)\n\nIntroduce models for non-normal response variables\nEstimation, interpretation, and inference\nMathematical details showing how GLMs are connected\n\n\n\n\nModeling correlated data (Ch 7 - 9)\n\nIntroduce multilevel models for correlated and longitudinal data\nEstimation, interpretation, and inference\nMathematical details, particularly diving into covariance structures\n\n\n\n\nMore Regression Models (ITSL Chapter 7) - Polynomial Regression - Regression Splines - Smoothing Splines - Generalized Additive Models (GAMS)\n\n\n\n\nCreate larger groups\nQuick introductions - Name, year, and major\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to December 1st.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Cornell Student\nNot clothes (we‚Äôre all wearing socks)\nNot body parts (we all have a nose)\n\n\n. . .\nReporter will share list with the class\n\n\n\n. . .\nPre-reqs\n\nSTA 201, 202 and DSC 223\n\n. . .\nBackground knowledge\n\n\n\nStatistical content\n\nLinear and logistic regression\nStatistical inference\nBasic understanding of random variables\n\n\n\n\nComputing\n\nUsing R for data analysis\nWriting reports using R Markdown or Quarto\n\n\n\n\n\n\n\n\nWebsite\n\nhttps://stats-tgeorge.github.io/STA363_AdvReg/\nCentral hub for the course\nNotes\nLabs\nDatasets\n\n\n\n\n\n\nMoodle:\n\nhttps://moodle.cornellcollege.edu/course/view.php?id=7908\nSubmissions\nGradebook\nAnnouncements\n\n\n\n\n\nLectures\n\nSome traditional lecture\nIndividual and group labs\nBring fully-charged laptop\nMini-projects\nExams\n\n. . .\nAttendance is expected (if you are healthy!)\n\n\n\n\n\n\n\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler\n\nAvailable online\nHard copies available for purchase\n\n\n\n\n\n\nThe secondary text is: An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani ‚Äì it is freely available online. Chapter 7.\n\nHard copies available for purchase\n\n\n\n\n\nRStudio Server is installed and should be used\nhttp://turing.cornellcollege.edu:8787/\n\n\n\n\nReadings\n\nPrimarily from Beyond Multiple Linear Regression\nRecommend reading assigned text before lecture\n\n. . .\nHomework - Primarily from Beyond Multiple Linear Regression - Individual assignments - Work together but must complete your own work. Discuss but don‚Äôt copy.\n\n\n\nMini-projects\nExamples:\n\nMini-project 01: Focused on models for non-normal response variables, such as count data\nMini-project 02: Focused on models for correlated data\n\n. . .\n\nShort write up and short presentation\nTeam-based\n\n\n\n\n\nTwo exams this block, September 6th and 18th.\nEach will have two components\n\nComponent 1 will be on these dates and you will get a choice of oral or written format.\nComponent 2 will be a take-home, open-book, open-note, exam.\nYou will have 12 hours or more to complete this component.\n\n\n\n\n\nFinal grades will be calculated as follows\n\n\n\nCategory\nPoints\n\n\n\n\nHomework\n200\n\n\nParticipation\n100\n\n\nLabs and Mini Projects\n300\n\n\nExams\n400\n\n\nTotal\n1000\n\n\n\nSee Syllabus on website for letter grade thresholds.\n\n\n\n\nOffice hours to meet with your instructor in West 311\n\nTypically MWTh 3:05pm-4:05pm and by appt.\nDouble check course calendar\nMake appointments by going to https://calendar.app.google/Li1dftFBXqzRnaX69\n\nEmail Tyler George for private questions regarding personal matters or grades.\n\nPlease put STA 363 in the subject line since I am also teaching capstone this semester\n\nCollege support at https://stats-tgeorge.github.io/personal_website/course-support.html."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#instructor",
    "href": "slides/01-welcome_ch1_o.html#instructor",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Dr.¬†Tyler George: tgeorge@cornellcollege.edu"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#course-logistics",
    "href": "slides/01-welcome_ch1_o.html#course-logistics",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Course Dates: August 26th to September 18th\nCourse sessions: M-F,9am-11am and 1pm-3pm\nExam Dates: September 6th and 18th"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#generalized-linear-models",
    "href": "slides/01-welcome_ch1_o.html#generalized-linear-models",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "In statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n\n\nWikipedia\n. . .\nLogistic regression\n\\[\\begin{aligned}\\pi = P(y = 1 | x) \\hspace{2mm} &\\Rightarrow \\hspace{2mm} \\text{Link function: } \\log\\big(\\frac{\\pi}{1-\\pi}\\big) \\\\\n&\\Rightarrow \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~x\\end{aligned}\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester13",
    "href": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester13",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Generalized Linear Models (Ch 1 - 6)\n\nIntroduce models for non-normal response variables\nEstimation, interpretation, and inference\nMathematical details showing how GLMs are connected"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester23",
    "href": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester23",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Modeling correlated data (Ch 7 - 9)\n\nIntroduce multilevel models for correlated and longitudinal data\nEstimation, interpretation, and inference\nMathematical details, particularly diving into covariance structures"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester33",
    "href": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester33",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "More Regression Models (ITSL Chapter 7) - Polynomial Regression - Regression Splines - Smoothing Splines - Generalized Additive Models (GAMS)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#meet-your-classmates",
    "href": "slides/01-welcome_ch1_o.html#meet-your-classmates",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Create larger groups\nQuick introductions - Name, year, and major\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to December 1st.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Cornell Student\nNot clothes (we‚Äôre all wearing socks)\nNot body parts (we all have a nose)\n\n\n. . .\nReporter will share list with the class"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-background-is-assumed-for-the-course",
    "href": "slides/01-welcome_ch1_o.html#what-background-is-assumed-for-the-course",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": ". . .\nPre-reqs\n\nSTA 201, 202 and DSC 223\n\n. . .\nBackground knowledge\n\n\n\nStatistical content\n\nLinear and logistic regression\nStatistical inference\nBasic understanding of random variables\n\n\n\n\nComputing\n\nUsing R for data analysis\nWriting reports using R Markdown or Quarto"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#course-toolkit-12",
    "href": "slides/01-welcome_ch1_o.html#course-toolkit-12",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Website\n\nhttps://stats-tgeorge.github.io/STA363_AdvReg/\nCentral hub for the course\nNotes\nLabs\nDatasets"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#course-toolkit-12-1",
    "href": "slides/01-welcome_ch1_o.html#course-toolkit-12-1",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Moodle:\n\nhttps://moodle.cornellcollege.edu/course/view.php?id=7908\nSubmissions\nGradebook\nAnnouncements"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#class-meetings",
    "href": "slides/01-welcome_ch1_o.html#class-meetings",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Lectures\n\nSome traditional lecture\nIndividual and group labs\nBring fully-charged laptop\nMini-projects\nExams\n\n. . .\nAttendance is expected (if you are healthy!)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#textbook",
    "href": "slides/01-welcome_ch1_o.html#textbook",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Beyond Multiple Linear Regression by Paul Roback and Julie Legler\n\nAvailable online\nHard copies available for purchase"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#textbook-2",
    "href": "slides/01-welcome_ch1_o.html#textbook-2",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "The secondary text is: An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani ‚Äì it is freely available online. Chapter 7.\n\nHard copies available for purchase"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#using-r-rstudio",
    "href": "slides/01-welcome_ch1_o.html#using-r-rstudio",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "RStudio Server is installed and should be used\nhttp://turing.cornellcollege.edu:8787/"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#activities-assessments",
    "href": "slides/01-welcome_ch1_o.html#activities-assessments",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Readings\n\nPrimarily from Beyond Multiple Linear Regression\nRecommend reading assigned text before lecture\n\n. . .\nHomework - Primarily from Beyond Multiple Linear Regression - Individual assignments - Work together but must complete your own work. Discuss but don‚Äôt copy."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#activities-assessments-1",
    "href": "slides/01-welcome_ch1_o.html#activities-assessments-1",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Mini-projects\nExamples:\n\nMini-project 01: Focused on models for non-normal response variables, such as count data\nMini-project 02: Focused on models for correlated data\n\n. . .\n\nShort write up and short presentation\nTeam-based"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#exams",
    "href": "slides/01-welcome_ch1_o.html#exams",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Two exams this block, September 6th and 18th.\nEach will have two components\n\nComponent 1 will be on these dates and you will get a choice of oral or written format.\nComponent 2 will be a take-home, open-book, open-note, exam.\nYou will have 12 hours or more to complete this component."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#grading",
    "href": "slides/01-welcome_ch1_o.html#grading",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Final grades will be calculated as follows\n\n\n\nCategory\nPoints\n\n\n\n\nHomework\n200\n\n\nParticipation\n100\n\n\nLabs and Mini Projects\n300\n\n\nExams\n400\n\n\nTotal\n1000\n\n\n\nSee Syllabus on website for letter grade thresholds."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#resources",
    "href": "slides/01-welcome_ch1_o.html#resources",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Office hours to meet with your instructor in West 311\n\nTypically MWTh 3:05pm-4:05pm and by appt.\nDouble check course calendar\nMake appointments by going to https://calendar.app.google/Li1dftFBXqzRnaX69\n\nEmail Tyler George for private questions regarding personal matters or grades.\n\nPlease put STA 363 in the subject line since I am also teaching capstone this semester\n\nCollege support at https://stats-tgeorge.github.io/personal_website/course-support.html."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#setup---r-packages",
    "href": "slides/01-welcome_ch1_o.html#setup---r-packages",
    "title": "Welcome and Chapter 1",
    "section": "Setup - R Packages",
    "text": "Setup - R Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#assumptions-for-linear-regression",
    "href": "slides/01-welcome_ch1_o.html#assumptions-for-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\nWhat are the assumptions for linear regression? . . .\nLinearity: Linear relationship between mean response and predictor variable(s)\n. . .\nIndependence: Residuals are independent. There is no connection between how far any two points lie above or below regression line.\n. . .\nNormality: Response follows a normal distribution at each level of the predictor (or combination of predictors)\n. . .\nEqual variance: Variability (variance or standard deviation) of the response is equal for all levels of the predictor (or combination of predictors)\n. . .\nUse residual plots to check that the conditions hold before using the model for statistical inference."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#assumptions-for-linear-regression-1",
    "href": "slides/01-welcome_ch1_o.html#assumptions-for-linear-regression-1",
    "title": "Welcome and Chapter 1",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\nModified from Figure 1.1. in BMLR]\n\n\nLinearity: Linear relationship between mean of the response \\(Y\\) and the predictor \\(X\\)\nIndependence: No connection between how any two points lie above or below the regression line\nNormality: Response, \\(Y\\), follows a normal distribution at each level of the predictor, \\(X\\) (indicated by red curves)\nEqual variance: Variance (or standard deviation) of the response, \\(Y\\), is equal for all levels of the predictor, \\(X\\)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#questions",
    "href": "slides/01-welcome_ch1_o.html#questions",
    "title": "Welcome and Chapter 1",
    "section": "Questions",
    "text": "Questions\nHow do we assess these conditions?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#beyond-linear-regression",
    "href": "slides/01-welcome_ch1_o.html#beyond-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Beyond linear regression",
    "text": "Beyond linear regression\n\nWhen we use linear least squares regression to draw conclusions, we do so under the assumption that L.I.N.E. are all met.\nGeneralized linear models require different assumptions and can accommodate violations in L.I.N.E.\n\nRelationship between response and predictor(s) can be nonlinear\nResponse variable can be non-normal\nVariance in response can differ at each level of predictor(s)\n\n\n. . .\nBut the independence assumption must hold!\n\nMultilevel models will be used for data with correlated observations"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#review-of-multiple-linear-regression",
    "href": "slides/01-welcome_ch1_o.html#review-of-multiple-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Review of multiple linear regression",
    "text": "Review of multiple linear regression"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#data-kentucky-derby-winners",
    "href": "slides/01-welcome_ch1_o.html#data-kentucky-derby-winners",
    "title": "Welcome and Chapter 1",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\nToday‚Äôs data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017.\n. . .\n\n\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)]\n\nAdditional variable\n\nwinner: Winning horse\n\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced]"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#data",
    "href": "slides/01-welcome_ch1_o.html#data",
    "title": "Welcome and Chapter 1",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")\n\n\nderby |&gt;\n  head(5) |&gt; kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n\n\n1898\nPlaudit\ngood\n51.16\n4\n\n\n1899\nManuel\nfast\n50.00\n5\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#data-analysis-life-cycle",
    "href": "slides/01-welcome_ch1_o.html#data-analysis-life-cycle",
    "title": "Welcome and Chapter 1",
    "section": "Data Analysis Life Cycle",
    "text": "Data Analysis Life Cycle"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#exploratory-data-analysis-eda",
    "href": "slides/01-welcome_ch1_o.html#exploratory-data-analysis-eda",
    "title": "Welcome and Chapter 1",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\n\nOnce you‚Äôre ready for the statistical analysis (explore), the first step should always be exploratory data analysis.\nThe EDA will help you\n\nbegin to understand the variables and observations\nidentify outliers or potential data entry errors\nbegin to see relationships between variables\nidentify the appropriate model and identify a strategy\n\nThe EDA is exploratory; formal modeling and statistical inference should be used to draw conclusions."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#plots-for-univariate-eda",
    "href": "slides/01-welcome_ch1_o.html#plots-for-univariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for univariate EDA",
    "text": "Plots for univariate EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = derby, aes(x = speed)) + \n  geom_histogram(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Winning speed (ft/s)\", y = \"Count\")\n\np2 &lt;- ggplot(data = derby, aes(x = starters)) + \n  geom_histogram(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Starters\", y = \"Count\")\n\np3 &lt;- ggplot(data = derby, aes(x = condition)) +\n   geom_bar(fill = \"forestgreen\", color = \"black\", aes(x = ))\n\np1 + (p2 / p3) + \n  plot_annotation(title = \"Univariate data analysis\")"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#plots-for-bivariate-eda",
    "href": "slides/01-welcome_ch1_o.html#plots-for-bivariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for bivariate EDA",
    "text": "Plots for bivariate EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np4 &lt;- ggplot(data = derby, aes(x = starters, y = speed)) + \n  geom_point() + \n  labs(x = \"Starters\", y = \"Speed (ft / s)\")\n\np5 &lt;- ggplot(data = derby, aes(x = year, y = speed)) + \n  geom_point() + \n  labs(x = \"Year\", y = \"Speed (ft / s)\")\n\np6 &lt;- ggplot(data = derby, aes(x = condition, y = speed)) + \n  geom_boxplot(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Conditions\", y = \"Speed (ft / s)\")\n\n(p4 + p5) + p6 +\n  plot_annotation(title = \"Bivariate data analysis\")"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#scatterplot-matrix",
    "href": "slides/01-welcome_ch1_o.html#scatterplot-matrix",
    "title": "Welcome and Chapter 1",
    "section": "Scatterplot matrix",
    "text": "Scatterplot matrix\nA scatterplot matrix helps quickly visualize relationships between many variable pairs. They are particularly useful to identify potentially correlated predictors.\n. . .\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#library(GGally)\nggpairs(data = derby, \n        columns = c(\"condition\", \"year\", \"starters\", \"speed\"))"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#plots-for-multivariate-eda",
    "href": "slides/01-welcome_ch1_o.html#plots-for-multivariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for multivariate EDA",
    "text": "Plots for multivariate EDA\nPlot the relationship between the response and a predictor based on levels of another predictor to assess potential interactions.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#library(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-1-main-effects-model",
    "href": "slides/01-welcome_ch1_o.html#model-1-main-effects-model",
    "title": "Welcome and Chapter 1",
    "section": "Model 1: Main effects model",
    "text": "Model 1: Main effects model\n\nOutputCode\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\n\n# Fit and display model\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\ntidy(model1) |&gt; \n  kable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#interpretation",
    "href": "slides/01-welcome_ch1_o.html#interpretation",
    "title": "Welcome and Chapter 1",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\\widehat{speed} = 8.197 - 0.005 ~ starters + 0.023 ~ year - 0.443 ~ good - 1.543 ~ slow\\]\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n. . .\n\nWrite out the interpretations for starters and conditiongood.\nDoes the intercept have a meaningful interpretation?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#centering",
    "href": "slides/01-welcome_ch1_o.html#centering",
    "title": "Welcome and Chapter 1",
    "section": "Centering",
    "text": "Centering\nCentering: Subtract a constant from each observation of a given variable\n\nDo this to make interpretation of model parameters more meaningful (particularly intercept)\nIn STA 202, we used mean-centering where we subtracted the mean from each observation of given variable\nHow does centering change the model?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#centering-year",
    "href": "slides/01-welcome_ch1_o.html#centering-year",
    "title": "Welcome and Chapter 1",
    "section": "Centering year",
    "text": "Centering year\n\nderby &lt;- derby |&gt;\n  mutate(yearnew = year - 1896) #1896 = starting year\n\n. . .\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.175\n0.194\n269.079\n0.000\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyearnew\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n. . .\n\\[\\widehat{speed} = 52.175 - 0.005 ~ starters + 0.023 ~ yearnew - 0.443 ~ good - 1.543 ~ slow\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-1-check-model-assumptions",
    "href": "slides/01-welcome_ch1_o.html#model-1-check-model-assumptions",
    "title": "Welcome and Chapter 1",
    "section": "Model 1: Check model assumptions",
    "text": "Model 1: Check model assumptions\n\nPlotsQuestions\n\n\n\n#library(ggfortify)\nautoplot(model1Cent)\n\n\n\n\n\n\n\n\n\n\nWhich of the model assumptions (LINE) does this pass and/or fail?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-2-add-quadratic-effect-for-year",
    "href": "slides/01-welcome_ch1_o.html#model-2-add-quadratic-effect-for-year",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Add quadratic effect for year?",
    "text": "Model 2: Add quadratic effect for year?\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = derby, aes(x = yearnew, y = speed)) + \n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") + \n  geom_smooth(se = FALSE, color = \"red\", linetype = 2) + \n  labs(x = \"Years since 1896\", y = \"Speed (ft/s)\", \n       title = \"Speed vs. Years since 1896\")"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-2-add-yearnew2",
    "href": "slides/01-welcome_ch1_o.html#model-2-add-yearnew2",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Add \\(yearnew^2\\)",
    "text": "Model 2: Add \\(yearnew^2\\)\n\nPlotCode\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n51.4130\n0.1826\n281.5645\n0.0000\n\n\nstarters\n-0.0253\n0.0136\n-1.8588\n0.0656\n\n\nyearnew\n0.0700\n0.0061\n11.4239\n0.0000\n\n\nI(yearnew^2)\n-0.0004\n0.0000\n-8.0411\n0.0000\n\n\nconditiongood\n-0.4770\n0.1857\n-2.5689\n0.0115\n\n\nconditionslow\n-1.3927\n0.1305\n-10.6701\n0.0000\n\n\n\n\n\n\n\n\nmodel2 &lt;- lm(speed ~ starters + yearnew + I(yearnew^2) + condition, \n             data = derby)\ntidy(model2) |&gt; kable(digits = 4)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#interpreting-quadratic-effects",
    "href": "slides/01-welcome_ch1_o.html#interpreting-quadratic-effects",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting quadratic effects",
    "text": "Interpreting quadratic effects\n\\[\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x_1  + \\hat{\\beta}_2 ~ x_2 + \\hat{\\beta}_3 ~ x_2^2\\]\nGeneral interpretation: When \\(x_2\\) increases from a to b, \\(y\\) is expected to change by \\(\\hat{\\beta}_2(b - a) + \\hat{\\beta}_3(b^2 - a^2)\\), holding \\(x_1\\) constant.\n. . ."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#interpreting-quadratic-effects-1",
    "href": "slides/01-welcome_ch1_o.html#interpreting-quadratic-effects-1",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting quadratic effects",
    "text": "Interpreting quadratic effects\n\\[\\begin{aligned}\\widehat{speed} = &51.413 - 0.025 ~ starters + 0.070 ~ yearnew \\\\\n& - 0.0004 ~ yearnew^2 - 0.477 ~ good - 1.393 ~ slow\\end{aligned}\\]\n. . .\nQuestions:\nInterpret the effect of year for the 5 most recent years (2013 - 2017)."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-2-check-model-assumptions",
    "href": "slides/01-welcome_ch1_o.html#model-2-check-model-assumptions",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Check model assumptions",
    "text": "Model 2: Check model assumptions"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-3-include-interaction-term",
    "href": "slides/01-welcome_ch1_o.html#model-3-include-interaction-term",
    "title": "Welcome and Chapter 1",
    "section": "Model 3: Include interaction term?",
    "text": "Model 3: Include interaction term?\nRecall from the EDA‚Ä¶\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-3-add-interaction-term",
    "href": "slides/01-welcome_ch1_o.html#model-3-add-interaction-term",
    "title": "Welcome and Chapter 1",
    "section": "Model 3: Add interaction term",
    "text": "Model 3: Add interaction term\n\\[\\begin{aligned}\\widehat{speed} = & 52.387 - 0.003 ~ starters + 0.020 ~ yearnew - 1.070 ~ good - 2.183 ~ slow \\\\ &+0.012 ~ yearnew \\times good + 0.012 ~ yearnew \\times slow \\end{aligned}\\]\n\nOutputCodeAssumptions\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n\n\n\nmodel3 &lt;- lm(speed ~ starters + yearnew + condition +\n               yearnew * condition, \n             data = derby)\ntidy(model3) |&gt; kable(digits = 4)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#interpreting-interaction-effects",
    "href": "slides/01-welcome_ch1_o.html#interpreting-interaction-effects",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting interaction effects",
    "text": "Interpreting interaction effects\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n\nWrite out the interpretation of‚Ä¶"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#which-model-would-you-choose",
    "href": "slides/01-welcome_ch1_o.html#which-model-would-you-choose",
    "title": "Welcome and Chapter 1",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\n\nModel 1: Main effectsModel 2: Main effects + \\(year^2\\)Model 3: Main effects + interactionCode\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.73\n0.721\n259.478\n276.302\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.827\n0.819\n207.429\n227.057\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\n\n# Model 1\nglance(model1Cent) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)\n\n# Model2\nglance(model2) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)\n\n# Model 3\nglance(model3) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-are-these-model-quality-metrics",
    "href": "slides/01-welcome_ch1_o.html#what-are-these-model-quality-metrics",
    "title": "Welcome and Chapter 1",
    "section": "What are these model quality metrics?",
    "text": "What are these model quality metrics?\n\nHow do we define RSquared?\nWhat is adj.r.squared?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#measures-of-model-performance",
    "href": "slides/01-welcome_ch1_o.html#measures-of-model-performance",
    "title": "Welcome and Chapter 1",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(\\color{#4187aa}{R^2}\\): Proportion of variability in the response explained by the model.\n\nWill always increase as predictors are added, so it shouldn‚Äôt be used to compare models\n\n\\(\\color{#4187aa}{Adj. R^2}\\): Similar to \\(R^2\\) with a penalty for extra terms\n\n. . .\n\n\\(\\color{#4187aa}{AIC}\\): Likelihood-based approach balancing model performance and complexity\n\\(\\color{#4187aa}{BIC}\\): Similar to AIC with stronger penalty for extra terms\n\n. . .\n\nNested F Test (extra sum of squares F test): Generalization of t-test for individual coefficients to perform significance tests on nested models"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#which-model-would-you-choose-1",
    "href": "slides/01-welcome_ch1_o.html#which-model-would-you-choose-1",
    "title": "Welcome and Chapter 1",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\nUse the glance function to get model statistics.\n\nOutputCode\n\n\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\n\nmodel1_glance &lt;- glance(model1Cent) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\nmodel2_glance &lt;- glance(model2) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\nmodel3_glance &lt;- glance(model3) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\n\nmodel1_glance |&gt;\n  bind_rows(model2_glance) |&gt;\n  bind_rows(model3_glance) |&gt;\n  bind_cols(model = c(\"Model1\", \"Model2\", \"Model3\")) |&gt;\n  select(model, everything()) |&gt;\nkable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#characteristics-of-a-good-final-model",
    "href": "slides/01-welcome_ch1_o.html#characteristics-of-a-good-final-model",
    "title": "Welcome and Chapter 1",
    "section": "Characteristics of a ‚Äúgood‚Äù final model",
    "text": "Characteristics of a ‚Äúgood‚Äù final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nunnecessary terms are removed\nAssumptions are met and influential points have been addressed\nmodel tells a ‚Äúpersuasive story parsimoniously‚Äù\n\n\n\nList from Section 1.6.7 of BMLR"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#inference-for-multiple-linear-regression",
    "href": "slides/01-welcome_ch1_o.html#inference-for-multiple-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Inference for multiple linear regression",
    "text": "Inference for multiple linear regression\nUse statistical inference to\n\nDetermine if predictors are statistically significant (not necessarily practically significant!)\nQuantify uncertainty in coefficient estimates\nQuantify uncertainty in model predictions\n\n. . .\nIf L.I.N.E. assumptions are met, we can conduct inference using the \\(t\\) distribution and estimated standard errors"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#inference-for-regression",
    "href": "slides/01-welcome_ch1_o.html#inference-for-regression",
    "title": "Welcome and Chapter 1",
    "section": "Inference for regression",
    "text": "Inference for regression\n\nWhen L.I.N.E. conditions are metWe can\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse least squares regression to get the estimates \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), and \\(\\hat{\\sigma}^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\n. . .\n\\[\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#acknowledgements",
    "href": "slides/01-welcome_ch1_o.html#acknowledgements",
    "title": "Welcome and Chapter 1",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University"
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood_fillable.html",
    "href": "labs/02_likelihood/02_likelihood_fillable.html",
    "title": "Chapter 2 - Likelihoods",
    "section": "",
    "text": "Consider a small example with 3 families with compositions of children given by BBG, GBG, and GG.\nFind the maximum likelihood estimator (MLE) for by:\n\n\nConducting a numerical search in R for the largest likelihood over a fine grid of values 0-1.\nConducting a numerical search in R for the largest log-likelihood between 0 and 1. Illustrate the process graphically, and report the maximum value of the likelihood and log-likelihood functions. Does it make sense that both methods would agree (and agree with the mathematical approach)?\n\n\nApply Model 1 to the NLSY data (families in Table 2 with 3 or fewer children). Find the MLE for by adapting the R code for (1).\n\n\n\n\n= probability of a boy when previously have had an equal number of boys and girls (neutral)\n= probability of a boy when previously have had more boys than girls (boy bias)\n= probability of a boy when previously have had more girls than boys (girl bias)\n\nWrite out the likelihood function given Model 2 for the small set of data in (1). [You could also try BGG, GGB, BBB just for fun.]"
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood_fillable.html#questions",
    "href": "labs/02_likelihood/02_likelihood_fillable.html#questions",
    "title": "Chapter 2 - Likelihoods",
    "section": "",
    "text": "Consider a small example with 3 families with compositions of children given by BBG, GBG, and GG.\nFind the maximum likelihood estimator (MLE) for by:\n\n\nConducting a numerical search in R for the largest likelihood over a fine grid of values 0-1.\nConducting a numerical search in R for the largest log-likelihood between 0 and 1. Illustrate the process graphically, and report the maximum value of the likelihood and log-likelihood functions. Does it make sense that both methods would agree (and agree with the mathematical approach)?\n\n\nApply Model 1 to the NLSY data (families in Table 2 with 3 or fewer children). Find the MLE for by adapting the R code for (1).\n\n\n\n\n= probability of a boy when previously have had an equal number of boys and girls (neutral)\n= probability of a boy when previously have had more boys than girls (boy bias)\n= probability of a boy when previously have had more girls than boys (girl bias)\n\nWrite out the likelihood function given Model 2 for the small set of data in (1). [You could also try BGG, GGB, BBB just for fun.]"
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary_fillable.html",
    "href": "labs/01_linear_regression/01_banksalary_fillable.html",
    "title": "Linear Regression Review Lab",
    "section": "",
    "text": "Example: Sex discrimination in bank salaries. In the 1970‚Äôs, Harris Trust was sued for sex discrimination in the salaries it paid its employees. One approach to addressing this issue was to examine the starting salaries of all skilled, entry-level clerical workers between 1965 and 1975. The data is saved under banksalary.csv, and relevant R code can be found in the STA363_inst_files folder on the home directory of the RStudio Server. banksalary.qmd.\nFirst, we will speculate on what we expect to find and then we will perform an analysis using the data.\nRead the data in and use aview() to see the data, but do not do anything else with the data on the computer until question 6.\n\nIdentify the observational units, the response variable, and explanatory variables.\nGiven the mean starting salary of male workers ($5957) was 16% higher than the mean starting salary of female workers ($5139): Is this enough evidence to conclude sex discrimination exists? If not, what further evidence would you need?\nHow would you expect age, experience, and education to each be related to starting salary?\nWhy might it be important to control for seniority (number of years with the bank) if we are only concerned with the salary when the worker started?\nDo you expect any explanatory variables (including sex) to be closely related to each other? What implications would this have for modeling?\n\nUsing the data‚Ä¶\nOne approach is to construct a good model for beginning salaries while requiring sex as a predictor, to determine the significance of sex after controlling for the other covariates. Then we can explore interactions with sex to see if its effect is consistent across levels of other predictors.\n\nUse the data to address the primary question of interest here using only the beginning salary and sex variables. Be sure to discuss plots and summary statistics first, and then look at test(s) of significance.\nConstruct plots to investigate how each of the potential confounders (age, experience, education) is related to beginning salaries. Describe your findings.\nDoes seniority play a role in the variation of starting salaries? In what way?\nExamine how the explanatory variables (including sex) are related to each other, if at all. What implications would this have for modeling?\nFit a simple linear regression model with starting salary as the response and education as the sole explanatory variable. Interpret the intercept and slope of this model; also interpret the R-squared value. Is there a significant relationship between education and starting salary?\n\nIntercept:\nSlope:\nR2\nSignificance:\n\nDoes model1 from question 10 meet all linear regression assumptions? List each assumption and how you decided if it was met or not.\nIs a model with all 4 confounding variables better than a model with just education? Justify with an appropriate significance test in addition to summary statistics of model performance.\nYou should have noticed that the term for age was not significant in the model3. What does this imply about age and about future modeling steps?\nThe relationship between experience and beginning salary exhibits some curvature. How might it be interpreted in this context? Determine whether a quadratic term in experience improves a model without curvature.\nBased on model6, what conclusions can be drawn about sex discrimination at Harris Trust? Do these conclusions have to be qualified at all, or are they pretty clear cut? Interpret a 95% confidence interval for the male indicator variable in context to help with your response.\nDo any explanatory variables exhibit an interaction with sex. If so, what are the implications for your answer in (15)?\nOften salary data is logged before analysis. Would you recommend logging starting salary in this study? Support your decision analytically.\nRegardless of your answer to (17), provide an interpretation for the coefficient for the male coefficient in model6a after logging starting salary."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Regression Schedule",
    "section": "",
    "text": "Note: The timeline of topics and assignments might be updated throughout the semester.\n\n\n\n\n\n\n\n\n\nDay\nDate\nTopic\nNotes\nOutline\nProject\nLab\nHomework\nExam\n\n\n\n\n1\n26 Aug\nSyllabus, Chapter 1 - Review MLR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\n27 Aug\nChapter 2 - Likelihoods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n28 Aug\nChapter 3 - Distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\n29 Aug\nChapter 4 - Poisson Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\n30 Aug\nPoisson Regression Practice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\n2 Sep\nChapter 5 - GLMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7\n3 Sep\nChapter 6 - Logistics Regression+\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\n4 Sep\nChapter 7 Correlated Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\n5 Sep\nGLMs Practice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\n6 Sep\nExam\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\n9 Sep\nChapter 8 - Multilevel Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\n10 Sep\nChapter 8 - Multilevel Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13\n11 Sep\nChapter 9 - Two-Level Longitudinal Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14\n12 Sep\nChapter 9 - Two-Level Longitudinal Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\n13 Sep\nMultilevel Model Practice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16\n16 Sep\nPolynomial Regression, Splines, and GAMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n17\n17 Sep\nPolynomial Regression, Splines, and GAMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n18\n18 Sep\nExam",
    "crumbs": [
      "Course Contents",
      "Schedule & Assignments"
    ]
  },
  {
    "objectID": "hw/01_hw_ch1.html",
    "href": "hw/01_hw_ch1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Go to our RStudio Server at http://turing.cornellcollege.edu:8787/\nGo to your class folder you made named ‚ÄúSTA363‚Äù\nCreate a new folder called FirstInitial_Last_Initial_HW with your initials.\n\n\n\n\nEach of your assignments will begin with the following steps.\n\nFinding the instructions on our website: https://stats-tgeorge.github.io/STA363_AdvReg/\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new project. and giving it a sensible name such as homework_1 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw1.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/01_hw_ch1.html#this-one-time",
    "href": "hw/01_hw_ch1.html#this-one-time",
    "title": "Homework 1",
    "section": "",
    "text": "Go to our RStudio Server at http://turing.cornellcollege.edu:8787/\nGo to your class folder you made named ‚ÄúSTA363‚Äù\nCreate a new folder called FirstInitial_Last_Initial_HW with your initials."
  },
  {
    "objectID": "hw/01_hw_ch1.html#every-homework",
    "href": "hw/01_hw_ch1.html#every-homework",
    "title": "Homework 1",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nFinding the instructions on our website: https://stats-tgeorge.github.io/STA363_AdvReg/\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new project. and giving it a sensible name such as homework_1 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw1.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Advanced Regression",
    "section": "",
    "text": "Course Description\nFollowing a second regression course, this class will begin with a review of multiple linear regression, but now using R. New topics will include probability distributions, likelihoods, differentiating binary vs binomial logistic regression, and poisson regression including its variants. The class of generalized linear models will then be presented which unifies all past modeling approaches. All methods are presented using realistic case studies. Conducting and communicating the modeling process including exploratory data analysis, model exploration and selection, and inferences are all emphasized.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-instructor.html",
    "href": "course-instructor.html",
    "title": "Instructor",
    "section": "",
    "text": "Dr.¬†Tyler George (he/him) is a Assistant Professor of Statistics at Cornell College. He received his PhD in Statistics and Analytics from Central Michigan University. During his PhD he also studied mathematics and statistics education. His dissertation work involved creating a new lack of fit test for linear regression models. His interests are broadly in statistics, data science and best pedagogy to teach them.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMonday - Thursday 3:05pm - 4:05pm\nWest 311\n\n\nOther Times by Appointment\nWest 311\n\n\n\nOffice hours are for STUDENTS. Please take advantage of them to get help with class, advising, and/or getting to know your professor! If you miss class, check out course calendar to verify there have been no changes.",
    "crumbs": [
      "Course information",
      "Instructor"
    ]
  },
  {
    "objectID": "course-instructor.html#instructor",
    "href": "course-instructor.html#instructor",
    "title": "Instructor",
    "section": "",
    "text": "Dr.¬†Tyler George (he/him) is a Assistant Professor of Statistics at Cornell College. He received his PhD in Statistics and Analytics from Central Michigan University. During his PhD he also studied mathematics and statistics education. His dissertation work involved creating a new lack of fit test for linear regression models. His interests are broadly in statistics, data science and best pedagogy to teach them.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMonday - Thursday 3:05pm - 4:05pm\nWest 311\n\n\nOther Times by Appointment\nWest 311\n\n\n\nOffice hours are for STUDENTS. Please take advantage of them to get help with class, advising, and/or getting to know your professor! If you miss class, check out course calendar to verify there have been no changes.",
    "crumbs": [
      "Course information",
      "Instructor"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources the course, Introduction to Data Science, offered by the Cornell College Department of Mathematics and Statistics, go to the RStudio Server while on campus and connected to campus internet.\nYour account will be pre-created before the class begins and will use your Cornell College username. The default password will be shared in class and you will need to change it.",
    "crumbs": [
      "Course information",
      "R/RStudio Access"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\nüîó on Cornell College Cluster\n\n\nCourse GitHub organization\nüîó on GitHub\n\n\nGradebook\nüîó on Moodle",
    "crumbs": [
      "Course Contents",
      "Useful links"
    ]
  },
  {
    "objectID": "course-links.html#course-links",
    "href": "course-links.html#course-links",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\nüîó on Cornell College Cluster\n\n\nCourse GitHub organization\nüîó on GitHub\n\n\nGradebook\nüîó on Moodle",
    "crumbs": [
      "Course Contents",
      "Useful links"
    ]
  },
  {
    "objectID": "course-links.html#other-useful-links",
    "href": "course-links.html#other-useful-links",
    "title": "Useful links",
    "section": "Other Useful Links",
    "text": "Other Useful Links\n\nData Wrangling and Viz Interactive Tutorials\nRStudio Cheatsheets\nIntroduction to dplyr\nR Date Examples\nNY Times Cornell College Sign-up\nR for Data Science 2nd Ed\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Course Contents",
      "Useful links"
    ]
  },
  {
    "objectID": "course-links.html#data-links",
    "href": "course-links.html#data-links",
    "title": "Useful links",
    "section": "Data Links",
    "text": "Data Links\n\nTidyTuesday\nR Data Sources for Regression Analysis\nFiveThirtyEight data\nAmazon Registry of Open Data\nOpen data StackExchange\nMicrosoft R Application Window\nData.gov\nUS Census\nNew York City data\nGeorge Mason University Data Link List\nToward Data Science list of Data Sources\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland‚Äôs official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nAndrew G. Reiter Poly Scie Datasets\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\nU.S. Data\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nState of Iowa Open Geospatial Data\nIf you know of others, let me know!",
    "crumbs": [
      "Course Contents",
      "Useful links"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nYou are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in person, so office hours are a valuable resource. I encourage every one of you to take advantage of this resource! Pledge to stop by during office hours at least once during the first few days of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of your professor‚Äôs office hours here.\n\nProfessor Email\nIf you are not available during office hours times or have a questions later in the evening or other times outside of class, email your professor at tgeorge@cornellcollege.edu. If your question involves code - it is very likely you will need to meet with him to get help. Please reach out with any concerns you have during the course!",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\n\nQuantitative Reasoning Studio (QRS)\nThere are times you may need help outside of class or office hours. Or, maybe you need something explained differently. In those instances, I encourage you to visit the Quantitative Reasoning Studio in Cole Library room 322. The Quantitative Reasoning Studio (QRS) offers free tutoring to all students at Cornell College. There will be at least 1 peer tutor who has taken this course and will be able to help you if you arrive at a time they are working. Feel free to email Jessica Johanningmeier at QRS@cornellcollege.edu to ask when the tutor for this class will be available. They often will have a schedule posted on the wall in the studio.\n\n\nQRS Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n3 p.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\n\n\n\nDungy Writing Studio\nFor help with your writing, visit the Dungy Writing Studio. You can make online appointments individually or in groups to get help with items such as your group project. If you have any questions about the studio, email Dungy Writing Studio Director and Director of Fellowships and Scholarships, Laura Farmer, at lfarmer@cornellcollege.edu.\n\n\nWriting Studio Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n1 p.m. - 5 p.m.\n\n\n\n\n\nAcademic Support Services\nThere are a variety of support services offered to all students. See more information at: https://www.cornellcollege.edu/academics/support-services/index.shtml&gt;",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#ebersole-health-and-wellbeing-center",
    "href": "course-support.html#ebersole-health-and-wellbeing-center",
    "title": "Course support",
    "section": "Ebersole Health and Wellbeing Center",
    "text": "Ebersole Health and Wellbeing Center\nThe mission of Cornell College Student Health Services complements the mission of the college by promoting the optimal well-being of students. We do this by:\n\nproviding and coordinating quality health care services\nadvocating for students in their pursuit of health and wellness\npreparing students to be their own health advocates and informed consumers of appropriate health care services\nproviding health education to promote the development of healthy lifestyles\n\nThe Student Health Center is located in the Ebersole Building, directly south of the Thomas Commons. Appointments are preferred. You can schedule an appointment online or by phone at 319-895-4292. Walk-ins will be accommodated as time permits. Appointments with the nurse are free.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#technology-support",
    "href": "course-support.html#technology-support",
    "title": "Course support",
    "section": "Technology Support",
    "text": "Technology Support\nIf you have issues with your computer during the block, IT may be able to help. Please submit a ticket.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "hw/02_hw_ch2.html",
    "href": "hw/02_hw_ch2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_2 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw2.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/02_hw_ch2.html#setup",
    "href": "hw/02_hw_ch2.html#setup",
    "title": "Homework 2",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_2 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw2.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/02_hw_ch2.html#instructions",
    "href": "hw/02_hw_ch2.html#instructions",
    "title": "Homework 2",
    "section": "Instructions",
    "text": "Instructions\nBe sure to include the relevant R code as well as full sentences answering each of the questions (i.e.¬†if I ask for the average, you can output the answer in R but also write a full sentence with the answer). Be sure to frequently save your files!\nData for the homework will be in the STA363_inst_files -&gt; data folder."
  },
  {
    "objectID": "hw/02_hw_ch2.html#exercises",
    "href": "hw/02_hw_ch2.html#exercises",
    "title": "Homework 2",
    "section": "Exercises",
    "text": "Exercises\nAll problems are from The main textbook is: Beyond Multiple Linear Regression by Paul Roback and Julie Legler ‚Äì it is freely available online. Chapters 1-9.. Abbreviated BMLR.\nUse the numbering on the left. The codes are for instructor use (Ex: C1).\n\nExercise 1\n\n(C1) Suppose we plan to use data to estimate one parameter, \\(p_B\\).\n\nWhen using a likelihood to obtain an estimate for the parameter, which is preferred: a large or a small likelihood value? Why?\nThe height of a likelihood curve is the probability of the data for the given parameter. The horizontal axis represents different possible parameter values. Does the area under the likelihood curve for an interval from .25 to .75 equal the probability that the true probability of a boy is between 0.25 and 0.75?\n\n\n\n\nExercise 2\n\n(C2) Suppose the families with an ‚Äúonly child‚Äù were excluded for the Sex Conditional Model. How might the estimates for the three parameters be affected? Would it still be possible to perform a Likelihood Ratio Test to compare the Sex Unconditional and Sex Conditional Models? Why or why not?\n\n\n\nExercise 3\n\n(G2) Case 3 In Case 1 we used hypothetical data with 30 boys and 20 girls. Case 2 was a much larger study with 600 boys and 400 girls. Consider Case 3, a hypothetical data set with 6000 boys and 4000 girls.\n\nUse the methods for Case 1 and Case 2 and determine the MLE for \\(p_B\\) for the case 3 independence model. Compare your result to the MLEs for Cases 1 and 2.\nDescribe how the graph of the log-likelihood for Case 3 would compare to the log-likelihood graphs for Cases 1 and 2.\nCompute the log-likelihood for Case 3. Why is it incorrect to perform an LRT comparing Cases 1, 2, and 3?\n\n\n\n\nExercise 4\n\n(G3) Write out an expression for the likelihood of seeing our NLSY data (5,416 boys and 5,256 girls) if the true probability of a boy is:\n\n\\(p_B=0.5\\)\n\n\\(p_B=0.45\\)\n\n\\(p_B= 0.55\\)\n\n\\(p_B= 0.5075\\)\n\n\n\nCompute the value of the log-likelihood for each of the values of \\(p_B\\) above.\nWhich of these four possibilities, \\(p_B=0.45, p_B=0.5,  p_B=0.55,\\) or \\(p_B=0.5075\\) would be the best estimate of \\(p_B\\) given what we observed (our data)?\n\n\n\n\nExercise 5\n\n(O2) The hot hand in basketball. @Gilovich1985 wrote a controversial but compelling article claiming that there is no such thing as ‚Äúthe hot hand‚Äù in basketball. That is, there is no empirical evidence that shooters have stretches where they are more likely to make consecutive shots, and basketball shots are essentially independent events. One of the many ways they tested for evidence of a ‚Äúhot hand‚Äù was to record sequences of shots for players under game conditions and determine if players are more likely to make shots after made baskets than after misses. For instance, assume we recorded data from one player‚Äôs first 5 three-point attempts over a 5-game period. We can assume games are independent, but we‚Äôll consider two models for shots within a game:\n\nNo Hot Hand (1 parameter): \\(p_B\\) = probability of making a basket (thus \\(1-p_B\\) = probability of not making a basket).\nHot Hand (2 parameters): \\(p_B\\) = probability of making a basket after a miss (or the first shot of a game); \\(p_{B|B}\\) = probability of making a basket after making the previous shot.\n\n\nFill out Table @ref(tab:hothandchp2)‚Äîwrite out the contribution of each game to the likelihood for both models along with the total likelihood for each model.\nGiven that, for the No Hot Hand model, \\(\\textrm{Lik}(p_B)=p_B^{10}(1-p_B)^{15}\\) for the 5 games where we collected data, how do we know that 0.40 (the maximum likelihood estimator (MLE) of \\(p_B\\)) is a better estimate than, say, 0.30?\nFind the MLEs for the parameters in each model, and then use those MLEs to determine if there‚Äôs significant evidence that the hot hand exists.\n\n\n\n\n\n\nData for Open-ended Exercise 2. (B = made basket. M = missed basket.)\n\n\nGame\nFirst 5 shots\nLikelihood (No Hot Hand)\nLikelihood (Hot Hand)\n\n\n\n\n1\nBMMBB\n\n\n\n\n2\nMBMBM\n\n\n\n\n3\nMMBBB\n\n\n\n\n4\nBMMMB\n\n\n\n\n5\nMMMMM\n\n\n\n\nTotal"
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html",
    "href": "labs/01_linear_regression/01_banksalary.html",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "",
    "text": "Since this our first lab, I suggest you get setup for files in the following way:\n\nLog into the course RStudio Server. http://turing.cornellcollege.edu:8787/ Make sure to close out of any projects on the top right corner.\nClick the ‚ÄúFile‚Äù tab in the bottom right corner. Then click ‚ÄúHome‚Äù across the top of the panel.\nIf ones does not exists already, use the ‚Äú+üìÇ‚Äù button to create a new folder and call it ‚ÄúSTA363‚Äù\nCopy project folder called ‚Äú01_linear_regression‚Äù located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file 01_banksalary_fillable.qmd."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html#first-lab-setup",
    "href": "labs/01_linear_regression/01_banksalary.html#first-lab-setup",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "",
    "text": "Since this our first lab, I suggest you get setup for files in the following way:\n\nLog into the course RStudio Server. http://turing.cornellcollege.edu:8787/ Make sure to close out of any projects on the top right corner.\nClick the ‚ÄúFile‚Äù tab in the bottom right corner. Then click ‚ÄúHome‚Äù across the top of the panel.\nIf ones does not exists already, use the ‚Äú+üìÇ‚Äù button to create a new folder and call it ‚ÄúSTA363‚Äù\nCopy project folder called ‚Äú01_linear_regression‚Äù located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file 01_banksalary_fillable.qmd."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html#introduction",
    "href": "labs/01_linear_regression/01_banksalary.html#introduction",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "Introduction",
    "text": "Introduction\nExample: Sex discrimination in bank salaries. In the 1970‚Äôs, Harris Trust was sued for sex discrimination in the salaries it paid its employees. One approach to addressing this issue was to examine the starting salaries of all skilled, entry-level clerical workers between 1965 and 1975. The data is saved under banksalary.csv, and relevant R code can be found in the STA363_inst_files folder on the home directory of the RStudio Server. banksalary.qmd.\nData from skilled entry-level clerical workers at bank being sued for sex discrimination in 1970s (from Statistical Sleuth, Ch 12):\n\nbsal = beginning salary (annual salary at time of hire)\nsal77 = annual salary in 1977\nsex = MALE or FEMALE\nsenior = months since hired\nage = age in months\neduc = years of education\nexper = months of prior work experience\n\nFirst, we will speculate on what we expect to find and then we will perform an analysis using the data.\n\nRead the data in and use aview() to see the data, but do not do anything else with the data on the computer until question 6."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html#questions",
    "href": "labs/01_linear_regression/01_banksalary.html#questions",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "Questions",
    "text": "Questions\n\nIdentify the observational units, the response variable, and explanatory variables.\nGiven the mean starting salary of male workers ($5957) was 16% higher than the mean starting salary of female workers ($5139): Is this enough evidence to conclude sex discrimination exists? If not, what further evidence would you need?\nHow would you expect age, experience, and education to each be related to starting salary?\nWhy might it be important to control for seniority (number of years with the bank) if we are only concerned with the salary when the worker started?\nDo you expect any explanatory variables (including sex) to be closely related to each other? What implications would this have for modeling?\n\nUsing the data‚Ä¶\nOne approach is to construct a good model for beginning salaries while requiring sex as a predictor, to determine the significance of sex after controlling for the other covariates. Then we can explore interactions with sex to see if its effect is consistent across levels of other predictors.\n\nUse the data to address the primary question of interest here using only the beginning salary and sex variables. Be sure to discuss plots and summary statistics first, and then look at test(s) of significance.\nConstruct plots to investigate how each of the potential confounders (age, experience, education) is related to beginning salaries. Describe your findings.\nDoes seniority play a role in the variation of starting salaries? In what way?\nExamine how the explanatory variables (including sex) are related to each other, if at all. What implications would this have for modeling?\nFit a simple linear regression model with starting salary as the response and education as the sole explanatory variable. Interpret the intercept and slope of this model; also interpret the R-squared value. Is there a significant relationship between education and starting salary?\n\nIntercept:\nSlope:\nR2\nSignificance:\n\nDoes model1 from question 10 meet all linear regression assumptions? List each assumption and how you decided if it was met or not.\nIs a model with all 4 confounding variables better than a model with just education? Justify with an appropriate significance test in addition to summary statistics of model performance.\nYou should have noticed that the term for age was not significant in the model3. What does this imply about age and about future modeling steps?\nThe relationship between experience and beginning salary exhibits some curvature. How might it be interpreted in this context? Determine whether a quadratic term in experience improves a model without curvature.\nBased on model6, what conclusions can be drawn about sex discrimination at Harris Trust? Do these conclusions have to be qualified at all, or are they pretty clear cut? Interpret a 95% confidence interval for the male indicator variable in context to help with your response.\nDo any explanatory variables exhibit an interaction with sex. If so, what are the implications for your answer in (15)?\nOften salary data is logged before analysis. Would you recommend logging starting salary in this study? Support your decision analytically.\nRegardless of your answer to (17), provide an interpretation for the coefficient for the male coefficient in model6a after logging starting salary."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html#code",
    "href": "labs/01_linear_regression/01_banksalary.html#code",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "Code",
    "text": "Code\n\nlibrary(mosaic)\nlibrary(skimr)   # may have to install\nlibrary(dplyr)  \nlibrary(ggplot2)\nlibrary(gridExtra)\nbank &lt;- read.csv(\"data/banksalary.csv\")\n\nData from skilled entry-level clerical workers at bank being sued for sex discrimination in 1970s (from Statistical Sleuth, Ch 12):\n\nbsal = beginning salary (annual salary at time of hire)\nsal77 = annual salary in 1977\nsex = MALE or FEMALE\nsenior = months since hired\nage = age in months\neduc = years of education\nexper = months of prior work experience\n\n\n# Examine data frame\nhead(bank)       # print first 6 rows\n\n# Generate relevant summary statistics for response variable\nfavstats(~ bsal, data = bank)\n\n# Look at marginal relationship between sex and beginning salary\n\n# Three options for getting summary statistics\nfavstats(~ bsal | sex, data = bank)\n\nbank |&gt;\n  group_by(sex) |&gt;\n  summarize(mean = mean(bsal),\n            median = median(bsal),\n            sd = sd(bsal),\n            iqr = IQR(bsal),\n            n = n())\n\n# Doesn't seem to render as a pdf\n#bank |&gt;\n#  group_by(sex) |&gt;\n#  skim()\n\n# Several options for plotting 1 categorical and 1 numeric variable\nboxplot(bsal ~ sex, ylab=\"Beginning salary\", data = bank)\nbwplot(sex ~ bsal, data = bank)\nggplot(bank, aes(x = sex, y = bsal)) +\n  geom_boxplot() + coord_flip()\nggplot(data = bank, mapping = aes(x = bsal, y = ..density..)) + \n  geom_freqpoly(mapping = aes(colour = sex), binwidth = 250)\nggplot(data = bank, mapping = aes(x = bsal, y = ..density..)) + \n  geom_density(mapping = aes(colour = sex))\nggplot(bank, aes(x=bsal, fill=sex)) +\n  geom_density(alpha=0.4)\nggplot(bank, aes(x = sex, y = bsal)) +\n  geom_violin() \nggplot(data = bank) + \n  geom_histogram(mapping = aes(x = bsal)) + \n  facet_wrap(~ sex, nrow = 2)\nggplot(data = bank) + \n  geom_histogram(mapping = aes(x = bsal, y = ..density..)) + \n  facet_wrap(~ sex, nrow = 2)\n\n# Initial analysis of sex vs salary, ignoring other covariates\nt.test(bsal ~ sex, data = bank)\n\nmodel1 = lm(bsal ~ sex, data = bank)\nsummary(model1)\n\nbank &lt;- bank |&gt;\n  mutate(male = ifelse(sex==\"MALE\",1,0))   # create our own indicator for sex\nt.test(bsal ~ male, var.equal = TRUE, data = bank)\n\n# How are covariates related to response?\nggplot(bank, aes(y = bsal, age)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, exper)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, educ)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, senior)) + \n  geom_point() + \n  geom_smooth(method = lm)\n\n# How are explanatory variables related to each other?\nbank0 &lt;- bank |&gt; select(bsal, age, exper, educ, senior, male)\npairs(bank0)     # matrix of scatterplots \ncor(bank0)       # matrix of correlations\n\n# How are explanatory variables related to sex?\nfavstats(~ age | sex, data = bank)\nggplot(bank, aes(x = sex, y = age)) +\n  geom_boxplot() + coord_flip()\n\nfavstats(~ exper | sex, data = bank)\nggplot(bank, aes(x = sex, y = exper)) +\n  geom_boxplot() + coord_flip()\n\nfavstats(~ educ | sex, data = bank)\nggplot(bank, aes(x = sex, y = educ)) +\n  geom_boxplot() + coord_flip()\n\nfavstats(~ senior | sex, data = bank)\nggplot(bank, aes(x = sex, y = senior)) +\n  geom_boxplot() + coord_flip()\n\n# Fit linear regression with single predictor (education)\nmodel2 = lm(bsal ~ educ, data = bank)\nsummary(model2)\n\n\n# Residual plots - run off the page unless redo margins\npar(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(0.5,0.5,0.5,0))\nplot(model2)   # Generate residual diagnostic plots\npar(mfrow=c(1,1))\n\n\n# Fit multiple regression model with four predictors\nmodel3 = lm(bsal ~ senior + age + educ + exper, data = bank)\nsummary(model3)\nanova(model2, model3, test=\"F\")\n\n# Examine AIC and BIC scores (lower is better)\nAIC(model2)                     # AIC-model2\nAIC(model3)                     # AIC-model3\nAIC(model2, k=log(nrow(bank)))  # BIC-model2\nAIC(model3, k=log(nrow(bank)))  # BIC-model3\n\n# Fit linear regression with experience\nmodel4 = lm(bsal ~ exper, data = bank)\nsummary(model4)\n\n\n# Residual plots - run off the page unless redo margins\npar(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(0.5,0.5,0.5,0))\nplot(model4)   # Generate residual diagnostic plots\npar(mfrow=c(1,1))\n\n\nbank &lt;- bank |&gt;\n  mutate(exper2 = exper^2)\nmodel5 = lm(bsal ~ exper + exper2, data = bank)\nsummary(model5)\n\n\n# Residual plots - run off the page unless redo margins\npar(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(0.5,0.5,0.5,0))\nplot(model5)   # Generate residual diagnostic plots\npar(mfrow=c(1,1))\n\n\n# One potential final model\nmodel6 = lm(bsal ~ senior + educ + exper + male, data = bank)\nsummary(model6)\n\n# Construct 95% CIs for model coefficients the hard way...\nbetas = summary(model6)$coef[,1]   # store model betas\nSEs = summary(model6)$coef[,2]    # store SEs of betas\ntstar = qt(.975,model6$df)\nlb = betas - tstar*SEs\nub = betas + tstar*SEs\ncbind(lb,ub)\n\n# ... or more simply:\nconfint(model6)\n\n# Investigate interactions with sex\nggplot(bank, aes(y = bsal, x = age, color = sex)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, x = exper, color = sex)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, x = educ, color = sex)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, x = senior, color = sex)) + \n  geom_point() + \n  geom_smooth(method = lm)\n\n# Examine interaction between sex and education\nmodel7 = lm(bsal ~ educ + male + educ:male, data = bank)\nsummary(model7)\n\n\n# Should beginning salary be log transformed?\nbank &lt;- bank |&gt; \n  mutate(logbsal = log(bsal))\nhist1 &lt;- ggplot(bank, aes(bsal)) + geom_histogram(bins = 10)\nhist2 &lt;- ggplot(bank, aes(logbsal)) + geom_histogram(bins = 10)\ngrid.arrange(hist1, hist2, ncol=2)\n\n# Look at marginal relationship between sex and beginning salary\nmodel6a = lm(logbsal ~ senior + educ + exper + male, data = bank)\nsummary(model6a)\n\n\n# Residual plots - run off the page unless redo margins\npar(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(0.5,0.5,0.5,0))\nplot(model6a)   # Generate residual diagnostic plots\npar(mfrow=c(1,1))\n\n\n# Bonus code: to help with HW1 when looking at 2 categorical variables\nytable &lt;- tally(~ sex + educ, data = bank)\nytable\nmosaicplot(ytable, color = c(\"blue\", \"light blue\"))\nprop.table(ytable, 1)\n\n# Other ways to visualize two categorical variables\nbank &lt;- bank |&gt;\n  mutate(education = ifelse(educ &lt; 12, \"No high school\", \"High school\"),\n         education = ifelse(educ &gt; 12, \"Some college\", education))\nggplot(data = bank) + \n  geom_bar(mapping = aes(x = sex, fill = education)) \nggplot(data = bank) + \n  geom_bar(mapping = aes(x = sex, fill = education), position = \"fill\") \nlibrary(ggmosaic)  # need to have ggmosaic package installed\nggplot(data = bank) +\n   geom_mosaic(aes(x = product(education, sex), fill=education), na.rm = TRUE)\n\n# Other ways to summarize relationship between two categorical variables\nbank |&gt;\n  group_by(sex, education) |&gt;\n  summarise (n = n()) |&gt;\n  mutate(freq = n / sum(n))"
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html",
    "href": "labs/02_likelihood/02_likelihood.html",
    "title": "Chapter 2 - Likelihoods",
    "section": "",
    "text": "Copy the project lab folder located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file qmd file included."
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html#lab-setup",
    "href": "labs/02_likelihood/02_likelihood.html#lab-setup",
    "title": "Chapter 2 - Likelihoods",
    "section": "",
    "text": "Copy the project lab folder located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file qmd file included."
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html#introduction",
    "href": "labs/02_likelihood/02_likelihood.html#introduction",
    "title": "Chapter 2 - Likelihoods",
    "section": "Introduction",
    "text": "Introduction\nDoes having boys or girls run in the family? Using demographic data from the National Longitudinal Survey of Youth, can we identify biases in sex composition patterns of children? The data is found in Table 2 in the Rodgers and Doughty (2001) article, and relevant R code can be found under below."
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html#questions",
    "href": "labs/02_likelihood/02_likelihood.html#questions",
    "title": "Chapter 2 - Likelihoods",
    "section": "Questions",
    "text": "Questions\n\nModel 1 ‚Äì Sex Unconditional Model. Each child is independent of the others, and there is a constant probability ( ) that a child is a boy.\n\nConsider a small example with 3 families with compositions of children given by BBG, GBG, and GG.\nFind the maximum likelihood estimator (MLE) for by:\n\n\nConducting a numerical search in R for the largest likelihood over a fine grid of values 0-1.\nConducting a numerical search in R for the largest log-likelihood between 0 and 1. Illustrate the process graphically, and report the maximum value of the likelihood and log-likelihood functions. Does it make sense that both methods would agree (and agree with the mathematical approach)?\n\n\nApply Model 1 to the NLSY data (families in Table 2 with 3 or fewer children). Find the MLE for by adapting the R code for (1).\n\n\n\nModel 2 ‚Äì Sex Conditional Model. The probability of having a boy depends on whether you‚Äôve had boys previously, so Model 2 will have three parameters:\n= probability of a boy when previously have had an equal number of boys and girls (neutral)\n= probability of a boy when previously have had more boys than girls (boy bias)\n= probability of a boy when previously have had more girls than boys (girl bias)\n\nWrite out the likelihood function given Model 2 for the small set of data in (1). [You could also try BGG, GGB, BBB just for fun.]"
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html#code",
    "href": "labs/02_likelihood/02_likelihood.html#code",
    "title": "Chapter 2 - Likelihoods",
    "section": "Code",
    "text": "Code\n\nModel 1: Sex Unconditional Model\nAssumes the sex for each birth is independent of other births\n\n# Evaluate small set of possible values of pb\npb &lt;- c(.3, .35, .375, .4, .45)  # possible values for prob a boy is born\nlik &lt;- pb^3 * (1 - pb)^5         # likelihood of getting observed data\ncbind(pb, lik)                   # print table of results\nplot(pb, lik, xlab = \"possible values of pb\", ylab = \"Likelihood\")\nmax(lik)                         # maximum likelihood over 5 values of pb\npb[lik == max(lik)]              # value of pb where likelihood maximized\n\n# Evaluate finer grid of possible values of pb\npb &lt;- seq(0, 1, length = 1001)   # possible values for prob a boy is born\nlik &lt;- pb^3 * (1 - pb)^5         # likelihood of getting observed data\nplot(pb, lik, xlab = \"possible values of pb\", ylab = \"Likelihood\", type = \"l\")\nmax(lik)                         # maximum likelihood over 1001 values of pb\npb[lik == max(lik)]              # value of pb where likelihood maximized\n\nloglik &lt;- 3 * log(pb) + 5 * log(1 - pb)      # find log likelihoods\nplot(pb, loglik, xlab = \"possible values of pb\", ylab = \"Loglikelihood\", \n     type = \"l\")\nmax(loglik)                    # maximum loglikelihood over 1001 values of pb\npb[loglik == max(loglik)]      # likelihood and loglikelihood max at same spot\nmle_pb_m1_small &lt;- pb[loglik == max(loglik)]\nmax_logL_m1_small &lt;- max(loglik)\n\n# Create ggplot of likelihood and log-likelihood functions\nmodel1grid &lt;- data.frame(pb = pb, lik1 = lik, loglik1 = loglik)\nggplot(data = model1grid, aes(x = pb, y = lik1)) +\n  geom_line() +\n  labs(x = \"possible values of pb\", y = \"Likelihood\")\nggplot(data = model1grid, aes(x = pb, y = loglik1)) +\n  geom_line() +\n  labs(x = \"possible values of pb\", y = \"log Likelihood\")\n\n\n# Apply Model 1 to NLSY data (for families with 3 or fewer children)\npb &lt;- seq(0, 1, length = 10001)   # possible values for prob a boy is born\nlik &lt;- pb^5416 * (1 - pb)^5256    # likelihood (too small)\nmax(lik)\nsummary(lik)  \n\n# loglikelihood of getting observed data\nloglik &lt;- 5416 * log(pb) + 5256 * log(1 - pb)   \nplot(pb, loglik, xlab = \"possible values of pb\", ylab = \"Loglikelihood\", \n     type = \"l\")\nplot(pb[loglik &gt; (-7500)], loglik[loglik &gt; (-7500)],\n  xlab = \"possible values of pb\", \n  ylab = \"Loglikelihood\", type = \"l\")  # zoom plot\nmax(loglik)                 # maximum loglikelihood over all values of pb\npb[loglik == max(loglik)]   # MLE of pb\nmle_pb_m1_nlsy &lt;- pb[loglik == max(loglik)]\nmax_logL_m1_nlsy &lt;- max(loglik)\n\n# Create ggplot of likelihood and log-likelihood functions\nmodel1grid &lt;- data.frame(pb = pb, lik1 = lik, loglik1 = loglik)\nggplot(data = model1grid, aes(x = pb, y = lik1)) +\n  geom_line() +\n  labs(x = \"possible values of pb\", y = \"Likelihood\")\nggplot(data = model1grid, aes(x = pb, y = loglik1)) +\n  geom_line() +\n  labs(x = \"possible values of pb\", y = \"log Likelihood\")\nmodel1grid |&gt;\n  filter(loglik1 &gt; (-7500)) |&gt;\n  ggplot(aes(x = pb, y = loglik1)) +\n    geom_line() +\n    labs(x = \"possible values of pb with loglik above -7500\", \n         y = \"log Likelihood\")\n\n\n\nModel 2: Sex Conditional Model (small 3 famly data set)\nAssumes probability of having a boy depends on whether you‚Äôve had boys previously\n\n# Find MLEs with 3-dimensional grid search\npbb &lt;- seq(0, 1, length = 101)\npbg &lt;- seq(0, 1, length = 101)\npbn &lt;- seq(0, 1, length = 101)\nmodel2_grid &lt;- expand.grid(pbb = pbb, pbg = pbg, pbn = pbn)\n\nlik &lt;- model2_grid$pbn^1 * (1 - model2_grid$pbn)^3 * model2_grid$pbb^1 * \n  (1 - model2_grid$pbb)^1 * model2_grid$pbg^1 * (1 - model2_grid$pbg)^1\nloglik &lt;- 1 * log(model2_grid$pbn) + 3 * log(1 - model2_grid$pbn) + \n  1 * log(model2_grid$pbb) + 1 * log(1 - model2_grid$pbb) + \n  1 * log(model2_grid$pbg) + 1 * log(1 - model2_grid$pbg)\n\n# Print results\nmax(lik)        # maximum likelihood over all combos of pbb, pbg, pbn\nmax(loglik)     # maximum loglikelihood over all combos of pbb, pbg, pbn\n\nmodel2_grid$pbb[loglik == max(loglik)]   # MLE of pbb\nmodel2_grid$pbg[loglik == max(loglik)]   # MLE of pbg\nmodel2_grid$pbn[loglik == max(loglik)]   # MLE of pbn\n\n# Store results\nmle_pbb_m2_small &lt;- model2_grid$pbb[loglik == max(loglik)]   # MLE of pbb\nmle_pbg_m2_small &lt;- model2_grid$pbg[loglik == max(loglik)]   # MLE of pbg\nmle_pbn_m2_small &lt;- model2_grid$pbn[loglik == max(loglik)]   # MLE of pbn\n\nmax_L_m2_small &lt;- max(lik)\nmax_logL_m2_small &lt;- max(loglik)\n\n\n\nModel comparisons - Model 1 vs.¬†Model 2\n\nlrt &lt;- 2 * (max_logL_m2_small - max_logL_m1_small)   \nlrt                       # likelihood ratio test statistic\n1 - pchisq(lrt, df = 2)   # p-value for testing Ho: no diff between Models 1&2\n\n# AIC and BIC values for Models 1 and 2\naic1 &lt;- -2 * max_logL_m1_small + 2 * 1\naic1\nbic1 &lt;- -2 * max_logL_m1_small + log(8) * 1\nbic1\naic2 &lt;- -2 * max_logL_m2_small + 2 * 3\naic2\nbic2 &lt;- -2 * max_logL_m2_small + log(8) * 3\nbic2"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Class Project",
    "section": "",
    "text": "You will be analyzing a dataset using regression analysis and a classification analysis.\nCollaboration: You can work individually or in groups of up to 3.\nAs one of my past professors liked to say, ‚ÄúKeep it Simple Stupid (KISS)‚Äù"
  },
  {
    "objectID": "project.html#part-1-research-questions-and-data",
    "href": "project.html#part-1-research-questions-and-data",
    "title": "Class Project",
    "section": "Part 1: Research Questions and Data",
    "text": "Part 1: Research Questions and Data\n\nDetermine a topic\nFind data that goes with that topic. See HERE.\n\n\nMust have at least 5 variables that may be useful in a classification and/or regression model.\n\n\nClean and prepare that data.\nWrite two research questions that you will use that data to investigate.\n\n\nOne question that can be answered with regression; make clear the outcome variable and its units.\nOne question that can be answered with classification; make clear the outcome variable and its possible categories.\n\n\nSubmit a project-proposal_last_names.html document that includes\n\n\nsource or sources of your data\na glimpse of your data (run glimpse())\nvariable definitions\nYour research questions\n\nMoodle link: HERE"
  },
  {
    "objectID": "project.html#part-2-eda",
    "href": "project.html#part-2-eda",
    "title": "Class Project",
    "section": "Part 2: EDA",
    "text": "Part 2: EDA\n\nConduct a full EDA on your dataset including any variables being considered for either research question. Minimally this should include the following. All included graphs/tables must have comments and discussion.\n\n\nClearly describe what the cases in the final clean dataset represent.\nWho collected the data? When, why, and how? Answer as much of this as the available information allows.\nUnivariate distributions of all variables.\nGraphs that specifically compare potential predictors to the variables that will be your response variables.\n\n\nSubmit a eda_last_names.html document to Moodle HERE."
  },
  {
    "objectID": "project.html#part-3-modeling",
    "href": "project.html#part-3-modeling",
    "title": "Class Project",
    "section": "Part 3: Modeling",
    "text": "Part 3: Modeling\nThe following should be included in your modeling report (generated from a Quarto file, or files).\n\nRegression\n\nRegression: Methods\n\nDescribe the models used.\nDescribe what you did to evaluate models.\n\nIndicate how you estimated quantitative evaluation metrics.\nIndicate what plots you used to evaluate models.\n\nDescribe the goals / purpose of the methods used in the overall context of your research investigations.\n\n\n\nRegression: Results\n\nSummarize your final model and justify your model choice (see below for ways to justify your choice).\n\nCompare the different models in light of evaluation metrics, plots, variable importance, and data context.\nDisplay evaluation metrics for different models in a clean, organized way. This display should include both the estimated CV metric as well as its standard deviation.\nBroadly summarize conclusions from looking at these CV evaluation metrics and their measures of uncertainty.\nSummarize conclusions from residual plots from initial models (don‚Äôt have to display them though).\n\nShow and interpret some representative examples of residual plots for your final model. Does the model show acceptable results in terms of any systematic biases?\n\n\n\nRegression: Conclusions\n\nInterpret you final model (show plots of estimated non-linear functions, or slope coefficients) for important predictors, and provide some general interpretations of what you learn from these\nInterpret evaluation metric(s) for the final model in context with units. Does the model show an acceptable amount of error?\nSummarization should show evidence of acknowledging the data context in thinking about the sensibility of these results.\n\n\n\n\nClassification\n\nClassification: Methods\n\nIndicate at least 2 different methods used to answer your classification research question.\n\nDescribe what you did to evaluate the models explored.\nIndicate how you estimated quantitative evaluation metrics.\n\nDescribe the goals / purpose of the methods used in the overall context of your research investigations.\n\n\n\nClassification: Results\n\nSummarize your final model and justify your model choice (see below for ways to justify your choice).\n\nCompare the different classification models tried in light of evaluation metrics, variable importance, and data context.\nDisplay evaluation metrics for different models in a clean, organized way. This display should include both the estimated metric as well as its standard deviation. (This won‚Äôt be available from OOB error estimation. If using OOB, don‚Äôt worry about reporting the SD.)\nBroadly summarize conclusions from looking at these evaluation metrics and their measures of uncertainty.\n\n\n\n\nClassification: Conclusions\n\nInterpret evaluation metric(s) for the final model in context. Does the model show an acceptable amount of error?\n\nIf using OOB error estimation, display the test (OOB) confusion matrix, and use it to interpret the strengths and weaknesses of the final model.\n\nSummarization should show evidence of acknowledging the data context in thinking about the sensibility of these results.\n\n\n\n\nSubmit\nSubmit one (or two) model_last_names.html document(s) with your analysis from the parts above. Submit on Moodle HERE."
  },
  {
    "objectID": "project.html#part-4-tell-people-about-it.",
    "href": "project.html#part-4-tell-people-about-it.",
    "title": "Class Project",
    "section": "Part 4: Tell people about it.",
    "text": "Part 4: Tell people about it.\nA 5-10 minute video presentation of your project. (Recording the presentation over Zoom is a good option for creating the video. You can record to your computer or to the cloud.)\n\nUpload the video to Google Drive.\nAll team members should have an equal speaking role in the presentation.\n\nIn order to record your presentation,\n\nStart a Zoom meeting and invite your project mates.\nOne of your share your screen with presentation slides (recommended: Quarto Presentation, Google Slides, or Powerpoint).\nPlease have everyone turn your video on so that we can see who is speaking.\nWhen you are ready to start, the host of the meeting (who ever started the meeting) can click Record on this Computer. I highly recommend that someone else start a timer so that you can make sure you keep the presentation to 10 minutes max.\nStart presenting!\nYou can Pause the recording, as needed, and then press start recording again.\nWhen you have finished recording, you can press Stop Recording. When you end the meeting, the recording (an mp4 file) will be downloaded to the computer of the individual who pressed Record.\nUpload the video to Google Drive.\n\nWe will watch these in class!\nSource: Brianna Heggeseth, STA 253"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html",
    "href": "slides/02_likelihoods_ch2_o.html",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "",
    "text": "library(tidyverse)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#setup",
    "href": "slides/02_likelihoods_ch2_o.html#setup",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "",
    "text": "library(tidyverse)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#learning-goals",
    "href": "slides/02_likelihoods_ch2_o.html#learning-goals",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Learning goals",
    "text": "Learning goals\n\nDescribe the concept of a likelihood\nConstruct the likelihood for a simple model\nDefine the Maximum Likelihood Estimate (MLE) and use it to answer an analysis question\nIdentify three ways to calculate or approximate the MLE and apply these methods to find the MLE for a simple model\nUse likelihoods to compare models (next week)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#what-is-the-likelihood",
    "href": "slides/02_likelihoods_ch2_o.html#what-is-the-likelihood",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "What is the likelihood?",
    "text": "What is the likelihood?\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values).\n\nUnlike Ordinary Least Squares (OLS), they do not require the responses be independent, identically distributed, and normal (iidN)\nThey are not the same as probability functions\n\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#fouls-in-college-basketball-games",
    "href": "slides/02_likelihoods_ch2_o.html#fouls-in-college-basketball-games",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\nThe data set 04-refs.csv includes 30 randomly selected NCAA men‚Äôs basketball games played in the 2009 - 2010 season.\nWe will focus on the variables foul1, foul2, and foul3, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.\n\nH: Foul was called on the home team\nV: Foul was called on the visiting team\n\n. . .\nWe are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.\n\n[The dataset was derived from basektball0910.csv used in BMLR Section 11.2"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#fouls-in-college-basketball-games-1",
    "href": "slides/02_likelihoods_ch2_o.html#fouls-in-college-basketball-games-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\n\nrefs &lt;- read_csv(\"data/04-refs.csv\")\nrefs %&gt;% slice(1:5) %&gt;% kable()\n\n\n\n\ngame\ndate\nvisitor\nhometeam\nfoul1\nfoul2\nfoul3\n\n\n\n\n166\n20100126\nCLEM\nBC\nV\nV\nV\n\n\n224\n20100224\nDEPAUL\nCIN\nH\nH\nV\n\n\n317\n20100109\nMARQET\nNOVA\nH\nH\nH\n\n\n214\n20100228\nMARQET\nSETON\nV\nV\nH\n\n\n278\n20100128\nSETON\nSFL\nH\nV\nV\n\n\n\n\n\nWe will treat the games as independent in this analysis."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#different-likelihood-models",
    "href": "slides/02_likelihoods_ch2_o.html#different-likelihood-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Different likelihood models",
    "text": "Different likelihood models\nModel 1 (Unconditional Model): What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\nModel 2 (Conditional Model):\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?\n\n. . .\nUltimately we want to decide which model is better."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#exploratory-data-analysis",
    "href": "slides/02_likelihoods_ch2_o.html#exploratory-data-analysis",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\nrefs %&gt;%\ncount(foul1, foul2, foul3) %&gt;% kable()\n\n\n\n\nfoul1\nfoul2\nfoul3\nn\n\n\n\n\nH\nH\nH\n3\n\n\nH\nH\nV\n2\n\n\nH\nV\nH\n3\n\n\nH\nV\nV\n7\n\n\nV\nH\nH\n7\n\n\nV\nH\nV\n1\n\n\nV\nV\nH\n5\n\n\nV\nV\nV\n2\n\n\n\n\n\n\nThere are\n\n46 total fouls on the home team\n44 total fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-1-unconditional-model",
    "href": "slides/02_likelihoods_ch2_o.html#model-1-unconditional-model",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Unconditional model",
    "text": "Model 1: Unconditional model\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihood-1",
    "href": "slides/02_likelihoods_ch2_o.html#likelihood-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood",
    "text": "Likelihood\nLet \\(p_H\\) be the probability the referees call a foul on the home team.\nThe likelihood for a single observation\n\\[Lik(p_H) = p_H^{y_i}(1 - p_H)^{n_i - y_i}\\]\nWhere \\(y_i\\) is the number of fouls called on the home team.\n(In this example, we know \\(n_i = 3\\) for all observations.)\n. . .\nExample\nFor a single game where the first three fouls are \\(H, H, V\\), then\n\\[Lik(p_H) = p_H^{2}(1 - p_H)^{3 - 2} = p_H^{2}(1 - p_H)\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-1-likelihood-contribution",
    "href": "slides/02_likelihoods_ch2_o.html#model-1-likelihood-contribution",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Likelihood contribution",
    "text": "Model 1: Likelihood contribution\n\n\n\nFoul1\nFoul2\nFoul3\nn\nLikelihood Contribution\n\n\n\n\nH\nH\nH\n3\n\\(p_H^3\\)\n\n\nH\nH\nV\n2\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nH\n3\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nH\n5\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nV\n2\n\\((1 - p_H)^3\\)\n\n\n\n. . .\nFill in A and B."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-1-likelihood-function",
    "href": "slides/02_likelihoods_ch2_o.html#model-1-likelihood-function",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Likelihood function",
    "text": "Model 1: Likelihood function\nBecause the observations (the games) are independent, the likelihood is\n\\[Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}\\]\nWe will use this function to find the maximum likelihood estimate (MLE). The MLE is the value between 0 and 1 where we are most likely to see the observed data."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#visualizing-the-likelihood",
    "href": "slides/02_likelihoods_ch2_o.html#visualizing-the-likelihood",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100\nlik &lt;- p^46 *(1 -p)^44\n\nx &lt;- tibble(p = p, lik = lik)\nggplot(data = x, aes(x = p, y = lik)) + \n  geom_point() + \n  geom_line() +\n  labs(y = \"Likelihood\",\n       title = \"Likelihood of p_H\")"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#q-what-is-your-best-guess-for-the-mle-hatp_h",
    "href": "slides/02_likelihoods_ch2_o.html#q-what-is-your-best-guess-for-the-mle-hatp_h",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: What is your best guess for the MLE, \\(\\hat{p}_H\\)?",
    "text": "Q: What is your best guess for the MLE, \\(\\hat{p}_H\\)?\nA. 0.489\nB. 0.500\nC. 0.511\nD. 0.556"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-maximum-likelihood-estimate",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-maximum-likelihood-estimate",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the maximum likelihood estimate",
    "text": "Finding the maximum likelihood estimate\nThere are three primary ways to find the MLE\n. . .\n‚úÖ Approximate using a graph\n. . .\n‚úÖ Numerical approximation\n. . .\n‚úÖ Using calculus"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#approximate-mle-from-a-graph",
    "href": "slides/02_likelihoods_ch2_o.html#approximate-mle-from-a-graph",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Approximate MLE from a graph",
    "text": "Approximate MLE from a graph"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#find-the-mle-using-numerical-approximation",
    "href": "slides/02_likelihoods_ch2_o.html#find-the-mle-using-numerical-approximation",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Find the MLE using numerical approximation",
    "text": "Find the MLE using numerical approximation\nSpecify a finite set of possible values the for \\(p_H\\) and calculate the likelihood for each value\n\n# write an R function for the likelihood\nref_lik &lt;- function(ph) {\n  ph^46 *(1 - ph)^44\n}\n\n\n# use the optimize function to find the MLE\noptimize(ref_lik, interval = c(0,1), maximum = TRUE)\n\n$maximum\n[1] 0.5111132\n\n$objective\n[1] 8.25947e-28"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#find-mle-using-calculus",
    "href": "slides/02_likelihoods_ch2_o.html#find-mle-using-calculus",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\nFind the MLE by taking the first derivative of the likelihood function.\nThis can be tricky because of the Product Rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood)\n\n. . .\n\n\n\n\n\n\n\n\n\n. . .\nSince calculus is not a pre-req, we will forgo this quest."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-2-conditional-model",
    "href": "slides/02_likelihoods_ch2_o.html#model-2-conditional-model",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Conditional model",
    "text": "Model 2: Conditional model\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-2-likelihood-contributions",
    "href": "slides/02_likelihoods_ch2_o.html#model-2-likelihood-contributions",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\nNow let‚Äôs assume fouls are not independent within each game. We will specify this dependence using conditional probabilities.\n\nConditional probability: \\(P(A|B) =\\) Probability of \\(A\\) given \\(B\\) has occurred\n\n\n. . .\nDefine new parameters:\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-2-likelihood-contributions-1",
    "href": "slides/02_likelihoods_ch2_o.html#model-2-likelihood-contributions-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\n\n\n\n\n\n\n\n\n\nFoul1\nFoul2\nFoul3\nn\nLikelihood Contribution\n\n\n\n\nH\nH\nH\n3\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(p_{H\\vert H Bias}) = (p_{H\\vert N})(p_{H\\vert H Bias})^2\\)\n\n\nH\nH\nV\n2\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(1 - p_{H\\vert H Bias})\\)\n\n\nH\nV\nH\n3\n\\((p_{H\\vert N})(1 - p_{H\\vert H Bias})(p_{H\\vert N}) = (p_{H\\vert N})^2(1 - p_{H\\vert H Bias})\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\((1 - p_{H\\vert N})(p_{H\\vert V Bias})(1 - p_{H\\vert N}) = (1 - p_{H\\vert N})^2(p_{H\\vert V Bias})\\)\n\n\nV\nV\nH\n5\n\\((1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(p_{H\\vert V Bias})\\)\n\n\nV\nV\nV\n2\n\\(\\begin{aligned}&(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(1-p_{H\\vert V Bias})\\\\ &=(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})^2\\end{aligned}\\)\n\n\n\nFill in A and B"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihood-function",
    "href": "slides/02_likelihoods_ch2_o.html#likelihood-function",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood function",
    "text": "Likelihood function\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n(Note: The exponents sum to 90, the total number of fouls in the data)\n. . .\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#q-if-fouls-within-a-game-are-independent-how-would-you-expect-hatp_h-hatp_hvert-h-bias-and-hatp_hvert-v-bias-to-compare",
    "href": "slides/02_likelihoods_ch2_o.html#q-if-fouls-within-a-game-are-independent-how-would-you-expect-hatp_h-hatp_hvert-h-bias-and-hatp_hvert-v-bias-to-compare",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: If fouls within a game are independent, how would you expect \\(\\hat{p}_H\\), \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H\\vert V Bias}\\) to compare?",
    "text": "Q: If fouls within a game are independent, how would you expect \\(\\hat{p}_H\\), \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H\\vert V Bias}\\) to compare?\n\n\\(\\hat{p}_H\\) is greater than \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\n\\(\\hat{p}_{H\\vert H Bias}\\) is greater than \\(\\hat{p}_H\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\n\\(\\hat{p}_{H\\vert V Bias}\\) is greater than \\(\\hat{p}_H\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\nThey are all approximately equal."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#q-if-there-is-a-tendency-for-referees-to-call-a-foul-on-the-team-that-already-has-more-fouls-how-would-you-expect-hatp_h-and-hatp_hvert-h-bias-to-compare",
    "href": "slides/02_likelihoods_ch2_o.html#q-if-there-is-a-tendency-for-referees-to-call-a-foul-on-the-team-that-already-has-more-fouls-how-would-you-expect-hatp_h-and-hatp_hvert-h-bias-to-compare",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: If there is a tendency for referees to call a foul on the team that already has more fouls, how would you expect \\(\\hat{p}_H\\) and \\(\\hat{p}_{H\\vert H Bias}\\) to compare?",
    "text": "Q: If there is a tendency for referees to call a foul on the team that already has more fouls, how would you expect \\(\\hat{p}_H\\) and \\(\\hat{p}_{H\\vert H Bias}\\) to compare?\n\n\\(\\hat{p}_H\\) is greater than \\(\\hat{p}_{H\\vert H Bias}\\)\n\\(\\hat{p}_{H\\vert H Bias}\\) is greater than \\(\\hat{p}_H\\)\nThey are approximately equal."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihoods",
    "href": "slides/02_likelihoods_ch2_o.html#likelihoods",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihoods",
    "text": "Likelihoods\nModel 1 (Unconditional Model)\n\n\\(p_H\\): probability of a foul being called on the home team\n\n. . .\nModel 2 (Conditional Model)\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihoods-1",
    "href": "slides/02_likelihoods_ch2_o.html#likelihoods-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihoods",
    "text": "Likelihoods\nModel 1 (Unconditional Model)\n\\[Lik(p_H) = p_H^{46}(1 - p_H)^{44}\\]\n. . .\nModel 2 (Conditional Model)\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#maximum-likelihood-estimates",
    "href": "slides/02_likelihoods_ch2_o.html#maximum-likelihood-estimates",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Maximum likelihood estimates",
    "text": "Maximum likelihood estimates\nThe maximum likelihood estimate (MLE) is the value between 0 and 1 where we are most likely to see the observed data.\n. . .\n\n\nModel 1 (Unconditional Model)\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\nModel 2 (Conditional Model)\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-mles-for-model-2",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-mles-for-model-2",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs for model 2",
    "text": "Finding the MLEs for model 2\nThe likelihood is\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n. . .\nThe log-likelihood is\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]\n. . .\nWe would like to find the MLEs for \\(p_{H| N}, p_{H|H Bias}, \\text{ and }p_{H |V Bias}\\)."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-mles-using-graphs",
    "href": "slides/02_likelihoods_ch2_o.html#finding-mles-using-graphs",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding MLEs using graphs",
    "text": "Finding MLEs using graphs\n\nWe need to find the MLEs for three parameters, therefore we would need to visualize a 4-dimensional object to find the MLEs from a graph. Given the difficulty of this task and the lack of precision in the estimates from this approach, we should rely on other approaches to find the MLEs in this instance.\n\n. . .\n\nWe also can‚Äôt use calculus‚Ä¶ that leaves only 1 approach‚Ä¶. optimization via grid search or optim in R"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-13",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-13",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (1/3)",
    "text": "Finding the MLEs using R (1/3)\nWe can write a function and do a grid search to find the values that maximize the log-likelihood.\n. . .\n\nmaxloglik&lt;- function(nvals){\n  #nvals specifies the number of values\n  phn &lt;- seq(0, 1, length = nvals)\n  phh &lt;- seq(0, 1, length = nvals)\n  phv &lt;- seq(0, 1, length = nvals)\n  \n  loglik &lt;- expand.grid(phn, phh, phv) \n  colnames(loglik) &lt;- c(\"phn\", \"phh\", \"phv\")\n  \n  loglik &lt;- loglik %&gt;%\n    mutate(loglik  = log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9))\n  \n  loglik %&gt;%\n    arrange(desc(loglik)) %&gt;%\n    slice(1)\n}\n\n\nmaxloglik(100)\n\n        phn       phh       phv    loglik\n1 0.5252525 0.4040404 0.5858586 -61.57691"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-23",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-23",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (2/3)",
    "text": "Finding the MLEs using R (2/3)\n\nDepending on the number of parameters, it may be hard to conduct a granular enough search to find the exact values of the MLEs.\nTherefore, one could use the function above to conduct a crude search to find starting values for R‚Äôs optim function.\nThe function optim differs from optimize in that it can optimize over multiple parameter values (The optimize function can only optimize over a single parameter value).\n\n. . .\n\n# Function to calculate log-likelihood that will be used in the optim function\nloglik &lt;- function(params){\n  phn &lt;- params[1]\n  phh &lt;- params[2]\n  phv &lt;- params[3]\n\n  log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9)\n}"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-33",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-33",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (3/3)",
    "text": "Finding the MLEs using R (3/3)\n\n# use manual search to get starting values \nstart_vals &lt;- maxloglik(50) %&gt;% select(-loglik)\n\n\n# Use optim function in R to find the values to maximize the log-likelihood\n#set fnscale = -1 to maximize (the default is minimize)\noptim(par = start_vals, fn = loglik, control=list(fnscale=-1))\n\n$par\n      phn       phh       phv \n0.5208272 0.4000361 0.5909793 \n\n$value\n[1] -61.57319\n\n$counts\nfunction gradient \n      66       NA \n\n$convergence\n[1] 0\n\n$message\nNULL"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-comparisons-1",
    "href": "slides/02_likelihoods_ch2_o.html#model-comparisons-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nNested models\nNon-nested models"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#nested-models-12",
    "href": "slides/02_likelihoods_ch2_o.html#nested-models-12",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Nested Models (1/2)",
    "text": "Nested Models (1/2)\nNested models: Models such that the parameters of the reduced model are a subset of the parameters for a larger model\nExample:\n\\[\\begin{aligned}&\\text{Model A: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\\\\\n&\\text{Model B: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\epsilon\\end{aligned}\\]\n. . .\nModel A is nested in Model B. We could use likelihoods to test whether it is useful to add \\(x_3\\) and \\(x_4\\) to the model.\n. . .\n\\[\\begin{aligned}&H_0: \\beta_3 = \\beta_4 = 0 \\\\\n&H_a: \\text{ at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#nested-models-22",
    "href": "slides/02_likelihoods_ch2_o.html#nested-models-22",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Nested models (2/2)",
    "text": "Nested models (2/2)\nAnother way to think about nested models: Parameters in larger model can be equated to get the simpler model or if some parameters can be set to constants\nExample:\n\\[\\begin{aligned}&\\text{Model 1: }p_H \\\\\n&\\text{Model 2: }p_{H| N}, p_{H| H Bias}, p_{H| V Bias}\\end{aligned}\\]\n. . .\nModel 1 is nested in Model 2. The parameters \\(p_{H| N}\\), \\(p_{H|H Bias}\\), and \\(p_{H |V Bias}\\) can be set equal to \\(p_H\\) to get Model 1.\n. . .\n\\[\\begin{aligned}&H_0: p_{H| N} = p_{H| H Bias} = p_{H| V Bias} = p_H \\\\\n&H_a: \\text{At least one of }p_{H| N}, p_{H| H Bias}, p_{H| V Bias} \\text{ differs from the others}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#steps-to-compare-models",
    "href": "slides/02_likelihoods_ch2_o.html#steps-to-compare-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Steps to compare models",
    "text": "Steps to compare models\n1Ô∏è‚É£ Find the MLEs for each model.\n2Ô∏è‚É£ Plug the MLEs into the log-likelihood function for each model to get the maximum value of the log-likelihood for each model.\n3Ô∏è‚É£ Find the difference in the maximum log-likelihoods\n4Ô∏è‚É£ Use the Likelihood Ratio Test to determine if the difference is statistically significant"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#steps-1---2",
    "href": "slides/02_likelihoods_ch2_o.html#steps-1---2",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Steps 1 - 2",
    "text": "Steps 1 - 2\nFind the MLEs for each model and plug them into the log-likelihood functions.\n\n\nModel 1:\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\n. . .\n\nloglik1 &lt;- function(ph){\n log(ph^46 * (1 - ph)^44)\n}\nloglik1(46/90)\n\n[1] -62.36102\n\n\n\nModel 2\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n. . .\n\nloglik2 &lt;- function(phn, phh, phv) {\n  log(phn^25 * (1 - phn)^23 * phh^8 * \n        (1 - phh)^12 * phv^13 * (1 - phv)^9)\n}\nloglik2(25/48, 8/20, 13/22)\n\n[1] -61.57319"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#step-3",
    "href": "slides/02_likelihoods_ch2_o.html#step-3",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Step 3",
    "text": "Step 3\nFind the difference in the log-likelihoods\n\n(diff &lt;- loglik2(25/48, 8/20, 13/22) - loglik1(46/90))\n\n[1] 0.7878318\n\n\n\n. . .\nIs the difference in the maximum log-likelihoods statistically significant?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihood-ratio-test",
    "href": "slides/02_likelihoods_ch2_o.html#likelihood-ratio-test",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood Ratio Test",
    "text": "Likelihood Ratio Test\nTest statistic\n\\[\\begin{aligned} LRT &= 2[\\max\\{\\log(Lik(\\text{larger model}))\\} - \\max\\{\\log(Lik(\\text{reduced model}))\\}]\\\\[10pt]\n&= 2\\log\\Bigg(\\frac{\\max\\{(Lik(\\text{larger model})\\}}{\\max\\{(Lik(\\text{reduced model})\\}}\\Bigg)\\end{aligned}\\]\n\n. . .\nLRT follows a \\(\\chi^2\\) distribution where the degrees of freedom equal the difference in the number of parameters between the two models"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#step-4",
    "href": "slides/02_likelihoods_ch2_o.html#step-4",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Step 4",
    "text": "Step 4\n\n(LRT &lt;- 2 * (loglik2(25/48, 8/20, 13/22) - loglik1(46/90)))\n\n[1] 1.575664\n\n\n. . .\nThe test statistic follows a \\(\\chi^2\\) distribution with 2 degrees of freedom. Therefore, the p-value is \\(P(\\chi^2 &gt; LRT)\\).\n\npchisq(LRT, 2, lower.tail = FALSE)\n\n[1] 0.4548299\n\n\n. . .\nThe p-value is very large, so we fail to reject \\(H_0\\). We do not have convincing evidence that the conditional model is an improvement over the unconditional model. Therefore, we can stick with the unconditional model."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#comparing-non-nested-models",
    "href": "slides/02_likelihoods_ch2_o.html#comparing-non-nested-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Comparing non-nested models",
    "text": "Comparing non-nested models\n\n\nAIC = -2(max log-likelihood) + 2p\n\n(Model1_AIC &lt;- 2 * loglik1(46/90) + 2 * 1)\n\n[1] -122.722\n\n(Model2_AIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 2 * 3)\n\n[1] -117.1464\n\n\n\nBIC = -2(max log-likelihood) + plog(n)\n\n(Model1_BIC &lt;- 2 * loglik1(46/90) + 1 * log(30))\n\n[1] -121.3208\n\n(Model2_BIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 3 * log(30))\n\n[1] -112.9428\n\n\nChoose Model 1, the unconditional model, based on AIC and BIC"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#looking-ahead",
    "href": "slides/02_likelihoods_ch2_o.html#looking-ahead",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nLikelihoods help us answer the question of how likely we are to observe the data given different parameters\nIn this example, we did not consider covariates, so in practice the parameters we want to estimate will look more similar to this\n\n. . .\n\\[p_H = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}\\]\n. . .\n\nFinding the MLE becomes much more complex and numerical methods may be required.\n\nWe will primarily rely on software to find the MLE, but the conceptual ideas will be the same"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#acknowledgements",
    "href": "slides/02_likelihoods_ch2_o.html#acknowledgements",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#setup",
    "href": "slides/02_likelihoods_ch2.html#setup",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#learning-goals",
    "href": "slides/02_likelihoods_ch2.html#learning-goals",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Learning goals",
    "text": "Learning goals\n\nDescribe the concept of a likelihood\nConstruct the likelihood for a simple model\nDefine the Maximum Likelihood Estimate (MLE) and use it to answer an analysis question\nIdentify three ways to calculate or approximate the MLE and apply these methods to find the MLE for a simple model\nUse likelihoods to compare models (next week)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#what-is-the-likelihood",
    "href": "slides/02_likelihoods_ch2.html#what-is-the-likelihood",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "What is the likelihood?",
    "text": "What is the likelihood?\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values).\n\nUnlike Ordinary Least Squares (OLS), they do not require the responses be independent, identically distributed, and normal (iidN)\nThey are not the same as probability functions\n\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#fouls-in-college-basketball-games",
    "href": "slides/02_likelihoods_ch2.html#fouls-in-college-basketball-games",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\nThe data set 04-refs.csv includes 30 randomly selected NCAA men‚Äôs basketball games played in the 2009 - 2010 season.\nWe will focus on the variables foul1, foul2, and foul3, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.\n\nH: Foul was called on the home team\nV: Foul was called on the visiting team\n\n\nWe are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.\n\n[The dataset was derived from basektball0910.csv used in BMLR Section 11.2"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#fouls-in-college-basketball-games-1",
    "href": "slides/02_likelihoods_ch2.html#fouls-in-college-basketball-games-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\n\nrefs &lt;- read_csv(\"data/04-refs.csv\")\nrefs %&gt;% slice(1:5) %&gt;% kable()\n\n\n\n\ngame\ndate\nvisitor\nhometeam\nfoul1\nfoul2\nfoul3\n\n\n\n\n166\n20100126\nCLEM\nBC\nV\nV\nV\n\n\n224\n20100224\nDEPAUL\nCIN\nH\nH\nV\n\n\n317\n20100109\nMARQET\nNOVA\nH\nH\nH\n\n\n214\n20100228\nMARQET\nSETON\nV\nV\nH\n\n\n278\n20100128\nSETON\nSFL\nH\nV\nV\n\n\n\n\n\nWe will treat the games as independent in this analysis."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#different-likelihood-models",
    "href": "slides/02_likelihoods_ch2.html#different-likelihood-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Different likelihood models",
    "text": "Different likelihood models\nModel 1 (Unconditional Model): What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\nModel 2 (Conditional Model):\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?\n\n\nUltimately we want to decide which model is better."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#exploratory-data-analysis",
    "href": "slides/02_likelihoods_ch2.html#exploratory-data-analysis",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\nrefs %&gt;%\ncount(foul1, foul2, foul3) %&gt;% kable()\n\n\n\n\nfoul1\nfoul2\nfoul3\nn\n\n\n\n\nH\nH\nH\n3\n\n\nH\nH\nV\n2\n\n\nH\nV\nH\n3\n\n\nH\nV\nV\n7\n\n\nV\nH\nH\n7\n\n\nV\nH\nV\n1\n\n\nV\nV\nH\n5\n\n\nV\nV\nV\n2\n\n\n\n\n\n\nThere are\n\n46 total fouls on the home team\n44 total fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-1-unconditional-model",
    "href": "slides/02_likelihoods_ch2.html#model-1-unconditional-model",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Unconditional model",
    "text": "Model 1: Unconditional model\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihood-1",
    "href": "slides/02_likelihoods_ch2.html#likelihood-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood",
    "text": "Likelihood\nLet \\(p_H\\) be the probability the referees call a foul on the home team.\nThe likelihood for a single observation\n\\[Lik(p_H) = p_H^{y_i}(1 - p_H)^{n_i - y_i}\\]\nWhere \\(y_i\\) is the number of fouls called on the home team.\n(In this example, we know \\(n_i = 3\\) for all observations.)\n\nExample\nFor a single game where the first three fouls are \\(H, H, V\\), then\n\\[Lik(p_H) = p_H^{2}(1 - p_H)^{3 - 2} = p_H^{2}(1 - p_H)\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-1-likelihood-contribution",
    "href": "slides/02_likelihoods_ch2.html#model-1-likelihood-contribution",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Likelihood contribution",
    "text": "Model 1: Likelihood contribution\n\n\n\nFoul1\nFoul2\nFoul3\nn\nLikelihood Contribution\n\n\n\n\nH\nH\nH\n3\n\\(p_H^3\\)\n\n\nH\nH\nV\n2\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nH\n3\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nH\n5\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nV\n2\n\\((1 - p_H)^3\\)\n\n\n\n\nFill in A and B."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-1-likelihood-function",
    "href": "slides/02_likelihoods_ch2.html#model-1-likelihood-function",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Likelihood function",
    "text": "Model 1: Likelihood function\nBecause the observations (the games) are independent, the likelihood is\n\\[Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}\\]\nWe will use this function to find the maximum likelihood estimate (MLE). The MLE is the value between 0 and 1 where we are most likely to see the observed data."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#visualizing-the-likelihood",
    "href": "slides/02_likelihoods_ch2.html#visualizing-the-likelihood",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100\nlik &lt;- p^46 *(1 -p)^44\n\nx &lt;- tibble(p = p, lik = lik)\nggplot(data = x, aes(x = p, y = lik)) + \n  geom_point() + \n  geom_line() +\n  labs(y = \"Likelihood\",\n       title = \"Likelihood of p_H\")"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#q-what-is-your-best-guess-for-the-mle-hatp_h",
    "href": "slides/02_likelihoods_ch2.html#q-what-is-your-best-guess-for-the-mle-hatp_h",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: What is your best guess for the MLE, \\(\\hat{p}_H\\)?",
    "text": "Q: What is your best guess for the MLE, \\(\\hat{p}_H\\)?\nA. 0.489\nB. 0.500\nC. 0.511\nD. 0.556"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-maximum-likelihood-estimate",
    "href": "slides/02_likelihoods_ch2.html#finding-the-maximum-likelihood-estimate",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the maximum likelihood estimate",
    "text": "Finding the maximum likelihood estimate\nThere are three primary ways to find the MLE\n\n‚úÖ Approximate using a graph\n\n\n‚úÖ Numerical approximation\n\n\n‚úÖ Using calculus"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#approximate-mle-from-a-graph",
    "href": "slides/02_likelihoods_ch2.html#approximate-mle-from-a-graph",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Approximate MLE from a graph",
    "text": "Approximate MLE from a graph"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#find-the-mle-using-numerical-approximation",
    "href": "slides/02_likelihoods_ch2.html#find-the-mle-using-numerical-approximation",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Find the MLE using numerical approximation",
    "text": "Find the MLE using numerical approximation\nSpecify a finite set of possible values the for \\(p_H\\) and calculate the likelihood for each value\n\n# write an R function for the likelihood\nref_lik &lt;- function(ph) {\n  ph^46 *(1 - ph)^44\n}\n\n\n# use the optimize function to find the MLE\noptimize(ref_lik, interval = c(0,1), maximum = TRUE)\n\n$maximum\n[1] 0.5111132\n\n$objective\n[1] 8.25947e-28"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#find-mle-using-calculus",
    "href": "slides/02_likelihoods_ch2.html#find-mle-using-calculus",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\nFind the MLE by taking the first derivative of the likelihood function.\nThis can be tricky because of the Product Rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSince calculus is not a pre-req, we will forgo this quest."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-2-conditional-model",
    "href": "slides/02_likelihoods_ch2.html#model-2-conditional-model",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Conditional model",
    "text": "Model 2: Conditional model\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-2-likelihood-contributions",
    "href": "slides/02_likelihoods_ch2.html#model-2-likelihood-contributions",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\nNow let‚Äôs assume fouls are not independent within each game. We will specify this dependence using conditional probabilities.\n\nConditional probability: \\(P(A|B) =\\) Probability of \\(A\\) given \\(B\\) has occurred\n\n\n\nDefine new parameters:\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-2-likelihood-contributions-1",
    "href": "slides/02_likelihoods_ch2.html#model-2-likelihood-contributions-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\n\n\n\n\n\n\n\n\n\nFoul1\nFoul2\nFoul3\nn\nLikelihood Contribution\n\n\n\n\nH\nH\nH\n3\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(p_{H\\vert H Bias}) = (p_{H\\vert N})(p_{H\\vert H Bias})^2\\)\n\n\nH\nH\nV\n2\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(1 - p_{H\\vert H Bias})\\)\n\n\nH\nV\nH\n3\n\\((p_{H\\vert N})(1 - p_{H\\vert H Bias})(p_{H\\vert N}) = (p_{H\\vert N})^2(1 - p_{H\\vert H Bias})\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\((1 - p_{H\\vert N})(p_{H\\vert V Bias})(1 - p_{H\\vert N}) = (1 - p_{H\\vert N})^2(p_{H\\vert V Bias})\\)\n\n\nV\nV\nH\n5\n\\((1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(p_{H\\vert V Bias})\\)\n\n\nV\nV\nV\n2\n\\(\\begin{aligned}&(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(1-p_{H\\vert V Bias})\\\\ &=(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})^2\\end{aligned}\\)\n\n\n\nFill in A and B"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihood-function",
    "href": "slides/02_likelihoods_ch2.html#likelihood-function",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood function",
    "text": "Likelihood function\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n(Note: The exponents sum to 90, the total number of fouls in the data)\n\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#q-if-fouls-within-a-game-are-independent-how-would-you-expect-hatp_h-hatp_hvert-h-bias-and-hatp_hvert-v-bias-to-compare",
    "href": "slides/02_likelihoods_ch2.html#q-if-fouls-within-a-game-are-independent-how-would-you-expect-hatp_h-hatp_hvert-h-bias-and-hatp_hvert-v-bias-to-compare",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: If fouls within a game are independent, how would you expect \\(\\hat{p}_H\\), \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H\\vert V Bias}\\) to compare?",
    "text": "Q: If fouls within a game are independent, how would you expect \\(\\hat{p}_H\\), \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H\\vert V Bias}\\) to compare?\n\n\\(\\hat{p}_H\\) is greater than \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\n\\(\\hat{p}_{H\\vert H Bias}\\) is greater than \\(\\hat{p}_H\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\n\\(\\hat{p}_{H\\vert V Bias}\\) is greater than \\(\\hat{p}_H\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\nThey are all approximately equal."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#q-if-there-is-a-tendency-for-referees-to-call-a-foul-on-the-team-that-already-has-more-fouls-how-would-you-expect-hatp_h-and-hatp_hvert-h-bias-to-compare",
    "href": "slides/02_likelihoods_ch2.html#q-if-there-is-a-tendency-for-referees-to-call-a-foul-on-the-team-that-already-has-more-fouls-how-would-you-expect-hatp_h-and-hatp_hvert-h-bias-to-compare",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: If there is a tendency for referees to call a foul on the team that already has more fouls, how would you expect \\(\\hat{p}_H\\) and \\(\\hat{p}_{H\\vert H Bias}\\) to compare?",
    "text": "Q: If there is a tendency for referees to call a foul on the team that already has more fouls, how would you expect \\(\\hat{p}_H\\) and \\(\\hat{p}_{H\\vert H Bias}\\) to compare?\n\n\\(\\hat{p}_H\\) is greater than \\(\\hat{p}_{H\\vert H Bias}\\)\n\\(\\hat{p}_{H\\vert H Bias}\\) is greater than \\(\\hat{p}_H\\)\nThey are approximately equal."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihoods",
    "href": "slides/02_likelihoods_ch2.html#likelihoods",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihoods",
    "text": "Likelihoods\nModel 1 (Unconditional Model)\n\n\\(p_H\\): probability of a foul being called on the home team\n\n\nModel 2 (Conditional Model)\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihoods-1",
    "href": "slides/02_likelihoods_ch2.html#likelihoods-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihoods",
    "text": "Likelihoods\nModel 1 (Unconditional Model)\n\\[Lik(p_H) = p_H^{46}(1 - p_H)^{44}\\]\n\nModel 2 (Conditional Model)\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#maximum-likelihood-estimates",
    "href": "slides/02_likelihoods_ch2.html#maximum-likelihood-estimates",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Maximum likelihood estimates",
    "text": "Maximum likelihood estimates\nThe maximum likelihood estimate (MLE) is the value between 0 and 1 where we are most likely to see the observed data.\n\n\n\nModel 1 (Unconditional Model)\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\nModel 2 (Conditional Model)\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-mles-for-model-2",
    "href": "slides/02_likelihoods_ch2.html#finding-the-mles-for-model-2",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs for model 2",
    "text": "Finding the MLEs for model 2\nThe likelihood is\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n\nThe log-likelihood is\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]\n\n\nWe would like to find the MLEs for \\(p_{H| N}, p_{H|H Bias}, \\text{ and }p_{H |V Bias}\\)."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-mles-using-graphs",
    "href": "slides/02_likelihoods_ch2.html#finding-mles-using-graphs",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding MLEs using graphs",
    "text": "Finding MLEs using graphs\n\nWe need to find the MLEs for three parameters, therefore we would need to visualize a 4-dimensional object to find the MLEs from a graph. Given the difficulty of this task and the lack of precision in the estimates from this approach, we should rely on other approaches to find the MLEs in this instance.\n\n\n\nWe also can‚Äôt use calculus‚Ä¶ that leaves only 1 approach‚Ä¶. optimization via grid search or optim in R"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-13",
    "href": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-13",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (1/3)",
    "text": "Finding the MLEs using R (1/3)\nWe can write a function and do a grid search to find the values that maximize the log-likelihood.\n\n\nmaxloglik&lt;- function(nvals){\n  #nvals specifies the number of values\n  phn &lt;- seq(0, 1, length = nvals)\n  phh &lt;- seq(0, 1, length = nvals)\n  phv &lt;- seq(0, 1, length = nvals)\n  \n  loglik &lt;- expand.grid(phn, phh, phv) \n  colnames(loglik) &lt;- c(\"phn\", \"phh\", \"phv\")\n  \n  loglik &lt;- loglik %&gt;%\n    mutate(loglik  = log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9))\n  \n  loglik %&gt;%\n    arrange(desc(loglik)) %&gt;%\n    slice(1)\n}\n\n\nmaxloglik(100)\n\n        phn       phh       phv    loglik\n1 0.5252525 0.4040404 0.5858586 -61.57691"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-23",
    "href": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-23",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (2/3)",
    "text": "Finding the MLEs using R (2/3)\n\nDepending on the number of parameters, it may be hard to conduct a granular enough search to find the exact values of the MLEs.\nTherefore, one could use the function above to conduct a crude search to find starting values for R‚Äôs optim function.\nThe function optim differs from optimize in that it can optimize over multiple parameter values (The optimize function can only optimize over a single parameter value).\n\n\n\n# Function to calculate log-likelihood that will be used in the optim function\nloglik &lt;- function(params){\n  phn &lt;- params[1]\n  phh &lt;- params[2]\n  phv &lt;- params[3]\n\n  log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9)\n}"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-33",
    "href": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-33",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (3/3)",
    "text": "Finding the MLEs using R (3/3)\n\n# use manual search to get starting values \nstart_vals &lt;- maxloglik(50) %&gt;% select(-loglik)\n\n\n# Use optim function in R to find the values to maximize the log-likelihood\n#set fnscale = -1 to maximize (the default is minimize)\noptim(par = start_vals, fn = loglik, control=list(fnscale=-1))\n\n$par\n      phn       phh       phv \n0.5208272 0.4000361 0.5909793 \n\n$value\n[1] -61.57319\n\n$counts\nfunction gradient \n      66       NA \n\n$convergence\n[1] 0\n\n$message\nNULL"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-comparisons-1",
    "href": "slides/02_likelihoods_ch2.html#model-comparisons-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nNested models\nNon-nested models"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#nested-models-12",
    "href": "slides/02_likelihoods_ch2.html#nested-models-12",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Nested Models (1/2)",
    "text": "Nested Models (1/2)\nNested models: Models such that the parameters of the reduced model are a subset of the parameters for a larger model\nExample:\n\\[\\begin{aligned}&\\text{Model A: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\\\\\n&\\text{Model B: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\epsilon\\end{aligned}\\]\n\nModel A is nested in Model B. We could use likelihoods to test whether it is useful to add \\(x_3\\) and \\(x_4\\) to the model.\n\n\n\\[\\begin{aligned}&H_0: \\beta_3 = \\beta_4 = 0 \\\\\n&H_a: \\text{ at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#nested-models-22",
    "href": "slides/02_likelihoods_ch2.html#nested-models-22",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Nested models (2/2)",
    "text": "Nested models (2/2)\nAnother way to think about nested models: Parameters in larger model can be equated to get the simpler model or if some parameters can be set to constants\nExample:\n\\[\\begin{aligned}&\\text{Model 1: }p_H \\\\\n&\\text{Model 2: }p_{H| N}, p_{H| H Bias}, p_{H| V Bias}\\end{aligned}\\]\n\nModel 1 is nested in Model 2. The parameters \\(p_{H| N}\\), \\(p_{H|H Bias}\\), and \\(p_{H |V Bias}\\) can be set equal to \\(p_H\\) to get Model 1.\n\n\n\\[\\begin{aligned}&H_0: p_{H| N} = p_{H| H Bias} = p_{H| V Bias} = p_H \\\\\n&H_a: \\text{At least one of }p_{H| N}, p_{H| H Bias}, p_{H| V Bias} \\text{ differs from the others}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#steps-to-compare-models",
    "href": "slides/02_likelihoods_ch2.html#steps-to-compare-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Steps to compare models",
    "text": "Steps to compare models\n1Ô∏è‚É£ Find the MLEs for each model.\n2Ô∏è‚É£ Plug the MLEs into the log-likelihood function for each model to get the maximum value of the log-likelihood for each model.\n3Ô∏è‚É£ Find the difference in the maximum log-likelihoods\n4Ô∏è‚É£ Use the Likelihood Ratio Test to determine if the difference is statistically significant"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#steps-1---2",
    "href": "slides/02_likelihoods_ch2.html#steps-1---2",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Steps 1 - 2",
    "text": "Steps 1 - 2\nFind the MLEs for each model and plug them into the log-likelihood functions.\n\n\nModel 1:\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\n. . .\n\nloglik1 &lt;- function(ph){\n log(ph^46 * (1 - ph)^44)\n}\nloglik1(46/90)\n\n[1] -62.36102\n\n\n\nModel 2\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n. . .\n\nloglik2 &lt;- function(phn, phh, phv) {\n  log(phn^25 * (1 - phn)^23 * phh^8 * \n        (1 - phh)^12 * phv^13 * (1 - phv)^9)\n}\nloglik2(25/48, 8/20, 13/22)\n\n[1] -61.57319"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#step-3",
    "href": "slides/02_likelihoods_ch2.html#step-3",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Step 3",
    "text": "Step 3\nFind the difference in the log-likelihoods\n\n(diff &lt;- loglik2(25/48, 8/20, 13/22) - loglik1(46/90))\n\n[1] 0.7878318\n\n\n\n\nIs the difference in the maximum log-likelihoods statistically significant?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihood-ratio-test",
    "href": "slides/02_likelihoods_ch2.html#likelihood-ratio-test",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood Ratio Test",
    "text": "Likelihood Ratio Test\nTest statistic\n\\[\\begin{aligned} LRT &= 2[\\max\\{\\log(Lik(\\text{larger model}))\\} - \\max\\{\\log(Lik(\\text{reduced model}))\\}]\\\\[10pt]\n&= 2\\log\\Bigg(\\frac{\\max\\{(Lik(\\text{larger model})\\}}{\\max\\{(Lik(\\text{reduced model})\\}}\\Bigg)\\end{aligned}\\]\n\n\nLRT follows a \\(\\chi^2\\) distribution where the degrees of freedom equal the difference in the number of parameters between the two models"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#step-4",
    "href": "slides/02_likelihoods_ch2.html#step-4",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Step 4",
    "text": "Step 4\n\n(LRT &lt;- 2 * (loglik2(25/48, 8/20, 13/22) - loglik1(46/90)))\n\n[1] 1.575664\n\n\n\nThe test statistic follows a \\(\\chi^2\\) distribution with 2 degrees of freedom. Therefore, the p-value is \\(P(\\chi^2 &gt; LRT)\\).\n\npchisq(LRT, 2, lower.tail = FALSE)\n\n[1] 0.4548299\n\n\n\n\nThe p-value is very large, so we fail to reject \\(H_0\\). We do not have convincing evidence that the conditional model is an improvement over the unconditional model. Therefore, we can stick with the unconditional model."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#comparing-non-nested-models",
    "href": "slides/02_likelihoods_ch2.html#comparing-non-nested-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Comparing non-nested models",
    "text": "Comparing non-nested models\n\n\nAIC = -2(max log-likelihood) + 2p\n\n(Model1_AIC &lt;- 2 * loglik1(46/90) + 2 * 1)\n\n[1] -122.722\n\n(Model2_AIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 2 * 3)\n\n[1] -117.1464\n\n\n\nBIC = -2(max log-likelihood) + plog(n)\n\n(Model1_BIC &lt;- 2 * loglik1(46/90) + 1 * log(30))\n\n[1] -121.3208\n\n(Model2_BIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 3 * log(30))\n\n[1] -112.9428\n\n\nChoose Model 1, the unconditional model, based on AIC and BIC"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#looking-ahead",
    "href": "slides/02_likelihoods_ch2.html#looking-ahead",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nLikelihoods help us answer the question of how likely we are to observe the data given different parameters\nIn this example, we did not consider covariates, so in practice the parameters we want to estimate will look more similar to this\n\n\n\\[p_H = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}\\]\n\n\n\nFinding the MLE becomes much more complex and numerical methods may be required.\n\nWe will primarily rely on software to find the MLE, but the conceptual ideas will be the same"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#acknowledgements",
    "href": "slides/02_likelihoods_ch2.html#acknowledgements",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  }
]