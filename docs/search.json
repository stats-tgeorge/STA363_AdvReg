[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Advanced Regression",
    "section": "",
    "text": "Instructor Dr.¬†Tyler George\n ¬† Cornell College, West 311\n ¬†  tgeorge@cornellcollege.edu \n\n\n\n\nAugust 28th - September 18th\n ¬† M-F,9am-11am and 1pm-3pm\n ¬† West 201\n ¬† Course Calendar\n\n\n\n\n ¬† MWTh 3:05pm-4:05pm and by appt.\n ¬† West 311\n ¬† Optional Appointment\nI am available far beyond these times listed. Please email me and we can set up a time to chat about class material or whatever you prefer! I will generally announce changes to office hours in class but I still suggest checking the Course Calendar to verify availability.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#ai-policy",
    "href": "syllabus.html#ai-policy",
    "title": "Advanced Regression",
    "section": "AI Policy",
    "text": "AI Policy\nThe beta release of Dall-E-Mini in July 2022 and ChatGPT in November 2022 are among many tools using artificial intelligence. There is a good possibility that using tools like these are going to become an important skill for careers in the not distant future (https://www.theguardian.com/commentisfree/2023/jan/07/chatgpt-bot-excel-ai-chatbot-tech).\nIn the meantime though, it‚Äôs going to take a while for society to figure out when using these tools is/isn‚Äôt acceptable.\nWork created by AI tools may not be considered original work and, instead, considered automated plagiarism. It is derived from previously created texts from other sources that the models were trained on, yet doesn‚Äôt cite sources. AI models have built-in biases (ie, they are trained on limited underlying sources; they reproduce, rather than challenge, errors in the sources) AI tools have limitations (ie, they lack critical thinking to evaluate and reflect on criteria; they lack abductive reasoning to make judgments with incomplete information at hand; they make up or use inaccurate information and may ‚Äúhallucinate‚Äù sources that do not exist)\nIn this course, all informal writing should be written without the use of AI. The purpose of informal writing is to help you think through your ideas, connect with your lived experiences, and to figure out your thoughts and opinions. Using AI here subverts that process.\nA final note: Other courses may have different AI policies, and it is important to be aware of the policy in each class.\n\nDISABILITIES AND ACCOMODATIONS POLICY\nCornell College makes reasonable accommodations for persons with disabilities. Students should notify the Office of Academic Support and Advising and their course instructor of any disability related accommodations within the first three days of the term for which the accommodations are required, due to the fast pace of the block format. For more information on the documentation required to establish the need for accommodations and the process of requesting the accommodations.\n\n\nACADEMIC HONESTY POLICY\nCornell College expects all members of the Cornell community to act with academic integrity. An important aspect of academic integrity is respecting the work of others. A student is expected to explicitly acknowledge ideas, claims, observations, or data of others, unless generally known. When a piece of work is submitted for credit, a student is asserting that the submission is her or his work unless there is a citation of a specific source. If there is no appropriate acknowledgment of sources, whether intended or not, this may constitute a violation of the College‚Äôs requirement for honesty in academic work and may be treated as a case of academic dishonesty. The procedures regarding how the College deals with cases of academic dishonesty appear in The Catalog, under the heading ‚ÄúAcademic Honesty.‚Äù\n\n\nIllness Policy\nIf you are experiencing COVID-19 symptoms, do not attend class. Perform a home test or contact Director of Student Health Services Lynn O‚ÄôBrien at student_health@cornellcollege.edu immediately to arrange a COVID-19 test at the Health Center. If you need to isolate due to COVID-19, or if you become unable to attend class for any other health reason, contact me as soon as possible to determine if you are able to continue in the class. A Withdrawal for Health Reasons may be required.\n\n\nMandatory Reporter Reminder\nIt is my goal that you feel supported and able to share information related to your life experiences during classroom discussions, in your written work, and in any one-on-one meetings with me. You should also know that all Cornell College faculty and staff are mandatory reporters. This means that I will keep information you share with me private to the greatest extent possible. However, I am required to share information regarding sexual assault, abuse, criminal behavior, or about a student who may be a danger to themselves or to others. If you wish to speak to someone confidentially who is not a mandatory reporter, you can schedule an appointment with one of the counselors in the Ebersole Health and Wellbeing Center or contact the College Chaplain, Rev.¬†Melea White, at mwhite@cornelllcollege.edu.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "slides/06_logistic_ch6.html#setup",
    "href": "slides/06_logistic_ch6.html#setup",
    "title": "Logistic Regression",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#learning-goals",
    "href": "slides/06_logistic_ch6.html#learning-goals",
    "title": "Logistic Regression",
    "section": "Learning goals",
    "text": "Learning goals\n\nIdentify Bernoulli and binomial random variables\nWrite GLM for binomial response variable\nInterpret the coefficients for a logistic regression model\nVisualizations for logistic regression\nInterpret coefficients and results from an ordinal logistic regression model\nSummarize GLMs for independent observations"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#bernoulli-binomial-random-variables-12",
    "href": "slides/06_logistic_ch6.html#bernoulli-binomial-random-variables-12",
    "title": "Logistic Regression",
    "section": "Bernoulli + Binomial random variables (1/2)",
    "text": "Bernoulli + Binomial random variables (1/2)\nLogistic regression is used to analyze data with two types of responses:\n\nBinary: These responses take on two values success \\((Y = 1)\\) or failure \\((Y = 0)\\), yes \\((Y = 1)\\) or no \\((Y = 0)\\), etc.\n\n\n\\[P(Y = y) = p^y(1-p)^{1-y} \\hspace{10mm} y = 0, 1\\]"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#bernoulli-binomial-random-variables-22",
    "href": "slides/06_logistic_ch6.html#bernoulli-binomial-random-variables-22",
    "title": "Logistic Regression",
    "section": "Bernoulli + Binomial random variables (2/2)",
    "text": "Bernoulli + Binomial random variables (2/2)\nLogistic regression is used to analyze data with two types of responses:\n\nBinomial: Number of successes in a Bernoulli process, \\(n\\) independent trials with a constant probability of success \\(p\\).\n\n\n\\[P(Y = y) = {n \\choose y}p^{y}(1-p)^{n - y} \\hspace{10mm} y = 0, 1, \\ldots, n\\]\n\n\nIn both instances, the goal is to model \\(p\\) the probability of success."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#binary-vs.-binomial-data",
    "href": "slides/06_logistic_ch6.html#binary-vs.-binomial-data",
    "title": "Logistic Regression",
    "section": "Binary vs.¬†Binomial data",
    "text": "Binary vs.¬†Binomial data\nFor each example, identify if the response is a Bernoulli or Binomial response\n\nUse median age and unemployment rate in a county to predict the percent of Obama votes in the county in the 2008 presidential election.\nUse GPA and MCAT scores to estimate the probability a student is accepted into medical school.\nUse sex, age, and smoking history to estimate the probability an individual has lung cancer.\nUse offensive and defensive statistics from the 2017-2018 NBA season to predict a team‚Äôs winning percentage."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#logistic-regression-model",
    "href": "slides/06_logistic_ch6.html#logistic-regression-model",
    "title": "Logistic Regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\n\\(\\log\\Big(\\frac{p}{1-p}\\Big) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p\\)\n\nThe response variable, \\(\\log\\Big(\\frac{p}{1-p}\\Big)\\), is the log(odds) of success, i.e.¬†the logit\nUse the model to calculate the probability of success \\(\\hat{p} = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p}}\\)\nWhen the response is a Bernoulli random variable, the probabilities can be used to classify each observation as a success or failure"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#logistic-vs-linear-regression-model",
    "href": "slides/06_logistic_ch6.html#logistic-vs-linear-regression-model",
    "title": "Logistic Regression",
    "section": "Logistic vs linear regression model",
    "text": "Logistic vs linear regression model\n\nPlotCode\n\n\n\n\n\n\n\nGraph from BMLR Chapter 6\n\n\n\n\n\n\n\nset.seed(0)\ndat &lt;- tibble(x=runif(200, -5, 10),\n                  p=exp(-2+1*x)/(1+exp(-2+1*x)),\n                  y=rbinom(200, 1, p),\n                  y2=.3408+.0901*x,\n                  logit=log(p/(1-p)))\ndat2 &lt;- tibble(x = c(dat$x, dat$x),\n               y = c(dat$y2, dat$p),\n               `Regression model` = c(rep(\"linear\", 200),\n                                      rep(\"logistic\", 200)))\n\nggplot() + \n  geom_point(data = dat, aes(x, y)) +\n  geom_line(data = dat2, aes(x, y, linetype = `Regression model`, \n                             color = `Regression model`)) + \n  labs(title = \"Linear vs. logistic regression models for binary response data\") + \n  scale_colour_manual(name = 'Regression model',\n                      values = c('blue', 'red'), \n                      labels = c('linear', 'logistic'), guide ='legend')"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#logit-link",
    "href": "slides/06_logistic_ch6.html#logit-link",
    "title": "Logistic Regression",
    "section": "Logit link",
    "text": "Logit link\nBernoulli and Binomial random variables can be written in one-parameter exponential family form, \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\n\nBernoulli\n\\[f(y;p) = e^{y\\log(\\frac{p}{1-p}) + \\log(1-p)}\\]\n\n\nBinomial\n\\[f(y;n,p) = e^{y\\log(\\frac{p}{1-p}) + n\\log(1-p) + \\log{n \\choose y}}\\]\n\n\nThey have the same canonical link \\(b(p) = \\log\\big(\\frac{p}{1-p}\\big)\\)"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#assumptions-for-logistic-regression",
    "href": "slides/06_logistic_ch6.html#assumptions-for-logistic-regression",
    "title": "Logistic Regression",
    "section": "Assumptions for logistic regression",
    "text": "Assumptions for logistic regression\nThe following assumptions need to be satisfied to use logistic regression to make inferences\n\n1Ô∏è‚É£ \\(\\hspace{0.5mm}\\) Binary response: The response is dichotomous (has two possible outcomes) or is the sum of dichotomous responses\n2Ô∏è‚É£ \\(\\hspace{0.5mm}\\) Independence: The observations must be independent of one another\n3Ô∏è‚É£ \\(\\hspace{0.5mm}\\) Variance structure: Variance of a binomial random variable is \\(np(1-p)\\) \\((n = 1 \\text{ for Bernoulli})\\) , so the variability is highest when \\(p = 0.5\\)\n4Ô∏è‚É£ \\(\\hspace{0.5mm}\\) Linearity: The log of the odds ratio, \\(\\log\\big(\\frac{p}{1-p}\\big)\\), must be a linear function of the predictors \\(x_1, \\ldots, x_p\\)"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#covid-19-infection-prevention-practices-at-food-establishments",
    "href": "slides/06_logistic_ch6.html#covid-19-infection-prevention-practices-at-food-establishments",
    "title": "Logistic Regression",
    "section": "COVID-19 infection prevention practices at food establishments",
    "text": "COVID-19 infection prevention practices at food establishments\nResearchers at Wollo Univeristy in Ethiopia conducted a study in July and August 2020 to understand factors associated with good COVID-19 infection prevention practices at food establishments. Their study is published in Andualem et al.¬†(2022)\n\nThey were particularly interested in the understanding implementation of prevention practices at food establishments, given the workers‚Äô increased risk due to daily contact with customers.\n\n\nAndualem, A., Tegegne, B., Ademe, S., Natnael, T., Berihun, G., Abebe, M., ‚Ä¶ & Adane, M. (2022). COVID-19 infection prevention practices among a sample of food handlers of food and drink establishments in Ethiopia. PloS one, 17(1), e0259851."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#the-data",
    "href": "slides/06_logistic_ch6.html#the-data",
    "title": "Logistic Regression",
    "section": "The data",
    "text": "The data\n‚ÄúAn institution-based cross-sectional study was conducted among 422 food handlers in Dessie City and Kombolcha Town food and drink establishments in July and August 2020. The study participants were selected using a simple random sampling technique. Data were collected by trained data collectors using a pretested structured questionnaire and an on-the-spot observational checklist.‚Äù\n\n\nAndualem, A., Tegegne, B., Ademe, S., Natnael, T., Berihun, G., Abebe, M., ‚Ä¶ & Adane, M. (2022). COVID-19 infection prevention practices among a sample of food handlers of food and drink establishments in Ethiopia. PloS one, 17(1), e0259851."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#response-variable",
    "href": "slides/06_logistic_ch6.html#response-variable",
    "title": "Logistic Regression",
    "section": "Response variable",
    "text": "Response variable\n‚ÄúThe outcome variable of this study was the good or poor practices of COVID-19 infection prevention among food handlers. Nine yes/no questions, one observational checklist and five multiple choice infection prevention practices questions were asked with a minimum score of 1 and maximum score of 25. Good infection prevention practice (the variable of interest) was determined for food handlers who scored 75% or above, whereas poor infection prevention practices refers to those food handlers who scored below 75% on the practice questions.‚Äù\n\n\nAndualem, A., Tegegne, B., Ademe, S., Natnael, T., Berihun, G., Abebe, M., ‚Ä¶ & Adane, M. (2022). COVID-19 infection prevention practices among a sample of food handlers of food and drink establishments in Ethiopia. PloS one, 17(1), e0259851."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#results",
    "href": "slides/06_logistic_ch6.html#results",
    "title": "Logistic Regression",
    "section": "Results",
    "text": "Results\n\n\n\nAndualem, A., Tegegne, B., Ademe, S., Natnael, T., Berihun, G., Abebe, M., ‚Ä¶ & Adane, M. (2022). COVID-19 infection prevention practices among a sample of food handlers of food and drink establishments in Ethiopia. PloS one, 17(1), e0259851."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#interpreting-the-results",
    "href": "slides/06_logistic_ch6.html#interpreting-the-results",
    "title": "Logistic Regression",
    "section": "Interpreting the results",
    "text": "Interpreting the results\n\nIs the response a Bernoulli or Binomial?\nWhat is the strongest predictor of having good COVID-19 infection prevention practices?\n\nIt‚Äôs often unreliable to look answer this question just based on the model output. Why are we able to answer this question based on the model output in this case?\n\nDescribe the effect (coefficient interpretation and inference) of having COVID-19 infection prevention policies available at the food establishment.\nThe intercept describes what group of food handlers?"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#access-to-personal-protective-equipment",
    "href": "slides/06_logistic_ch6.html#access-to-personal-protective-equipment",
    "title": "Logistic Regression",
    "section": "Access to personal protective equipment",
    "text": "Access to personal protective equipment\nWe will use the data from Andualem et al.¬†(2022) to explore the association between age, sex, years of service, and whether someone works at a food establishment with access to personal protective equipment (PPE) as of August 2020. We will use access to PPE as a proxy for wearing PPE.\n\nPlotCode\n\n\n\n\nRows: 401 Columns: 58\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\ndbl (58): Age of food handlers, Sex, Years of service, Specific budget for PPE, Availa...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nage\nsex\nyears\nppe_access\n\n\n\n\n34\nMale\n2\n1\n\n\n32\nFemale\n3\n1\n\n\n32\nFemale\n1\n1\n\n\n40\nMale\n4\n1\n\n\n32\nMale\n10\n1\n\n\n\n\n\n\n\n\ncovid_df &lt;- read_csv(\"data/covid-prevention-study.csv\") |&gt;\n  rename(age = \"Age of food handlers\", \n         years = \"Years of service\", \n         ppe_access = \"Availability of PPEs\") |&gt;\n  mutate(sex = factor(if_else(Sex == 2, \"Female\", \"Male\"))) |&gt;\n  select(age, sex, years, ppe_access) \n\ncovid_df |&gt; slice(1:5) |&gt; kable()"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#eda-for-binary-response-12",
    "href": "slides/06_logistic_ch6.html#eda-for-binary-response-12",
    "title": "Logistic Regression",
    "section": "EDA for binary response (1/2)",
    "text": "EDA for binary response (1/2)\n\nlibrary(Stat2Data)\npar(mfrow = c(1, 2))\nemplogitplot1(ppe_access ~ age, data = covid_df, ngroups = 10)\nemplogitplot1(ppe_access ~ years, data = covid_df, ngroups = 5)"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#eda-for-binary-response-22",
    "href": "slides/06_logistic_ch6.html#eda-for-binary-response-22",
    "title": "Logistic Regression",
    "section": "EDA for binary response (2/2)",
    "text": "EDA for binary response (2/2)\n\nplotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(viridis)\nggplot(data = covid_df, aes(x = sex, fill = factor(ppe_access))) + \n  geom_bar(position = \"fill\")  +\n  labs(x = \"Sex\", \n       fill = \"PPE Access\", \n       title = \"PPE Access by Sex\") + \n  scale_fill_viridis_d()"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#model-results",
    "href": "slides/06_logistic_ch6.html#model-results",
    "title": "Logistic Regression",
    "section": "Model results",
    "text": "Model results\n\nppe_model &lt;- glm(factor(ppe_access) ~ age + sex + years, data = covid_df, \n                 family = binomial)\ntidy(ppe_model, conf.int = TRUE) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-2.127\n0.458\n-4.641\n0.000\n-3.058\n-1.257\n\n\nage\n0.056\n0.017\n3.210\n0.001\n0.023\n0.091\n\n\nsexMale\n0.341\n0.224\n1.524\n0.128\n-0.098\n0.780\n\n\nyears\n0.264\n0.066\n4.010\n0.000\n0.143\n0.401"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#visualizing-coefficient-estimates",
    "href": "slides/06_logistic_ch6.html#visualizing-coefficient-estimates",
    "title": "Logistic Regression",
    "section": "Visualizing coefficient estimates",
    "text": "Visualizing coefficient estimates\n\nmodel_coef &lt;- tidy(ppe_model, exponentiate = TRUE, conf.int = TRUE)\n\n\nggplot(data = model_coef, aes(x = term, y = estimate)) +\n  geom_point() +\n  geom_hline(yintercept = 1, lty = 2) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high))+\n  labs(title = \"Exponentiated model coefficients\") + \n  coord_flip()"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#data-supporting-railroads-in-the-1870s",
    "href": "slides/06_logistic_ch6.html#data-supporting-railroads-in-the-1870s",
    "title": "Logistic Regression",
    "section": "Data: Supporting railroads in the 1870s",
    "text": "Data: Supporting railroads in the 1870s\nThe data set RR_Data_Hale.csv contains information on support for referendums related to railroad subsidies for 11 communities in Alabama in the 1870s. The data were originally analyzed as part of a thesis project by a student at St.¬†Olaf College. The variables in the data are\n\npctBlack: percentage of Black residents in the county\ndistance: distance the proposed railroad is from the community (in miles)\nYesVotes: number of ‚Äúyes‚Äù votes in favor of the proposed railroad line\nNumVotes: number of votes cast in the election\n\n\nPrimary question: Was voting on the railroad referendum related to the distance from the proposed railroad line, after adjusting for the racial composition of a community?"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#the-data-1",
    "href": "slides/06_logistic_ch6.html#the-data-1",
    "title": "Logistic Regression",
    "section": "The data",
    "text": "The data\n\nrr &lt;- read_csv(\"data/RR_Data_Hale.csv\")\n\nRows: 12 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): County\ndbl (7): popBlack, popWhite, popTotal, pctBlack, distance, YesVotes, NumVotes\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrr |&gt; slice(1:5) |&gt; kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCounty\npopBlack\npopWhite\npopTotal\npctBlack\ndistance\nYesVotes\nNumVotes\n\n\n\n\nCarthage\n841\n599\n1440\n58.40\n17\n61\n110\n\n\nCederville\n1774\n146\n1920\n92.40\n7\n0\n15\n\n\nFive Mile Creek\n140\n626\n766\n18.28\n15\n4\n42\n\n\nGreensboro\n1425\n975\n2400\n59.38\n0\n1790\n1804\n\n\nHarrison\n443\n355\n798\n55.51\n7\n0\n15"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#eda-13",
    "href": "slides/06_logistic_ch6.html#eda-13",
    "title": "Logistic Regression",
    "section": "EDA (1/3)",
    "text": "EDA (1/3)\n\nrr &lt;- rr |&gt;\n  mutate(pctYes = YesVotes/NumVotes, \n         emp_logit = log(pctYes / (1 - pctYes)))\n\nrr |&gt; head(5)\n\n# A tibble: 5 √ó 10\n  County   popBlack popWhite popTotal pctBlack distance YesVotes NumVotes pctYes emp_logit\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1 Carthage      841      599     1440     58.4       17       61      110 0.555      0.219\n2 Cedervi‚Ä¶     1774      146     1920     92.4        7        0       15 0       -Inf    \n3 Five Mi‚Ä¶      140      626      766     18.3       15        4       42 0.0952    -2.25 \n4 Greensb‚Ä¶     1425      975     2400     59.4        0     1790     1804 0.992      4.85 \n5 Harrison      443      355      798     55.5        7        0       15 0       -Inf"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#eda-23",
    "href": "slides/06_logistic_ch6.html#eda-23",
    "title": "Logistic Regression",
    "section": "EDA (2/3)",
    "text": "EDA (2/3)\n\nPlotCode\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3 rows containing non-finite outside the scale range (`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = rr, aes(x = distance, y = emp_logit)) + \n  geom_point() + \n  geom_smooth(method  = \"lm\", se = FALSE) + \n  labs(x = \"Distance to proposed railroad\", \n       y = \" \")\n  \np2 &lt;- ggplot(data = rr, aes(x = pctBlack, y = emp_logit)) + \n  geom_point() + \n  geom_smooth(method  = \"lm\", se = FALSE) + \n  labs(x = \"% Black residents\", \n       y = \"\")\np1 + p2 + plot_annotation(title = \"Log(odds yes vote) vs. predictor variables\")"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#eda-33",
    "href": "slides/06_logistic_ch6.html#eda-33",
    "title": "Logistic Regression",
    "section": "EDA (3/3)",
    "text": "EDA (3/3)\n\nrr &lt;- rr |&gt;\n  mutate(inFavor = if_else(pctYes &gt; 0.5, \"Yes\", \"No\"))\n\n\nPlotCode\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range (`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = rr, aes(x = distance, y = pctBlack, color = inFavor)) + \n  geom_point() + \n  geom_smooth(method  = \"lm\", se = FALSE, aes(lty = inFavor)) + \n  labs(x = \"Distance to proposed railroad\", \n       y = \"% Black residents\",\n       title = \"% Black residents vs. distance\", \n       subtitle = \"Based on vote outcome\") + \n  scale_color_viridis_d(end = 0.85)\n\n\n\n\n\nCheck for potential multicollinearity and interaction effect."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#model",
    "href": "slides/06_logistic_ch6.html#model",
    "title": "Logistic Regression",
    "section": "Model",
    "text": "Model\nLet \\(p\\) be the percent of yes votes in a county. We‚Äôll start by fitting the following model:\n\\[\\log\\Big(\\frac{p}{1-p}\\Big)  = \\beta_0 + \\beta_1 ~ dist + \\beta_2 ~ pctBlack\\]\n\nLikelihood\n\\[\\begin{aligned}L(p) &= \\prod_{i=1}^{n} {m_i \\choose y_i}p_i^{y_i}(1 - p_i)^{m_i - y_i} \\\\\n&= \\prod_{i=1}^{n} {m_i \\choose y_i}\\Big[\\frac{e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}{1 + e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}\\Big]^{y_i}\\Big[\\frac{1}{e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}\\Big]^{m_i - y_i} \\\\\\end{aligned}\\]\nUse IWLS to find \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2\\)."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#model-in-r",
    "href": "slides/06_logistic_ch6.html#model-in-r",
    "title": "Logistic Regression",
    "section": "Model in R",
    "text": "Model in R\n\nrr_model &lt;- glm(cbind(YesVotes, NumVotes - YesVotes) ~ distance + pctBlack, \n                data = rr, family = binomial)\ntidy(rr_model, conf.int = TRUE) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n4.222\n0.297\n14.217\n0.000\n3.644\n4.809\n\n\ndistance\n-0.292\n0.013\n-22.270\n0.000\n-0.318\n-0.267\n\n\npctBlack\n-0.013\n0.004\n-3.394\n0.001\n-0.021\n-0.006\n\n\n\n\n\n\n\\[\\log\\Big(\\frac{\\hat{p}}{1-\\hat{p}}\\Big)  = 4.22 - 0.292 ~ dist - 0.013 ~ pctBlack\\]\n\n\n\nSee Section 6.5 of Generalized Linear Models with Examples in R by Dunn and Smyth (available through Duke library) for details on estimating the standard errors."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#residuals",
    "href": "slides/06_logistic_ch6.html#residuals",
    "title": "Logistic Regression",
    "section": "Residuals",
    "text": "Residuals\nSimilar to Poisson regression, there are two types of residuals: Pearson and deviance residuals\n\nPearson residuals\n\\[\\text{Pearson residual}_i = \\frac{\\text{actual count} - \\text{predicted count}}{\\text{SD count}} = \\frac{Y_i - m_i\\hat{p}_i}{\\sqrt{m_i\\hat{p}_i(1 - \\hat{p}_i)}}\\]\n\n\nDeviance residuals\n\\[d_i = \\text{sign}(Y_i - m_i\\hat{p}_i)\\sqrt{2\\Big[Y_i\\log\\Big(\\frac{Y_i}{m_i\\hat{p}_i}\\Big) + (m_i - Y_i)\\log\\Big(\\frac{m_i - Y_i}{m_i - m_i\\hat{p}_i}\\Big)\\Big]}\\]"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#plot-of-deviance-residuals",
    "href": "slides/06_logistic_ch6.html#plot-of-deviance-residuals",
    "title": "Logistic Regression",
    "section": "Plot of deviance residuals",
    "text": "Plot of deviance residuals\n\nModelResidual PlotPlot Code\n\n\n\nrr_int_model &lt;- glm(cbind(YesVotes, NumVotes - YesVotes) ~ distance + pctBlack +\n                      distance*pctBlack, \n                data = rr, family = binomial)\n\n\nrr_int_aug &lt;- augment(rr_int_model, type.predict = \"response\", \n                        type.residuals = \"deviance\")\n\nrr_int_aug |&gt; slice(1:5) |&gt; kable()\n\nWarning in `[&lt;-.data.frame`(`*tmp*`, , isn, value = structure(list(`cbind(YesVotes,\nNumVotes - YesVotes).YesVotes` = c(\"61\", : provided 10 variables to replace 9 variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.rownames\ncbind(YesVotes, NumVotes - YesVotes)\ndistance\npctBlack\n.fitted\n.resid\n.hat\n.sigma\n.cooksd\n.std.resid\n\n\n\n\n1\n61\n49\n17\n58.40\n0.2075801\n7.964510\n0.4663943\n5.0884957\n32.9667672\n\n\n2\n0\n15\n7\n92.40\n0.6776101\n-5.827504\n0.0492925\n6.3049338\n0.4298496\n\n\n3\n4\n38\n15\n18.28\n0.2024659\n-1.885115\n0.6433983\n6.6366201\n3.7828247\n\n\n4\n1790\n14\n0\n59.38\n0.9760416\n5.230746\n0.8996698\n0.5044966\n452.2582760\n\n\n5\n0\n15\n7\n55.51\n0.8513123\n-7.561561\n0.0240118\n5.9951340\n0.5412285\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = rr_int_aug, aes(x = .fitted, y = .resid)) + \n  geom_point() + \n  geom_hline(yintercept = 0, color = \"red\") + \n  labs(x = \"Fitted values\", \n       y = \"Deviance residuals\", \n       title = \"Deviance residuals vs. fitted\", \n       subtitle = \"for model with interaction term\")"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#goodness-of-fit",
    "href": "slides/06_logistic_ch6.html#goodness-of-fit",
    "title": "Logistic Regression",
    "section": "Goodness of fit",
    "text": "Goodness of fit\nSimilar to Poisson regression, the sum of the squared deviance residuals is used to assess goodness of fit.\n\\[\\begin{aligned} &H_0: \\text{ Model is a good fit} \\\\\n&H_a: \\text{ Model is not a good fit}\\end{aligned}\\]\n\nWhen \\(m_i\\) is large and the model is a good fit \\((H_0 \\text{ true})\\) the residual deviance follows a \\(\\chi^2\\) distribution with \\(n - p\\) degrees of freedom.\n\nRecall \\(n - p\\) is the residual degrees of freedom.\n\nIf the model fits, we expect the residual deviance to be approximately what value?"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#adjusting-for-overdispersion-12",
    "href": "slides/06_logistic_ch6.html#adjusting-for-overdispersion-12",
    "title": "Logistic Regression",
    "section": "Adjusting for overdispersion (1/2)",
    "text": "Adjusting for overdispersion (1/2)\n\nOverdispersion occurs when there is extra-binomial variation, i.e.¬†the variance is greater than what we would expect, \\(np(1-p)\\).\nSimilar to Poisson regression, we can adjust for overdispersion in the binomial regression model by using a dispersion parameter \\[\\hat{\\phi} = \\sum \\frac{(\\text{Pearson residuals})^2}{n-p}\\]\n\nBy multiplying by \\(\\hat{\\phi}\\), we are accounting for the reduction in information we would expect from independent observations."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#adjusting-for-overdispersion-22",
    "href": "slides/06_logistic_ch6.html#adjusting-for-overdispersion-22",
    "title": "Logistic Regression",
    "section": "Adjusting for overdispersion (2/2)",
    "text": "Adjusting for overdispersion (2/2)\n\nWe adjust for overdispersion using a quasibinomial model.\n\n‚ÄúQuasi‚Äù reflects the fact we are no longer using a binomial model with true likelihood.\n\nThe standard errors of the coefficients are \\(SE_{Q}(\\hat{\\beta}_j) = \\sqrt{\\hat{\\phi}} SE(\\hat{\\beta})\\)\n\nInference is done using the \\(t\\) distribution to account for extra variability"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#predicting-ed-wait-and-treatment-times",
    "href": "slides/06_logistic_ch6.html#predicting-ed-wait-and-treatment-times",
    "title": "Logistic Regression",
    "section": "Predicting ED wait and treatment times",
    "text": "Predicting ED wait and treatment times\nAtaman and Sariyer (2021) use ordinal logistic regression to predict patient wait and treatment times in an emergency department (ED). The goal is to identify relevant factors that can be used to inform recommendations for reducing wait and treatment times, thus improving the quality of care in the ED.\nData: Daily records for ED arrivals in August 2018 at a public hospital in Izmir, Turkey.\nResponse variable: Wait time, a categorical variable with three levels: - Patients who wait less than 10 minutes - Patients whose waiting time is in the range of 10-60 minutes - Patients who wait more than 60 minutes\n\n\nAtaman, M. G., & Sarƒ±yer, G. (2021). Predicting waiting and treatment times in emergency departments using ordinal logistic regression models. The American Journal of Emergency Medicine, 46, 45-50."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#ordinal-logistic-regression",
    "href": "slides/06_logistic_ch6.html#ordinal-logistic-regression",
    "title": "Logistic Regression",
    "section": "Ordinal logistic regression",
    "text": "Ordinal logistic regression\nLet \\(Y\\) be an ordinal response variable that takes levels \\(1, 2, \\ldots, J\\) with associated probabilities \\(p_1, p_2, \\ldots, p_J\\).\nThe proportional odds model can be written as the following:\n\\[\\begin{aligned}&\\log\\Big(\\frac{P(Y\\leq 1)}{P(Y &gt; 1)}\\Big) = \\beta_{01} + \\beta_1x_1 + \\dots +  \\beta_px_p \\\\\n& \\log\\Big(\\frac{P(Y\\leq 2)}{P(Y &gt; 2)}\\Big) = \\beta_{02} + \\beta_1x_1 + \\dots +  \\beta_px_p \\\\\n& \\dots \\\\\n& \\log\\Big(\\frac{P(Y\\leq J-1)}{P(Y &gt; J-1)}\\Big) = \\beta_{0{J-1}} + \\beta_1x_1 + \\dots +  \\beta_px_p\\end{aligned}\\]"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#questions",
    "href": "slides/06_logistic_ch6.html#questions",
    "title": "Logistic Regression",
    "section": "Questions",
    "text": "Questions\n\nHow is the proportional odds model similar to the multinomial logistic model?\nHow is it different?"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#effect-of-arrival-mode",
    "href": "slides/06_logistic_ch6.html#effect-of-arrival-mode",
    "title": "Logistic Regression",
    "section": "Effect of arrival mode",
    "text": "Effect of arrival mode\n\n\nQuestion\nThe variable arrival mode takes two categories: ambulance and walk-in. Describe the effect of arrival mode in this model. Note that the baseline level is ‚Äúwalk-in‚Äù."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#effect-of-triage-level",
    "href": "slides/06_logistic_ch6.html#effect-of-triage-level",
    "title": "Logistic Regression",
    "section": "Effect of triage level",
    "text": "Effect of triage level\n\nConsider the full output with the ordinal logistic models for wait and treatment times.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nUse the results from both models to describe the effect of triage level (red = urgent, green = non-urgent) on the wait and treatment times in the ED. Note that ‚Äúred‚Äù is the baseline level. Is this what you expected?"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#wrap-up",
    "href": "slides/06_logistic_ch6.html#wrap-up",
    "title": "Logistic Regression",
    "section": "Wrap up",
    "text": "Wrap up\n\nCovered fitting, interpreting, and drawing conclusions from GLMs\n\nLooked at Poisson, Negative Binomial, and Logistic (binary, binomial, ordinal) in detail\n\nUsed Pearson and deviance residuals to assess model fit and determine if new variables should be added to the model\nAddressed issues of overdispersion and zero-inflation\nUsed the properties of the one-parameter exponential family to identify the best link function for any GLM\n\n\nEverything we‚Äôve done thus far as been under the assumption that the observations are independent. Looking ahead we will consider models for data with dependent (correlated) observations."
  },
  {
    "objectID": "slides/06_logistic_ch6.html#acknowledgements",
    "href": "slides/06_logistic_ch6.html#acknowledgements",
    "title": "Logistic Regression",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in\n\nBMLR: Chapter 6 - Logistic Regression"
  },
  {
    "objectID": "slides/06_logistic_ch6.html#acknowledgements-1",
    "href": "slides/06_logistic_ch6.html#acknowledgements-1",
    "title": "Logistic Regression",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in\n\nBMLR: Chapter 6 - Logistic Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\n\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html",
    "href": "slides/06_logistic_ch6_o.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#setup",
    "href": "slides/06_logistic_ch6_o.html#setup",
    "title": "Logistic Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#learning-goals",
    "href": "slides/06_logistic_ch6_o.html#learning-goals",
    "title": "Logistic Regression",
    "section": "Learning goals",
    "text": "Learning goals\n\nIdentify Bernoulli and binomial random variables\nWrite GLM for binomial response variable\nInterpret the coefficients for a logistic regression model\nVisualizations for logistic regression\nInterpret coefficients and results from an ordinal logistic regression model\nSummarize GLMs for independent observations"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#bernoulli-binomial-random-variables-12",
    "href": "slides/06_logistic_ch6_o.html#bernoulli-binomial-random-variables-12",
    "title": "Logistic Regression",
    "section": "Bernoulli + Binomial random variables (1/2)",
    "text": "Bernoulli + Binomial random variables (1/2)\nLogistic regression is used to analyze data with two types of responses:\n\nBinary: These responses take on two values success \\((Y = 1)\\) or failure \\((Y = 0)\\), yes \\((Y = 1)\\) or no \\((Y = 0)\\), etc.\n\n. . .\n\\[P(Y = y) = p^y(1-p)^{1-y} \\hspace{10mm} y = 0, 1\\]"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#bernoulli-binomial-random-variables-22",
    "href": "slides/06_logistic_ch6_o.html#bernoulli-binomial-random-variables-22",
    "title": "Logistic Regression",
    "section": "Bernoulli + Binomial random variables (2/2)",
    "text": "Bernoulli + Binomial random variables (2/2)\nLogistic regression is used to analyze data with two types of responses:\n\nBinomial: Number of successes in a Bernoulli process, \\(n\\) independent trials with a constant probability of success \\(p\\).\n\n. . .\n\\[P(Y = y) = {n \\choose y}p^{y}(1-p)^{n - y} \\hspace{10mm} y = 0, 1, \\ldots, n\\]\n. . .\nIn both instances, the goal is to model \\(p\\) the probability of success."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#binary-vs.-binomial-data",
    "href": "slides/06_logistic_ch6_o.html#binary-vs.-binomial-data",
    "title": "Logistic Regression",
    "section": "Binary vs.¬†Binomial data",
    "text": "Binary vs.¬†Binomial data\nFor each example, identify if the response is a Bernoulli or Binomial response\n\nUse median age and unemployment rate in a county to predict the percent of Obama votes in the county in the 2008 presidential election.\nUse GPA and MCAT scores to estimate the probability a student is accepted into medical school.\nUse sex, age, and smoking history to estimate the probability an individual has lung cancer.\nUse offensive and defensive statistics from the 2017-2018 NBA season to predict a team‚Äôs winning percentage."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#logistic-regression-model",
    "href": "slides/06_logistic_ch6_o.html#logistic-regression-model",
    "title": "Logistic Regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\n\\(\\log\\Big(\\frac{p}{1-p}\\Big) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p\\)\n\nThe response variable, \\(\\log\\Big(\\frac{p}{1-p}\\Big)\\), is the log(odds) of success, i.e.¬†the logit\nUse the model to calculate the probability of success \\(\\hat{p} = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p}}\\)\nWhen the response is a Bernoulli random variable, the probabilities can be used to classify each observation as a success or failure"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#logistic-vs-linear-regression-model",
    "href": "slides/06_logistic_ch6_o.html#logistic-vs-linear-regression-model",
    "title": "Logistic Regression",
    "section": "Logistic vs linear regression model",
    "text": "Logistic vs linear regression model\n\nPlotCode\n\n\n\n\n\n\n\nGraph from BMLR Chapter 6\n\n\n\n\n\n\n\nset.seed(0)\ndat &lt;- tibble(x=runif(200, -5, 10),\n                  p=exp(-2+1*x)/(1+exp(-2+1*x)),\n                  y=rbinom(200, 1, p),\n                  y2=.3408+.0901*x,\n                  logit=log(p/(1-p)))\ndat2 &lt;- tibble(x = c(dat$x, dat$x),\n               y = c(dat$y2, dat$p),\n               `Regression model` = c(rep(\"linear\", 200),\n                                      rep(\"logistic\", 200)))\n\nggplot() + \n  geom_point(data = dat, aes(x, y)) +\n  geom_line(data = dat2, aes(x, y, linetype = `Regression model`, \n                             color = `Regression model`)) + \n  labs(title = \"Linear vs. logistic regression models for binary response data\") + \n  scale_colour_manual(name = 'Regression model',\n                      values = c('blue', 'red'), \n                      labels = c('linear', 'logistic'), guide ='legend')"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#logit-link",
    "href": "slides/06_logistic_ch6_o.html#logit-link",
    "title": "Logistic Regression",
    "section": "Logit link",
    "text": "Logit link\nBernoulli and Binomial random variables can be written in one-parameter exponential family form, \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\n. . .\nBernoulli\n\\[f(y;p) = e^{y\\log(\\frac{p}{1-p}) + \\log(1-p)}\\]\n. . .\nBinomial\n\\[f(y;n,p) = e^{y\\log(\\frac{p}{1-p}) + n\\log(1-p) + \\log{n \\choose y}}\\]\n. . .\nThey have the same canonical link \\(b(p) = \\log\\big(\\frac{p}{1-p}\\big)\\)"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#assumptions-for-logistic-regression",
    "href": "slides/06_logistic_ch6_o.html#assumptions-for-logistic-regression",
    "title": "Logistic Regression",
    "section": "Assumptions for logistic regression",
    "text": "Assumptions for logistic regression\nThe following assumptions need to be satisfied to use logistic regression to make inferences\n. . .\n1Ô∏è‚É£ \\(\\hspace{0.5mm}\\) Binary response: The response is dichotomous (has two possible outcomes) or is the sum of dichotomous responses\n2Ô∏è‚É£ \\(\\hspace{0.5mm}\\) Independence: The observations must be independent of one another\n3Ô∏è‚É£ \\(\\hspace{0.5mm}\\) Variance structure: Variance of a binomial random variable is \\(np(1-p)\\) \\((n = 1 \\text{ for Bernoulli})\\) , so the variability is highest when \\(p = 0.5\\)\n4Ô∏è‚É£ \\(\\hspace{0.5mm}\\) Linearity: The log of the odds ratio, \\(\\log\\big(\\frac{p}{1-p}\\big)\\), must be a linear function of the predictors \\(x_1, \\ldots, x_p\\)"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#covid-19-infection-prevention-practices-at-food-establishments",
    "href": "slides/06_logistic_ch6_o.html#covid-19-infection-prevention-practices-at-food-establishments",
    "title": "Logistic Regression",
    "section": "COVID-19 infection prevention practices at food establishments",
    "text": "COVID-19 infection prevention practices at food establishments\nResearchers at Wollo Univeristy in Ethiopia conducted a study in July and August 2020 to understand factors associated with good COVID-19 infection prevention practices at food establishments. Their study is published in Andualem et al.¬†(2022)\n\nThey were particularly interested in the understanding implementation of prevention practices at food establishments, given the workers‚Äô increased risk due to daily contact with customers.\n\n\nAndualem, A., Tegegne, B., Ademe, S., Natnael, T., Berihun, G., Abebe, M., ‚Ä¶ & Adane, M. (2022). COVID-19 infection prevention practices among a sample of food handlers of food and drink establishments in Ethiopia. PloS one, 17(1), e0259851."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#the-data",
    "href": "slides/06_logistic_ch6_o.html#the-data",
    "title": "Logistic Regression",
    "section": "The data",
    "text": "The data\n‚ÄúAn institution-based cross-sectional study was conducted among 422 food handlers in Dessie City and Kombolcha Town food and drink establishments in July and August 2020. The study participants were selected using a simple random sampling technique. Data were collected by trained data collectors using a pretested structured questionnaire and an on-the-spot observational checklist.‚Äù\n\n\nAndualem, A., Tegegne, B., Ademe, S., Natnael, T., Berihun, G., Abebe, M., ‚Ä¶ & Adane, M. (2022). COVID-19 infection prevention practices among a sample of food handlers of food and drink establishments in Ethiopia. PloS one, 17(1), e0259851."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#response-variable",
    "href": "slides/06_logistic_ch6_o.html#response-variable",
    "title": "Logistic Regression",
    "section": "Response variable",
    "text": "Response variable\n‚ÄúThe outcome variable of this study was the good or poor practices of COVID-19 infection prevention among food handlers. Nine yes/no questions, one observational checklist and five multiple choice infection prevention practices questions were asked with a minimum score of 1 and maximum score of 25. Good infection prevention practice (the variable of interest) was determined for food handlers who scored 75% or above, whereas poor infection prevention practices refers to those food handlers who scored below 75% on the practice questions.‚Äù\n\n\nAndualem, A., Tegegne, B., Ademe, S., Natnael, T., Berihun, G., Abebe, M., ‚Ä¶ & Adane, M. (2022). COVID-19 infection prevention practices among a sample of food handlers of food and drink establishments in Ethiopia. PloS one, 17(1), e0259851."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#results",
    "href": "slides/06_logistic_ch6_o.html#results",
    "title": "Logistic Regression",
    "section": "Results",
    "text": "Results\n\n\n\nAndualem, A., Tegegne, B., Ademe, S., Natnael, T., Berihun, G., Abebe, M., ‚Ä¶ & Adane, M. (2022). COVID-19 infection prevention practices among a sample of food handlers of food and drink establishments in Ethiopia. PloS one, 17(1), e0259851."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#interpreting-the-results",
    "href": "slides/06_logistic_ch6_o.html#interpreting-the-results",
    "title": "Logistic Regression",
    "section": "Interpreting the results",
    "text": "Interpreting the results\n\nIs the response a Bernoulli or Binomial?\nWhat is the strongest predictor of having good COVID-19 infection prevention practices?\n\nIt‚Äôs often unreliable to look answer this question just based on the model output. Why are we able to answer this question based on the model output in this case?\n\nDescribe the effect (coefficient interpretation and inference) of having COVID-19 infection prevention policies available at the food establishment.\nThe intercept describes what group of food handlers?"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#access-to-personal-protective-equipment",
    "href": "slides/06_logistic_ch6_o.html#access-to-personal-protective-equipment",
    "title": "Logistic Regression",
    "section": "Access to personal protective equipment",
    "text": "Access to personal protective equipment\nWe will use the data from Andualem et al.¬†(2022) to explore the association between age, sex, years of service, and whether someone works at a food establishment with access to personal protective equipment (PPE) as of August 2020. We will use access to PPE as a proxy for wearing PPE.\n\nPlotCode\n\n\n\n\nRows: 401 Columns: 58\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\ndbl (58): Age of food handlers, Sex, Years of service, Specific budget for PPE, Availa...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nage\nsex\nyears\nppe_access\n\n\n\n\n34\nMale\n2\n1\n\n\n32\nFemale\n3\n1\n\n\n32\nFemale\n1\n1\n\n\n40\nMale\n4\n1\n\n\n32\nMale\n10\n1\n\n\n\n\n\n\n\n\ncovid_df &lt;- read_csv(\"data/covid-prevention-study.csv\") |&gt;\n  rename(age = \"Age of food handlers\", \n         years = \"Years of service\", \n         ppe_access = \"Availability of PPEs\") |&gt;\n  mutate(sex = factor(if_else(Sex == 2, \"Female\", \"Male\"))) |&gt;\n  select(age, sex, years, ppe_access) \n\ncovid_df |&gt; slice(1:5) |&gt; kable()"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#eda-for-binary-response-12",
    "href": "slides/06_logistic_ch6_o.html#eda-for-binary-response-12",
    "title": "Logistic Regression",
    "section": "EDA for binary response (1/2)",
    "text": "EDA for binary response (1/2)\n\nlibrary(Stat2Data)\npar(mfrow = c(1, 2))\nemplogitplot1(ppe_access ~ age, data = covid_df, ngroups = 10)\nemplogitplot1(ppe_access ~ years, data = covid_df, ngroups = 5)"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#eda-for-binary-response-22",
    "href": "slides/06_logistic_ch6_o.html#eda-for-binary-response-22",
    "title": "Logistic Regression",
    "section": "EDA for binary response (2/2)",
    "text": "EDA for binary response (2/2)\n\nplotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(viridis)\nggplot(data = covid_df, aes(x = sex, fill = factor(ppe_access))) + \n  geom_bar(position = \"fill\")  +\n  labs(x = \"Sex\", \n       fill = \"PPE Access\", \n       title = \"PPE Access by Sex\") + \n  scale_fill_viridis_d()"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#model-results",
    "href": "slides/06_logistic_ch6_o.html#model-results",
    "title": "Logistic Regression",
    "section": "Model results",
    "text": "Model results\n\nppe_model &lt;- glm(factor(ppe_access) ~ age + sex + years, data = covid_df, \n                 family = binomial)\ntidy(ppe_model, conf.int = TRUE) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-2.127\n0.458\n-4.641\n0.000\n-3.058\n-1.257\n\n\nage\n0.056\n0.017\n3.210\n0.001\n0.023\n0.091\n\n\nsexMale\n0.341\n0.224\n1.524\n0.128\n-0.098\n0.780\n\n\nyears\n0.264\n0.066\n4.010\n0.000\n0.143\n0.401"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#visualizing-coefficient-estimates",
    "href": "slides/06_logistic_ch6_o.html#visualizing-coefficient-estimates",
    "title": "Logistic Regression",
    "section": "Visualizing coefficient estimates",
    "text": "Visualizing coefficient estimates\n\nmodel_coef &lt;- tidy(ppe_model, exponentiate = TRUE, conf.int = TRUE)\n\n\nggplot(data = model_coef, aes(x = term, y = estimate)) +\n  geom_point() +\n  geom_hline(yintercept = 1, lty = 2) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high))+\n  labs(title = \"Exponentiated model coefficients\") + \n  coord_flip()"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#data-supporting-railroads-in-the-1870s",
    "href": "slides/06_logistic_ch6_o.html#data-supporting-railroads-in-the-1870s",
    "title": "Logistic Regression",
    "section": "Data: Supporting railroads in the 1870s",
    "text": "Data: Supporting railroads in the 1870s\nThe data set RR_Data_Hale.csv contains information on support for referendums related to railroad subsidies for 11 communities in Alabama in the 1870s. The data were originally analyzed as part of a thesis project by a student at St.¬†Olaf College. The variables in the data are\n\npctBlack: percentage of Black residents in the county\ndistance: distance the proposed railroad is from the community (in miles)\nYesVotes: number of ‚Äúyes‚Äù votes in favor of the proposed railroad line\nNumVotes: number of votes cast in the election\n\n. . .\nPrimary question: Was voting on the railroad referendum related to the distance from the proposed railroad line, after adjusting for the racial composition of a community?"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#the-data-1",
    "href": "slides/06_logistic_ch6_o.html#the-data-1",
    "title": "Logistic Regression",
    "section": "The data",
    "text": "The data\n\nrr &lt;- read_csv(\"data/RR_Data_Hale.csv\")\n\nRows: 12 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): County\ndbl (7): popBlack, popWhite, popTotal, pctBlack, distance, YesVotes, NumVotes\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrr |&gt; slice(1:5) |&gt; kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCounty\npopBlack\npopWhite\npopTotal\npctBlack\ndistance\nYesVotes\nNumVotes\n\n\n\n\nCarthage\n841\n599\n1440\n58.40\n17\n61\n110\n\n\nCederville\n1774\n146\n1920\n92.40\n7\n0\n15\n\n\nFive Mile Creek\n140\n626\n766\n18.28\n15\n4\n42\n\n\nGreensboro\n1425\n975\n2400\n59.38\n0\n1790\n1804\n\n\nHarrison\n443\n355\n798\n55.51\n7\n0\n15"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#eda-13",
    "href": "slides/06_logistic_ch6_o.html#eda-13",
    "title": "Logistic Regression",
    "section": "EDA (1/3)",
    "text": "EDA (1/3)\n\nrr &lt;- rr |&gt;\n  mutate(pctYes = YesVotes/NumVotes, \n         emp_logit = log(pctYes / (1 - pctYes)))\n\nrr |&gt; head(5)\n\n# A tibble: 5 √ó 10\n  County   popBlack popWhite popTotal pctBlack distance YesVotes NumVotes pctYes emp_logit\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1 Carthage      841      599     1440     58.4       17       61      110 0.555      0.219\n2 Cedervi‚Ä¶     1774      146     1920     92.4        7        0       15 0       -Inf    \n3 Five Mi‚Ä¶      140      626      766     18.3       15        4       42 0.0952    -2.25 \n4 Greensb‚Ä¶     1425      975     2400     59.4        0     1790     1804 0.992      4.85 \n5 Harrison      443      355      798     55.5        7        0       15 0       -Inf"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#eda-23",
    "href": "slides/06_logistic_ch6_o.html#eda-23",
    "title": "Logistic Regression",
    "section": "EDA (2/3)",
    "text": "EDA (2/3)\n\nPlotCode\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3 rows containing non-finite outside the scale range (`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = rr, aes(x = distance, y = emp_logit)) + \n  geom_point() + \n  geom_smooth(method  = \"lm\", se = FALSE) + \n  labs(x = \"Distance to proposed railroad\", \n       y = \" \")\n  \np2 &lt;- ggplot(data = rr, aes(x = pctBlack, y = emp_logit)) + \n  geom_point() + \n  geom_smooth(method  = \"lm\", se = FALSE) + \n  labs(x = \"% Black residents\", \n       y = \"\")\np1 + p2 + plot_annotation(title = \"Log(odds yes vote) vs. predictor variables\")"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#eda-33",
    "href": "slides/06_logistic_ch6_o.html#eda-33",
    "title": "Logistic Regression",
    "section": "EDA (3/3)",
    "text": "EDA (3/3)\n\nrr &lt;- rr |&gt;\n  mutate(inFavor = if_else(pctYes &gt; 0.5, \"Yes\", \"No\"))\n\n\nPlotCode\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range (`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = rr, aes(x = distance, y = pctBlack, color = inFavor)) + \n  geom_point() + \n  geom_smooth(method  = \"lm\", se = FALSE, aes(lty = inFavor)) + \n  labs(x = \"Distance to proposed railroad\", \n       y = \"% Black residents\",\n       title = \"% Black residents vs. distance\", \n       subtitle = \"Based on vote outcome\") + \n  scale_color_viridis_d(end = 0.85)\n\n\n\n\n. . .\nCheck for potential multicollinearity and interaction effect."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#model",
    "href": "slides/06_logistic_ch6_o.html#model",
    "title": "Logistic Regression",
    "section": "Model",
    "text": "Model\nLet \\(p\\) be the percent of yes votes in a county. We‚Äôll start by fitting the following model:\n\\[\\log\\Big(\\frac{p}{1-p}\\Big)  = \\beta_0 + \\beta_1 ~ dist + \\beta_2 ~ pctBlack\\]\n. . .\nLikelihood\n\\[\\begin{aligned}L(p) &= \\prod_{i=1}^{n} {m_i \\choose y_i}p_i^{y_i}(1 - p_i)^{m_i - y_i} \\\\\n&= \\prod_{i=1}^{n} {m_i \\choose y_i}\\Big[\\frac{e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}{1 + e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}\\Big]^{y_i}\\Big[\\frac{1}{e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}\\Big]^{m_i - y_i} \\\\\\end{aligned}\\]\nUse IWLS to find \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2\\)."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#model-in-r",
    "href": "slides/06_logistic_ch6_o.html#model-in-r",
    "title": "Logistic Regression",
    "section": "Model in R",
    "text": "Model in R\n\nrr_model &lt;- glm(cbind(YesVotes, NumVotes - YesVotes) ~ distance + pctBlack, \n                data = rr, family = binomial)\ntidy(rr_model, conf.int = TRUE) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n4.222\n0.297\n14.217\n0.000\n3.644\n4.809\n\n\ndistance\n-0.292\n0.013\n-22.270\n0.000\n-0.318\n-0.267\n\n\npctBlack\n-0.013\n0.004\n-3.394\n0.001\n-0.021\n-0.006\n\n\n\n\n\n. . .\n\\[\\log\\Big(\\frac{\\hat{p}}{1-\\hat{p}}\\Big)  = 4.22 - 0.292 ~ dist - 0.013 ~ pctBlack\\]\n\n\nSee Section 6.5 of Generalized Linear Models with Examples in R by Dunn and Smyth (available through Duke library) for details on estimating the standard errors."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#residuals",
    "href": "slides/06_logistic_ch6_o.html#residuals",
    "title": "Logistic Regression",
    "section": "Residuals",
    "text": "Residuals\nSimilar to Poisson regression, there are two types of residuals: Pearson and deviance residuals\n. . .\nPearson residuals\n\\[\\text{Pearson residual}_i = \\frac{\\text{actual count} - \\text{predicted count}}{\\text{SD count}} = \\frac{Y_i - m_i\\hat{p}_i}{\\sqrt{m_i\\hat{p}_i(1 - \\hat{p}_i)}}\\]\n. . .\nDeviance residuals\n\\[d_i = \\text{sign}(Y_i - m_i\\hat{p}_i)\\sqrt{2\\Big[Y_i\\log\\Big(\\frac{Y_i}{m_i\\hat{p}_i}\\Big) + (m_i - Y_i)\\log\\Big(\\frac{m_i - Y_i}{m_i - m_i\\hat{p}_i}\\Big)\\Big]}\\]"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#plot-of-deviance-residuals",
    "href": "slides/06_logistic_ch6_o.html#plot-of-deviance-residuals",
    "title": "Logistic Regression",
    "section": "Plot of deviance residuals",
    "text": "Plot of deviance residuals\n\nModelResidual PlotPlot Code\n\n\n\nrr_int_model &lt;- glm(cbind(YesVotes, NumVotes - YesVotes) ~ distance + pctBlack +\n                      distance*pctBlack, \n                data = rr, family = binomial)\n\n\nrr_int_aug &lt;- augment(rr_int_model, type.predict = \"response\", \n                        type.residuals = \"deviance\")\n\nrr_int_aug |&gt; slice(1:5) |&gt; kable()\n\nWarning in `[&lt;-.data.frame`(`*tmp*`, , isn, value = structure(list(`cbind(YesVotes,\nNumVotes - YesVotes).YesVotes` = c(\"61\", : provided 10 variables to replace 9 variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.rownames\ncbind(YesVotes, NumVotes - YesVotes)\ndistance\npctBlack\n.fitted\n.resid\n.hat\n.sigma\n.cooksd\n.std.resid\n\n\n\n\n1\n61\n49\n17\n58.40\n0.2075801\n7.964510\n0.4663943\n5.0884957\n32.9667672\n\n\n2\n0\n15\n7\n92.40\n0.6776101\n-5.827504\n0.0492925\n6.3049338\n0.4298496\n\n\n3\n4\n38\n15\n18.28\n0.2024659\n-1.885115\n0.6433983\n6.6366201\n3.7828247\n\n\n4\n1790\n14\n0\n59.38\n0.9760416\n5.230746\n0.8996698\n0.5044966\n452.2582760\n\n\n5\n0\n15\n7\n55.51\n0.8513123\n-7.561561\n0.0240118\n5.9951340\n0.5412285\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = rr_int_aug, aes(x = .fitted, y = .resid)) + \n  geom_point() + \n  geom_hline(yintercept = 0, color = \"red\") + \n  labs(x = \"Fitted values\", \n       y = \"Deviance residuals\", \n       title = \"Deviance residuals vs. fitted\", \n       subtitle = \"for model with interaction term\")"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#goodness-of-fit",
    "href": "slides/06_logistic_ch6_o.html#goodness-of-fit",
    "title": "Logistic Regression",
    "section": "Goodness of fit",
    "text": "Goodness of fit\nSimilar to Poisson regression, the sum of the squared deviance residuals is used to assess goodness of fit.\n\\[\\begin{aligned} &H_0: \\text{ Model is a good fit} \\\\\n&H_a: \\text{ Model is not a good fit}\\end{aligned}\\]\n\nWhen \\(m_i\\) is large and the model is a good fit \\((H_0 \\text{ true})\\) the residual deviance follows a \\(\\chi^2\\) distribution with \\(n - p\\) degrees of freedom.\n\nRecall \\(n - p\\) is the residual degrees of freedom.\n\nIf the model fits, we expect the residual deviance to be approximately what value?"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#adjusting-for-overdispersion-12",
    "href": "slides/06_logistic_ch6_o.html#adjusting-for-overdispersion-12",
    "title": "Logistic Regression",
    "section": "Adjusting for overdispersion (1/2)",
    "text": "Adjusting for overdispersion (1/2)\n\nOverdispersion occurs when there is extra-binomial variation, i.e.¬†the variance is greater than what we would expect, \\(np(1-p)\\).\nSimilar to Poisson regression, we can adjust for overdispersion in the binomial regression model by using a dispersion parameter \\[\\hat{\\phi} = \\sum \\frac{(\\text{Pearson residuals})^2}{n-p}\\]\n\nBy multiplying by \\(\\hat{\\phi}\\), we are accounting for the reduction in information we would expect from independent observations."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#adjusting-for-overdispersion-22",
    "href": "slides/06_logistic_ch6_o.html#adjusting-for-overdispersion-22",
    "title": "Logistic Regression",
    "section": "Adjusting for overdispersion (2/2)",
    "text": "Adjusting for overdispersion (2/2)\n\nWe adjust for overdispersion using a quasibinomial model.\n\n‚ÄúQuasi‚Äù reflects the fact we are no longer using a binomial model with true likelihood.\n\nThe standard errors of the coefficients are \\(SE_{Q}(\\hat{\\beta}_j) = \\sqrt{\\hat{\\phi}} SE(\\hat{\\beta})\\)\n\nInference is done using the \\(t\\) distribution to account for extra variability"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#predicting-ed-wait-and-treatment-times",
    "href": "slides/06_logistic_ch6_o.html#predicting-ed-wait-and-treatment-times",
    "title": "Logistic Regression",
    "section": "Predicting ED wait and treatment times",
    "text": "Predicting ED wait and treatment times\nAtaman and Sariyer (2021) use ordinal logistic regression to predict patient wait and treatment times in an emergency department (ED). The goal is to identify relevant factors that can be used to inform recommendations for reducing wait and treatment times, thus improving the quality of care in the ED.\nData: Daily records for ED arrivals in August 2018 at a public hospital in Izmir, Turkey.\nResponse variable: Wait time, a categorical variable with three levels: - Patients who wait less than 10 minutes - Patients whose waiting time is in the range of 10-60 minutes - Patients who wait more than 60 minutes\n\n\nAtaman, M. G., & Sarƒ±yer, G. (2021). Predicting waiting and treatment times in emergency departments using ordinal logistic regression models. The American Journal of Emergency Medicine, 46, 45-50."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#ordinal-logistic-regression",
    "href": "slides/06_logistic_ch6_o.html#ordinal-logistic-regression",
    "title": "Logistic Regression",
    "section": "Ordinal logistic regression",
    "text": "Ordinal logistic regression\nLet \\(Y\\) be an ordinal response variable that takes levels \\(1, 2, \\ldots, J\\) with associated probabilities \\(p_1, p_2, \\ldots, p_J\\).\nThe proportional odds model can be written as the following:\n\\[\\begin{aligned}&\\log\\Big(\\frac{P(Y\\leq 1)}{P(Y &gt; 1)}\\Big) = \\beta_{01} + \\beta_1x_1 + \\dots +  \\beta_px_p \\\\\n& \\log\\Big(\\frac{P(Y\\leq 2)}{P(Y &gt; 2)}\\Big) = \\beta_{02} + \\beta_1x_1 + \\dots +  \\beta_px_p \\\\\n& \\dots \\\\\n& \\log\\Big(\\frac{P(Y\\leq J-1)}{P(Y &gt; J-1)}\\Big) = \\beta_{0{J-1}} + \\beta_1x_1 + \\dots +  \\beta_px_p\\end{aligned}\\]"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#questions",
    "href": "slides/06_logistic_ch6_o.html#questions",
    "title": "Logistic Regression",
    "section": "Questions",
    "text": "Questions\n\nHow is the proportional odds model similar to the multinomial logistic model?\nHow is it different?"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#effect-of-arrival-mode",
    "href": "slides/06_logistic_ch6_o.html#effect-of-arrival-mode",
    "title": "Logistic Regression",
    "section": "Effect of arrival mode",
    "text": "Effect of arrival mode\n\n\n\n\n\n\n\n\n\n. . .\nQuestion\nThe variable arrival mode takes two categories: ambulance and walk-in. Describe the effect of arrival mode in this model. Note that the baseline level is ‚Äúwalk-in‚Äù."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#effect-of-triage-level",
    "href": "slides/06_logistic_ch6_o.html#effect-of-triage-level",
    "title": "Logistic Regression",
    "section": "Effect of triage level",
    "text": "Effect of triage level\n. . .\nConsider the full output with the ordinal logistic models for wait and treatment times.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n. . .\nUse the results from both models to describe the effect of triage level (red = urgent, green = non-urgent) on the wait and treatment times in the ED. Note that ‚Äúred‚Äù is the baseline level. Is this what you expected?"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#wrap-up",
    "href": "slides/06_logistic_ch6_o.html#wrap-up",
    "title": "Logistic Regression",
    "section": "Wrap up",
    "text": "Wrap up\n\nCovered fitting, interpreting, and drawing conclusions from GLMs\n\nLooked at Poisson, Negative Binomial, and Logistic (binary, binomial, ordinal) in detail\n\nUsed Pearson and deviance residuals to assess model fit and determine if new variables should be added to the model\nAddressed issues of overdispersion and zero-inflation\nUsed the properties of the one-parameter exponential family to identify the best link function for any GLM\n\n. . .\nEverything we‚Äôve done thus far as been under the assumption that the observations are independent. Looking ahead we will consider models for data with dependent (correlated) observations."
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#acknowledgements",
    "href": "slides/06_logistic_ch6_o.html#acknowledgements",
    "title": "Logistic Regression",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in\n\nBMLR: Chapter 6 - Logistic Regression"
  },
  {
    "objectID": "slides/06_logistic_ch6_o.html#acknowledgements-1",
    "href": "slides/06_logistic_ch6_o.html#acknowledgements-1",
    "title": "Logistic Regression",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in\n\nBMLR: Chapter 6 - Logistic Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#setup",
    "href": "slides/04_poisson_ch4.html#setup",
    "title": "Poisson Regression",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#learning-goals-12",
    "href": "slides/04_poisson_ch4.html#learning-goals-12",
    "title": "Poisson Regression",
    "section": "Learning goals (1/2)",
    "text": "Learning goals (1/2)\n\nDescribe properties of the Poisson random variable\nWrite the Poisson regression model\nDescribe how the Poisson regression differs from least-squares regression\nInterpret the coefficients for the Poisson regression model\nCompare two Poisson regression models\nDefine and calculate residuals for the Poisson regression model\nUse Goodness-of-fit to assess model fit"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#learning-goals-22",
    "href": "slides/04_poisson_ch4.html#learning-goals-22",
    "title": "Poisson Regression",
    "section": "Learning goals (2/2)",
    "text": "Learning goals (2/2)\n\nIdentify overdispersion\nApply modeling approaches to deal with overdispersion\nExplore properties of negative binomial versus Poisson response\nFit and interpret models with offset to adjust for differences in sampling effort\nFit and interpret Zero-inflated Poisson models\nWrite likelihood for Poisson and Zero-inflated Poisson model"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#scenarios-to-use-poisson-regression",
    "href": "slides/04_poisson_ch4.html#scenarios-to-use-poisson-regression",
    "title": "Poisson Regression",
    "section": "Scenarios to use Poisson regression",
    "text": "Scenarios to use Poisson regression\n\nDoes the number of employers conducting on-campus interviews during a year differ for public and private colleges?\nDoes the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices?\nDoes the number of paint defects per square foot of wall differ based on the years of experience of the painter?\n\n\nEach response variable is a count per a unit of time or space."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#poisson-distribution",
    "href": "slides/04_poisson_ch4.html#poisson-distribution",
    "title": "Poisson Regression",
    "section": "Poisson distribution",
    "text": "Poisson distribution\nLet \\(Y\\) be the number of events in a given unit of time or space. Then \\(Y\\) can be modeled using a Poisson distribution\n\n\\[P(Y=y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y=0,1,2,\\ldots, \\infty\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#poisson-features",
    "href": "slides/04_poisson_ch4.html#poisson-features",
    "title": "Poisson Regression",
    "section": "Poisson Features",
    "text": "Poisson Features\n\n\\(E(Y) = Var(Y) = \\lambda\\)\nThe distribution is typically skewed right, particularly if \\(\\lambda\\) is small\nThe distribution becomes more symmetric as \\(\\lambda\\) increases\n\nIf \\(\\lambda\\) is sufficiently large, it can be approximated using a normal distribution (Click here for an example.)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#poisson-graphs",
    "href": "slides/04_poisson_ch4.html#poisson-graphs",
    "title": "Poisson Regression",
    "section": "Poisson Graphs",
    "text": "Poisson Graphs\n\nGraphsTable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nVariance\n\n\n\n\nlambda = 1\n0.99351\n0.9902178\n\n\nlambda = 5\n4.99367\n4.9865798\n\n\nlambda = 50\n49.99288\n49.8962683"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#example",
    "href": "slides/04_poisson_ch4.html#example",
    "title": "Poisson Regression",
    "section": "Example",
    "text": "Example\nThe annual number of earthquakes registering at least 2.5 on the Richter Scale and having an epicenter within 40 miles of downtown Memphis follows a Poisson distribution with mean 6.5. What is the probability there will be at 3 or fewer such earthquakes next year?\n\n\\[P(Y \\leq 3) = P(Y = 0) + P(Y = 1) + P(Y = 2) + P(Y = 3)\\]\n\\[ = \\frac{e^{-6.5}6.5^0}{0!} + \\frac{e^{-6.5}6.5^1}{1!} + \\frac{e^{-6.5}6.5^2}{2!} + \\frac{e^{-6.5}6.5^3}{3!}\\]\n\\[ = 0.112\\]\n\n\n\nppois(3, 6.5)\n\n[1] 0.1118496\n\n\n\n\n\nExample adapted from Introduction to Probability Theory Example 28-2"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#poisson-regression-1",
    "href": "slides/04_poisson_ch4.html#poisson-regression-1",
    "title": "Poisson Regression",
    "section": "Poisson regression",
    "text": "Poisson regression\nThe data: Household size in the Philippines\n\nThe data fHH1.csv come from the 2015 Family Income and Expenditure Survey conducted by the Philippine Statistics Authority.\nGoal: Understand the association between household size and various characteristics of the household\nResponse: - total: Number of people in the household other than the head\n\n\nPredictors: - location: Where the house is located - age: Age of the head of household - roof: Type of roof on the residence (proxy for wealth)\n\nOther variables: - numLT5: Number in the household under 5 years old"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#the-data",
    "href": "slides/04_poisson_ch4.html#the-data",
    "title": "Poisson Regression",
    "section": "The data",
    "text": "The data\n\nhh_data &lt;- read_csv(\"data/fHH1.csv\")\nhh_data |&gt; slice(1:5) |&gt; kable()\n\n\n\n\nlocation\nage\ntotal\nnumLT5\nroof\n\n\n\n\nCentralLuzon\n65\n0\n0\nPredominantly Strong Material\n\n\nMetroManila\n75\n3\n0\nPredominantly Strong Material\n\n\nDavaoRegion\n54\n4\n0\nPredominantly Strong Material\n\n\nVisayas\n49\n3\n0\nPredominantly Strong Material\n\n\nMetroManila\n74\n3\n0\nPredominantly Strong Material"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#response-variable",
    "href": "slides/04_poisson_ch4.html#response-variable",
    "title": "Poisson Regression",
    "section": "Response variable",
    "text": "Response variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n3.685\n5.534"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#why-the-least-squares-model-doesnt-work",
    "href": "slides/04_poisson_ch4.html#why-the-least-squares-model-doesnt-work",
    "title": "Poisson Regression",
    "section": "Why the least-squares model doesn‚Äôt work",
    "text": "Why the least-squares model doesn‚Äôt work\nThe goal is to model \\(\\lambda\\), the expected number of people in the household (other than the head), as a function of the predictors (covariates)\n\nWe might be tempted to try a linear model \\[\\lambda_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\dots + \\beta_px_{ip}\\]\n\n\nThis model won‚Äôt work because‚Ä¶\n\nIt could produce negative values of \\(\\lambda\\) for certain values of the predictors\nThe equal variance assumption required to conduct inference for linear regression is violated."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#poisson-regression-model",
    "href": "slides/04_poisson_ch4.html#poisson-regression-model",
    "title": "Poisson Regression",
    "section": "Poisson regression model",
    "text": "Poisson regression model\nIf \\(Y_i \\sim Poisson\\) with \\(\\lambda = \\lambda_i\\) for the given values \\(x_{i1}, \\ldots, x_{ip}\\), then\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}\\]\n\nEach observation can have a different value of \\(\\lambda\\) based on its value of the predictors \\(x_1, \\ldots, x_p\\)\n\\(\\lambda\\) determines the mean and variance, so we don‚Äôt need to estimate a separate error term"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#poisson-vs.-multiple-linear-regression",
    "href": "slides/04_poisson_ch4.html#poisson-vs.-multiple-linear-regression",
    "title": "Poisson Regression",
    "section": "Poisson vs.¬†multiple linear regression",
    "text": "Poisson vs.¬†multiple linear regression\n\n\n\n\n\nRegression models: Linear regression (left) and Poisson regression (right).\n\n\n\n\n\n\nFrom BMLR Figure 4.1"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#assumptions-for-poisson-regression",
    "href": "slides/04_poisson_ch4.html#assumptions-for-poisson-regression",
    "title": "Poisson Regression",
    "section": "Assumptions for Poisson regression",
    "text": "Assumptions for Poisson regression\n\n\nPoisson response: The response variable is a count per unit of time or space, described by a Poisson distribution, at each level of the predictor(s)\nIndependence: The observations must be independent of one another\nMean = Variance: The mean must equal the variance\nLinearity: The log of the mean rate, \\(\\log(\\lambda)\\), must be a linear function of the predictor(s)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#model-1-number-in-household-vs.-age",
    "href": "slides/04_poisson_ch4.html#model-1-number-in-household-vs.-age",
    "title": "Poisson Regression",
    "section": "Model 1: Number in household vs.¬†age",
    "text": "Model 1: Number in household vs.¬†age\n\nmodel1 &lt;- glm(total ~ age, data = hh_data, family = poisson)\n\ntidy(model1) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n\n\n\n\n\n\\[\\log(\\hat{\\lambda}) = 1.5499  - 0.0047 ~ age\\]\n\nQuestion: The coefficient for age is -0.0047. Interpret this coefficient in context."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#answers",
    "href": "slides/04_poisson_ch4.html#answers",
    "title": "Poisson Regression",
    "section": "Answers",
    "text": "Answers\n\nEach additional year older the head of household is, the estimated average log of the number of people in the household is .0047 lower.\nEach additional year older the head of household is, the estimated average number of people in the household reduces by 0.5%.\nEach additional year older the head of household is the estimated average number of people in the household changes by a factor of .995.\nFor every 10 years older the head of household is, the estimated average number of people in the household reduces by 5%."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#understanding-the-interpretation",
    "href": "slides/04_poisson_ch4.html#understanding-the-interpretation",
    "title": "Poisson Regression",
    "section": "Understanding the interpretation",
    "text": "Understanding the interpretation\nLet‚Äôs derive the change in predicted mean when we go from \\(x\\) to \\(x+1\\)\n(see boardwork)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#is-the-coefficient-of-age-statistically-significant",
    "href": "slides/04_poisson_ch4.html#is-the-coefficient-of-age-statistically-significant",
    "title": "Poisson Regression",
    "section": "Is the coefficient of age statistically significant?",
    "text": "Is the coefficient of age statistically significant?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n1.4512\n1.6482\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n-0.0065\n-0.0029\n\n\n\n\n\n\\[H_0: \\beta_1 = 0 \\hspace{2mm} \\text{ vs. } \\hspace{2mm} H_a: \\beta_1 \\neq 0\\]\n\nTest statistic\n\\[Z = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)} = \\frac{-0.0047 - 0}{0.0009} = -5.026 \\text{ (using exact values)}\\]\n\n\nP-value\n\\[P(|Z| &gt; |-5.026|) = 5.01 \\times 10^{-7} \\approx 0\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#what-are-plausible-values-for-the-coefficient-of-age",
    "href": "slides/04_poisson_ch4.html#what-are-plausible-values-for-the-coefficient-of-age",
    "title": "Poisson Regression",
    "section": "What are plausible values for the coefficient of age?",
    "text": "What are plausible values for the coefficient of age?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n1.4512\n1.6482\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n-0.0065\n-0.0029\n\n\n\n\n\n95% confidence interval for the coefficient of age\n\\[\\hat{\\beta}_1 \\pm Z^{*}\\times SE(\\hat{\\beta}_1)\\] \\[-0.0047 \\pm 1.96 \\times 0.0009 = \\mathbf{(-.0065, -0.0029)}\\]\n\nQuestion: Interpret the interval in terms of the change in mean household size."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#which-can-best-help-us-determine-whether-model-1-is-a-good-fit",
    "href": "slides/04_poisson_ch4.html#which-can-best-help-us-determine-whether-model-1-is-a-good-fit",
    "title": "Poisson Regression",
    "section": "Which can best help us determine whether Model 1 is a good fit?",
    "text": "Which can best help us determine whether Model 1 is a good fit?\n:::{.panel-tabset}\nPlots\n\nCode\n\np1 &lt;- ggplot(data = hh_data, aes(x = age, y = total)) + \n  geom_point() + \n  labs(y = \"Total household size\", \n       title = \"Plot A\")\n\np2 &lt;- hh_data |&gt;\n  group_by(age) |&gt; \n  summarise(mean = mean(total)) |&gt;\n  ggplot(aes(x = age, y = mean))+ \n  geom_point() + \n  labs(y = \"Empirical mean household size\", \n       title = \"Plot B\")\n\np3 &lt;- hh_data |&gt;\n  group_by(age) |&gt; \n  summarise(log_mean = log(mean(total))) |&gt;\n  ggplot(aes(x = age, y = log_mean)) + \n  geom_point() + \n  labs(y = \"Log empirical mean household size\", \n       title = \"Plot C\")\n\np1 + p2 + p3 + plot_annotation(tag_levels = 'A')"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#model-2-add-a-quadratic-effect-for-age",
    "href": "slides/04_poisson_ch4.html#model-2-add-a-quadratic-effect-for-age",
    "title": "Poisson Regression",
    "section": "Model 2: Add a quadratic effect for age",
    "text": "Model 2: Add a quadratic effect for age\n\nhh_data &lt;- hh_data |&gt; \n  mutate(age2 = age*age)\n\nmodel2 &lt;- glm(total ~ age + age2, data = hh_data, family = poisson)\ntidy(model2, conf.int = T) |&gt; \n  kable(digits = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3325\n0.1788\n-1.8594\n0.063\n-0.6863\n0.0148\n\n\nage\n0.0709\n0.0069\n10.2877\n0.000\n0.0575\n0.0845\n\n\nage2\n-0.0007\n0.0001\n-11.0578\n0.000\n-0.0008\n-0.0006"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#model-2-add-a-quadratic-effect-for-age-1",
    "href": "slides/04_poisson_ch4.html#model-2-add-a-quadratic-effect-for-age-1",
    "title": "Poisson Regression",
    "section": "Model 2: Add a quadratic effect for age",
    "text": "Model 2: Add a quadratic effect for age\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3325\n0.1788\n-1.8594\n0.063\n-0.6863\n0.0148\n\n\nage\n0.0709\n0.0069\n10.2877\n0.000\n0.0575\n0.0845\n\n\nage2\n-0.0007\n0.0001\n-11.0578\n0.000\n-0.0008\n-0.0006\n\n\n\n\n\nWe can determine whether to keep \\(age^2\\) in the model in two ways:\n1Ô∏è‚É£ Use the p-value (or confidence interval) for the coefficient (since we are adding a single term to the model)\n2Ô∏è‚É£ Conduct a drop-in-deviance test"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#deviance",
    "href": "slides/04_poisson_ch4.html#deviance",
    "title": "Poisson Regression",
    "section": "Deviance",
    "text": "Deviance\nA deviance is a way to measure how the observed data deviates from the model predictions.\n\nIt‚Äôs a measure unexplained variability in the response variable (similar to SSE in linear regression )\nLower deviance means the model is a better fit to the data\n\n\nWe can calculate the ‚Äúdeviance residual‚Äù for each observation in the data (more on the formula later). Let \\((\\text{deviance residual}_i\\) be the deviance residual for the \\(i^{th}\\) observation, then\n\\[\\text{deviance} = \\sum(\\text{deviance residual})_i^2\\]\n\n\nNote: Deviance is also known as the ‚Äúresidual deviance‚Äù"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#drop-in-deviance-test",
    "href": "slides/04_poisson_ch4.html#drop-in-deviance-test",
    "title": "Poisson Regression",
    "section": "Drop-in-Deviance Test",
    "text": "Drop-in-Deviance Test\nWe can use a drop-in-deviance test to compare two models. To conduct the test\n1Ô∏è‚É£ Compute the deviance for each model\n2Ô∏è‚É£ Calculate the drop in deviance\n\\[\\text{drop-in-deviance =  Deviance(reduced model) - Deviance(larger model)}\\]\n\n3Ô∏è‚É£ Given the reduced model is the true model \\((H_0 \\text{ true})\\), then \\[\\text{drop-in-deviance} \\sim \\chi_d^2\\]\nwhere \\(d\\) is the difference in degrees of freedom between the two models (i.e., the difference in number of terms)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#drop-in-deviance---model1-and-model2",
    "href": "slides/04_poisson_ch4.html#drop-in-deviance---model1-and-model2",
    "title": "Poisson Regression",
    "section": "Drop-in-deviance - Model1 and Model2",
    "text": "Drop-in-deviance - Model1 and Model2\n\nanova(model1, model2, test = \"Chisq\") |&gt;\n  kable(digits = 3)\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n1498\n2337.089\nNA\nNA\nNA\n\n\n1497\n2200.944\n1\n136.145\n0\n\n\n\n\n\n\nQuestions:\n\nWrite the null and alternative hypotheses.\nWhat does the value 2337.089 tell you?\nWhat does the value 1 tell you?\nWhat is your conclusion?"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#add-location-to-the-model",
    "href": "slides/04_poisson_ch4.html#add-location-to-the-model",
    "title": "Poisson Regression",
    "section": "Add location to the model?",
    "text": "Add location to the model?\nSuppose we want to add location to the model, so we compare the following models:\nModel A: \\(\\lambda_i = \\beta_0 + \\beta_1 ~ age_i + \\beta_2 ~ age_i^2\\)\nModel B: \\(\\lambda_i =  \\beta_0 + \\beta_1 ~ age_i + \\beta_2 ~ age_i^2 + \\beta_3 ~ Loc1_i + \\beta_4 ~ Loc2_i + \\beta_5 ~ Loc3_i + \\beta_6 ~ Loc4_i\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#question",
    "href": "slides/04_poisson_ch4.html#question",
    "title": "Poisson Regression",
    "section": "Question",
    "text": "Question\nWhich of the following are reliable ways to determine if location should be added to the model?\n\n\nDrop-in-deviance test\nUse the p-value for each coefficient\nLikelihood ratio test\nNested F Test\nBIC"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#add-location-to-the-model-1",
    "href": "slides/04_poisson_ch4.html#add-location-to-the-model-1",
    "title": "Poisson Regression",
    "section": "Add location to the model?",
    "text": "Add location to the model?\n\nmodel3 &lt;- glm(total ~ age + age2 + location, data = hh_data, family = poisson)\n\n\nUse a drop-in-deviance test to determine if Model 2 or Model 3 (with location) is a better fit for the data.\n\n\n\nanova(model2, model3, test = \"Chisq\") |&gt;\n  kable(digits = 3)\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n1497\n2200.944\nNA\nNA\nNA\n\n\n1493\n2187.800\n4\n13.144\n0.011\n\n\n\n\n\nThe p-value is small (0.01 &lt; 0.05), so we conclude that Model 3 is a better fit for the data."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#model-3",
    "href": "slides/04_poisson_ch4.html#model-3",
    "title": "Poisson Regression",
    "section": "Model 3",
    "text": "Model 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n-2.1107\n0.0348\n-0.7444\n-0.0306\n\n\nage\n0.0704\n0.0069\n10.1900\n0.0000\n0.0569\n0.0840\n\n\nage2\n-0.0007\n0.0001\n-10.9437\n0.0000\n-0.0008\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n-0.3605\n0.7185\n-0.1250\n0.0859\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n1.1580\n0.2468\n-0.0423\n0.1641\n\n\nlocationMetroManila\n0.0545\n0.0472\n1.1542\n0.2484\n-0.0378\n0.1473\n\n\nlocationVisayas\n0.1121\n0.0417\n2.6853\n0.0072\n0.0308\n0.1945\n\n\n\n\n\n\nDoes this model sufficiently explain the variability in the mean household size?"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#pearson-residuals",
    "href": "slides/04_poisson_ch4.html#pearson-residuals",
    "title": "Poisson Regression",
    "section": "Pearson residuals",
    "text": "Pearson residuals\nWe can calculate two types of residuals for Poisson regression: Pearson residuals and deviance residuals\n\n\\[\\text{Pearson residual}_i = \\frac{\\text{observed} - \\text{predicted}}{\\text{std. error}} = \\frac{y_i - \\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda}_i}}\\]\n\n\n\nSimilar interpretation as standardized residuals from linear regression\nExpect most to fall between -2 and 2\nUsed to calculate overdispersion parameter"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#deviance-residuals",
    "href": "slides/04_poisson_ch4.html#deviance-residuals",
    "title": "Poisson Regression",
    "section": "Deviance residuals",
    "text": "Deviance residuals\nThe deviance residual indicates how much the observed data deviates from the fitted model\n\\[\\text{deviance residual}_i = \\text{sign}(y_i - \\hat{\\lambda}_i)\\sqrt{2\\Bigg[y_i\\log\\bigg(\\frac{y_i}{\\hat{\\lambda}_i}\\bigg) - (y_i - \\hat{\\lambda}_i)\\Bigg]}\\]\nwhere\n\\[\\text{sign}(y_i - \\hat{\\lambda}_i)  =  \\begin{cases}\n1 & \\text{ if }(y_i - \\hat{\\lambda}_i) &gt; 0 \\\\\n-1 & \\text{ if }(y_i - \\hat{\\lambda}_i) &lt; 0 \\\\\n0 & \\text{ if }(y_i - \\hat{\\lambda}_i) = 0\n\\end{cases}\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#model-3-residual-plots",
    "href": "slides/04_poisson_ch4.html#model-3-residual-plots",
    "title": "Poisson Regression",
    "section": "Model 3: Residual plots",
    "text": "Model 3: Residual plots\n\nmodel3_aug_pearson &lt;- augment(model3, type.residuals = \"pearson\") \nmodel3_aug_deviance &lt;- augment(model3, type.residuals = \"deviance\")\n\n\nPlotsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = model3_aug_pearson, aes(x = .fitted, y = .resid)) + \n  geom_point()  + \n  geom_smooth() + \n  labs(x = \"Fitted values\", \n       y = \"Pearson residuals\", \n       title = \"Pearson residuals vs. fitted\")\n\np2 &lt;-  ggplot(data = model3_aug_deviance, aes(x = .fitted, y = .resid)) + \n  geom_point()  + \n  geom_smooth() + \n  labs(x = \"Fitted values\", \n       y = \"Deviance residuals\", \n       title = \"Deviance residuals vs. fitted\")\n\np1 + p2"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#goodness-of-fit-1",
    "href": "slides/04_poisson_ch4.html#goodness-of-fit-1",
    "title": "Poisson Regression",
    "section": "Goodness-of-fit",
    "text": "Goodness-of-fit\n\nGoal: Use the (residual) deviance to assess how much the predicted values differ from the observed values. Recall \\((\\text{deviance}) = \\sum_{i=1}^{n}(\\text{deviance residual})_i^2\\)\nIf the model sufficiently fits the data, then\n\n\\[\\text{deviance} \\sim \\chi^2_{df}\\]\nwhere \\(df\\) is the model‚Äôs residual degrees of freedom\n\n\nQuestion: What is the probability of observing a deviance larger than the one we‚Äôve observed, given this model sufficiently fits the data?\n\n\n\n\\[P(\\chi^2_{df} &gt; \\text{ deviance})\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#model-3-goodness-of-fit-calculations",
    "href": "slides/04_poisson_ch4.html#model-3-goodness-of-fit-calculations",
    "title": "Poisson Regression",
    "section": "Model 3: Goodness-of-fit calculations",
    "text": "Model 3: Goodness-of-fit calculations\n\nmodel3$deviance\n\n[1] 2187.8\n\nmodel3$df.residual\n\n[1] 1493\n\n\n\npchisq(model3$deviance, model3$df.residual, lower.tail = FALSE)\n\n[1] 3.153732e-29\n\n\nThe probability of observing a deviance greater than 2187.8 is \\(\\approx 0\\), so there is significant evidence of lack-of-fit."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#lack-of-fit",
    "href": "slides/04_poisson_ch4.html#lack-of-fit",
    "title": "Poisson Regression",
    "section": "Lack-of-fit",
    "text": "Lack-of-fit\nThere are a few potential reasons for lack-of-fit:\n\nMissing important interactions or higher-order terms\nMissing important variables (perhaps this means a more comprehensive data set is required)\nThere could be extreme observations causing the deviance to be larger than expected (assess based on the residual plots)\nThere could be a problem with the Poisson model\n\nMay need more flexibility in the model to handle overdispersion"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#overdispersion",
    "href": "slides/04_poisson_ch4.html#overdispersion",
    "title": "Poisson Regression",
    "section": "Overdispersion",
    "text": "Overdispersion\nOverdispersion: There is more variability in the response than what is implied by the Poisson model\n\nTablesCode\n\n\n\n\nOverall\n\n\n\n\n\nmean\nvar\n\n\n\n\n3.685\n5.534\n\n\n\n\n\n\nby Location\n\n\n\n\n\nlocation\nmean\nvar\n\n\n\n\nCentralLuzon\n3.402\n4.152\n\n\nDavaoRegion\n3.390\n4.723\n\n\nIlocosRegion\n3.586\n5.402\n\n\nMetroManila\n3.707\n4.863\n\n\nVisayas\n3.902\n6.602\n\n\n\n\n\n\n\n\n\n\nhh_data |&gt;\n  summarise(mean = mean(total), var = var(total)) |&gt;\n  kable(digits = 3)\n\n\nhh_data |&gt;\n  group_by(location) |&gt;\n  summarise(mean = mean(total), var = var(total)) |&gt;\n  kable(digits = 3)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#why-overdispersion-matters",
    "href": "slides/04_poisson_ch4.html#why-overdispersion-matters",
    "title": "Poisson Regression",
    "section": "Why overdispersion matters",
    "text": "Why overdispersion matters\nIf there is overdispersion, then there is more variation in the response than what‚Äôs implied by a Poisson model. This means\n‚ùå The standard errors of the model coefficients are artificially small\n‚ùå The p-values are artificially small\n‚ùå This could lead to models that are more complex than what is needed\n\nWe can take overdispersion into account by\n\ninflating standard errors by multiplying them by a dispersion factor\nusing a negative-binomial regression model"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#dispersion-parameter",
    "href": "slides/04_poisson_ch4.html#dispersion-parameter",
    "title": "Poisson Regression",
    "section": "Dispersion parameter",
    "text": "Dispersion parameter\nThe dispersion parameter is represented by \\(\\phi\\)\n\\[\\hat{\\phi} =\\frac{\\text{deviance}}{\\text{residual df}} = \\frac{\\sum_{i=1}^{n}(\\text{Pearson residuals})^2}{n - p}\\]\nwhere \\(p\\) is the number of terms in the model (including the intercept)\n\nIf there is no overdispersion \\(\\hat{\\phi} = 1\\)\nIf there is overdispersion \\(\\hat{\\phi} &gt;  1\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#accounting-for-dispersion-in-the-model",
    "href": "slides/04_poisson_ch4.html#accounting-for-dispersion-in-the-model",
    "title": "Poisson Regression",
    "section": "Accounting for dispersion in the model",
    "text": "Accounting for dispersion in the model\nWe inflate the standard errors of the coefficient by multiplying the variance by \\(\\hat{\\phi}\\)\n\n\\[SE_{Q}(\\hat{\\beta}) = \\sqrt{\\hat{\\phi}}  * SE(\\hat{\\beta})\\] - ‚ÄúQ‚Äù stands for quasi-Poisson, since this is an ad-hoc solution - The process for model building and model comparison is called quasilikelihood (similar to likelihood without exact underlying distributions)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#model-3-quasi-poisson-model",
    "href": "slides/04_poisson_ch4.html#model-3-quasi-poisson-model",
    "title": "Poisson Regression",
    "section": "Model 3: Quasi-Poisson model",
    "text": "Model 3: Quasi-Poisson model\n\nmodel3_q &lt;- glm(total ~ age + age2 + location, data = hh_data, \n                family = quasipoisson) #&lt;&lt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n-1.7744\n0.0762\n-0.8134\n0.0358\n\n\nage\n0.0704\n0.0082\n8.5665\n0.0000\n0.0544\n0.0866\n\n\nage2\n-0.0007\n0.0001\n-9.2000\n0.0000\n-0.0009\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n-0.3030\n0.7619\n-0.1451\n0.1058\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n0.9735\n0.3304\n-0.0620\n0.1837\n\n\nlocationMetroManila\n0.0545\n0.0561\n0.9703\n0.3320\n-0.0552\n0.1649\n\n\nlocationVisayas\n0.1121\n0.0497\n2.2574\n0.0241\n0.0156\n0.2103"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#poisson-vs.-q-poisson",
    "href": "slides/04_poisson_ch4.html#poisson-vs.-q-poisson",
    "title": "Poisson Regression",
    "section": "Poisson vs.¬†Q-Poisson",
    "text": "Poisson vs.¬†Q-Poisson\n\n\nPoisson\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n\n\nage\n0.0704\n0.0069\n\n\nage2\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n\n\nlocationMetroManila\n0.0545\n0.0472\n\n\nlocationVisayas\n0.1121\n0.0417\n\n\n\n\n\n\nQuasi-Poisson\n\n\n\n\n\nestimate\nstd.error\n\n\n\n\n-0.3843\n0.2166\n\n\n0.0704\n0.0082\n\n\n-0.0007\n0.0001\n\n\n-0.0194\n0.0640\n\n\n0.0610\n0.0626\n\n\n0.0545\n0.0561\n\n\n0.1121\n0.0497"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#q-poisson-inference-for-coefficients",
    "href": "slides/04_poisson_ch4.html#q-poisson-inference-for-coefficients",
    "title": "Poisson Regression",
    "section": "Q-Poisson: Inference for coefficients",
    "text": "Q-Poisson: Inference for coefficients\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n\n\nage\n0.0704\n0.0082\n\n\nage2\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n\n\nlocationMetroManila\n0.0545\n0.0561\n\n\nlocationVisayas\n0.1121\n0.0497\n\n\n\n\n\n\nTest statistic \\[t = \\frac{\\hat{\\beta} - 0}{SE_{Q}(\\hat{\\beta})} \\sim t_{n-p}\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#negative-binomial-regression-model-1",
    "href": "slides/04_poisson_ch4.html#negative-binomial-regression-model-1",
    "title": "Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\nAnother approach to handle overdispersion is to use a negative binomial regression model\n\nThis has more flexibility than the quasi-Poisson model, because there is a new parameter in addition to \\(\\lambda\\)\n\n\n\nLet \\(Y\\) be a negative binomial random variable, \\(Y\\sim NegBinom(r, p)\\), then\n\\[P(Y = y_i) = {y_i + r - 1 \\choose r - 1}(1-p)^{y_i}p^r \\hspace{5mm} y_i = 0, 1, 2, \\ldots, \\infty\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#negative-binomial-regression-model-2",
    "href": "slides/04_poisson_ch4.html#negative-binomial-regression-model-2",
    "title": "Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\n\nMain idea: Generate a \\(\\lambda\\) for each observation (household) and generate a count using the Poisson random variable with parameter \\(\\lambda\\)\n\nMakes the counts more dispersed than with a single parameter\n\nThink of it as a Poisson model such that \\(\\lambda\\) is also random\n\n\n\\(\\begin{aligned} &\\text{If }Y|\\lambda \\sim Poisson(\\lambda)\\\\\n&\\text{ and } \\lambda \\sim Gamma\\bigg(r, \\frac{1-p}{p}\\bigg)\\\\\n&\\text{ then } Y \\sim NegBinom(r, p)\\end{aligned}\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#negative-binomial-regression-in-r",
    "href": "slides/04_poisson_ch4.html#negative-binomial-regression-in-r",
    "title": "Poisson Regression",
    "section": "Negative binomial regression in R",
    "text": "Negative binomial regression in R\n\nlibrary(MASS)\nmodel3_nb &lt;- glm.nb(total ~ age + age2 + location, data = hh_data)\ntidy(model3_nb) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.3753\n0.2076\n-1.8081\n0.0706\n\n\nage\n0.0699\n0.0079\n8.8981\n0.0000\n\n\nage2\n-0.0007\n0.0001\n-9.5756\n0.0000\n\n\nlocationDavaoRegion\n-0.0219\n0.0625\n-0.3501\n0.7262\n\n\nlocationIlocosRegion\n0.0577\n0.0615\n0.9391\n0.3477\n\n\nlocationMetroManila\n0.0562\n0.0551\n1.0213\n0.3071\n\n\nlocationVisayas\n0.1104\n0.0487\n2.2654\n0.0235"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#data-airbnbs-in-nyc",
    "href": "slides/04_poisson_ch4.html#data-airbnbs-in-nyc",
    "title": "Poisson Regression",
    "section": "Data: Airbnbs in NYC",
    "text": "Data: Airbnbs in NYC\nThe data set NYCairbnb-sample.csv contains information about a random sample of 1000 Airbnbs in New York City. It is a subset of the data on 40628 Airbnbs scraped by Awad et al.¬†(2017).\nVariables\n\nnumber_of_reviews: Number of reviews for the unit on Airbnb (proxy for number of rentals)\nprice: price per night in US dollars\nroom_type: Entire home/apartment, private room, or shared room\ndays: Number of days the unit has been listed (date when info scraped - date when unit first listed on Airbnb)\n\n\n\nData set pulled from BMLR Section 4.11.3."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#data-airbnbs-in-nyc-1",
    "href": "slides/04_poisson_ch4.html#data-airbnbs-in-nyc-1",
    "title": "Poisson Regression",
    "section": "Data: Airbnbs in NYC",
    "text": "Data: Airbnbs in NYC\n\nairbnb &lt;- read_csv(\"data/NYCairbnb-sample.csv\") |&gt;\n  dplyr::select(id, number_of_reviews, days, room_type, price)\n\n\n\n\n\n\nid\nnumber_of_reviews\ndays\nroom_type\nprice\n\n\n\n\n15756544\n16\n1144\nPrivate room\n120\n\n\n14218251\n15\n471\nPrivate room\n89\n\n\n21644\n0\n2600\nPrivate room\n89\n\n\n13667835\n1\n283\nEntire home/apt\n150\n\n\n265912\n0\n1970\nEntire home/apt\n89\n\n\n\n\n\nGoal: Use the price and room type of Airbnbs to describe variation in the number of reviews (a proxy for number of rentals)."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#eda",
    "href": "slides/04_poisson_ch4.html#eda",
    "title": "Poisson Regression",
    "section": "EDA",
    "text": "EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = airbnb, aes(x = number_of_reviews)) + \n  geom_histogram() + \n   labs(x = \"Number of reviews\",\n    title = \"Distribution of number of reviews\")\n\np2 &lt;- airbnb |&gt;\n  filter(price &lt;= 2000) |&gt;\n  group_by(price) |&gt;\n  summarise(log_mean = log(mean(number_of_reviews))) |&gt;\n  ggplot(aes(x = price, y = log_mean)) + \n  geom_point(alpha= 0.7) + \n  geom_smooth() + \n  labs(x = \"Price in  US dollars\",\n    y = \"Log(mean # reviews)\", \n    title = \"Log mean #  of reviews vs. price\", \n    subtitle = \"Airbnbs $2000 or less\")\n\np3 &lt;- airbnb |&gt;\n  filter(price &lt;= 500) |&gt;\n  group_by(price) |&gt;\n  summarise(log_mean = log(mean(number_of_reviews))) |&gt;\n  ggplot(aes(x = price, y = log_mean)) + \n  geom_point(alpha= 0.7) + \n  geom_smooth() + \n  labs(x = \"Price in  US dollars\",\n    y = \"Log(mean # reviews)\", \n    title = \"Log mean # of reviews vs. price\", \n    subtitle = \"Airbnbs $500 or less\")\n\np1  / (p2 + p3)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#eda-1",
    "href": "slides/04_poisson_ch4.html#eda-1",
    "title": "Poisson Regression",
    "section": "EDA",
    "text": "EDA\n\n\nOverall\n\n\n\n\n\nmean\nvar\n\n\n\n\n15.916\n765.969\n\n\n\n\n\n\nby Room type\n\n\n\n\n\nroom_type\nmean\nvar\n\n\n\n\nEntire home/apt\n16.283\n760.348\n\n\nPrivate room\n15.608\n786.399\n\n\nShared room\n15.028\n605.971"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#considerations-for-modeling",
    "href": "slides/04_poisson_ch4.html#considerations-for-modeling",
    "title": "Poisson Regression",
    "section": "Considerations for modeling",
    "text": "Considerations for modeling\nWe would like to fit the Poisson regression model\n\\[\\log(\\lambda) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2\\]\n\nQuestion: - Based on the EDA, what are some potential issues we may want to address in the model building?\n\nSuppose any model fit issues are addressed. What are some potential limitations to the conclusions and interpretations from the model?"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#offset",
    "href": "slides/04_poisson_ch4.html#offset",
    "title": "Poisson Regression",
    "section": "Offset",
    "text": "Offset\n\nSometimes counts are not directly comparable because the observations differ based on some characteristic directly related to the counts, i.e.¬†the sampling effort.\nAn offset can be used to adjust for differences in sampling effort.\n\n\n\nLet \\(x_{offset}\\) be the variable that accounts for differences in sampling effort, then \\(\\log(x_{offset})\\) will be added to the model.\n\n\n\n\\(\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ x_{i1} + \\beta_2 ~ x_{i2} + ... + \\beta_p ~ x_{ip} + \\log(x_{offset_i})\\)\n\nThe offset is a term in the model with coefficient always equal to 1."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#adding-an-offset-to-the-airbnb-model",
    "href": "slides/04_poisson_ch4.html#adding-an-offset-to-the-airbnb-model",
    "title": "Poisson Regression",
    "section": "Adding an offset to the Airbnb model",
    "text": "Adding an offset to the Airbnb model\nWe will add the offset \\(\\log(days)\\) to the model. This accounts for the fact that we would expect Airbnbs that have been listed longer to have more reviews.\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i + \\log(days_i)\\] \nNote: The response variable for the model is still \\(\\log(\\lambda_i)\\), the log mean number of reviews"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#detail-on-the-offset",
    "href": "slides/04_poisson_ch4.html#detail-on-the-offset",
    "title": "Poisson Regression",
    "section": "Detail on the offset",
    "text": "Detail on the offset\nWe want to adjust for the number of days, so we are interested in \\(\\frac{reviews}{days}\\).\n\nGiven \\(\\lambda\\) is the mean number of reviews\n\\[\\log\\Big(\\frac{\\lambda}{days}\\Big) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2\\]\n\n\n\\[\\Rightarrow \\log({\\lambda}) - \\log(days) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2\\]\n\n\n\\[\\Rightarrow \\log({\\lambda}) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2 + \\log(days)\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#airbnb-model-in-r",
    "href": "slides/04_poisson_ch4.html#airbnb-model-in-r",
    "title": "Poisson Regression",
    "section": "Airbnb model in R",
    "text": "Airbnb model in R\n\nairbnb_model &lt;- glm(number_of_reviews ~ price + room_type, \n                    data = airbnb, family = poisson, \n                    offset = log(days)) #&lt;&lt;\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1351\n0.0170\n-243.1397\n0\n\n\nprice\n-0.0005\n0.0001\n-7.0952\n0\n\n\nroom_typePrivate room\n-0.0994\n0.0174\n-5.6986\n0\n\n\nroom_typeShared room\n0.2436\n0.0452\n5.3841\n0\n\n\n\n\n\n\nThe coefficient for \\(\\log(days)\\) is fixed at 1, so it is not in the model output."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#interpretations",
    "href": "slides/04_poisson_ch4.html#interpretations",
    "title": "Poisson Regression",
    "section": "Interpretations",
    "text": "Interpretations\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1351\n0.0170\n-243.1397\n0\n\n\nprice\n-0.0005\n0.0001\n-7.0952\n0\n\n\nroom_typePrivate room\n-0.0994\n0.0174\n-5.6986\n0\n\n\nroom_typeShared room\n0.2436\n0.0452\n5.3841\n0\n\n\n\n\n\n\nQuestion:\n\nInterpret the coefficient of price.\nInterpret the coefficient of room_typePrivate room"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#goodness-of-fit-2",
    "href": "slides/04_poisson_ch4.html#goodness-of-fit-2",
    "title": "Poisson Regression",
    "section": "Goodness-of-fit",
    "text": "Goodness-of-fit\n\\[\\begin{aligned}&H_0: \\text{ The model is a good fit for the data}\\\\\n&H_a: \\text{ There is significant lack of fit}\\end{aligned}\\]\n\npchisq(airbnb_model$deviance, airbnb_model$df.residual, lower.tail = F)\n\n[1] 0\n\n\n\nThere is evidence of significant lack of fit in the model. Therefore, more models would need to be explored that address the issues mentioned earlier.\n\n\nIn practice we would assess goodness-of-fit and finalize the model before any interpretations and conclusions."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#data-weekend-drinking",
    "href": "slides/04_poisson_ch4.html#data-weekend-drinking",
    "title": "Poisson Regression",
    "section": "Data: Weekend drinking",
    "text": "Data: Weekend drinking\nThe data weekend-drinks.csv contains information from a survey of 77 students in a introductory statistics course on a dry campus.\nVariables\n\ndrinks: Number of drinks they had in the past weekend\noff_campus: 1 - lives off campus, 0 otherwise\nfirst_year: 1 - student is a first-year, 0 otherwise\nsex: f - student identifies as female, m - student identifies as male\n\n\nGoal: The goal is explore factors related to drinking behavior on a dry campus.\n\n\n\nCase study in BMLR - Section 4.10"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#eda-response-variable",
    "href": "slides/04_poisson_ch4.html#eda-response-variable",
    "title": "Poisson Regression",
    "section": "EDA: Response variable",
    "text": "EDA: Response variable"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#observed-vs.-expected-response",
    "href": "slides/04_poisson_ch4.html#observed-vs.-expected-response",
    "title": "Poisson Regression",
    "section": "Observed vs.¬†expected response",
    "text": "Observed vs.¬†expected response\n\n\nWhat does it mean to be a ‚Äúzero‚Äù in this data?"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#two-types-of-zeros",
    "href": "slides/04_poisson_ch4.html#two-types-of-zeros",
    "title": "Poisson Regression",
    "section": "Two types of zeros",
    "text": "Two types of zeros\nThere are two types of zeros\n\nThose who happen to have a zero in the data set (people who drink but happened to not drink last weekend)\nThose who will always report a value of zero (non-drinkers)\n\nThese are called true zeros\n\n\n\nWe introduce a new parameter \\(\\alpha\\) for the proportion of true zeros, then fit a model that has two components:\n\n\n1Ô∏è‚É£ The association between mean number of drinks and various characteristics among those who drink\n2Ô∏è‚É£ The estimated proportion of non-drinkers"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#zero-inflated-poisson-model-1",
    "href": "slides/04_poisson_ch4.html#zero-inflated-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Zero-inflated Poisson model",
    "text": "Zero-inflated Poisson model\nZero-inflated Poisson (ZIP) model has two parts\n\n1Ô∏è‚É£ Association, among those who drink, between the mean number of drinks and predictors sex and off campus residence\n\n\n\\[\\log(\\lambda) = \\beta_0 + \\beta_1 ~ off\\_campus + \\beta_2 ~ sex\\] where \\(\\lambda\\) is the mean number of drinks among those who drink\n\n\n2Ô∏è‚É£ Probability that a student does not drink\n\\[\\text{logit}(\\alpha) = \\log\\Big(\\frac{\\alpha}{1- \\alpha}\\Big) = \\beta_0 + \\beta_1 ~ first\\_year\\]\nwhere \\(\\alpha\\) is the proportion of non-drinkers\n\n\nNote: The same variables can be used in each component"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#details-of-the-zip-model",
    "href": "slides/04_poisson_ch4.html#details-of-the-zip-model",
    "title": "Poisson Regression",
    "section": "Details of the ZIP model",
    "text": "Details of the ZIP model\n\nThe ZIP model is a special case of a latent variable model\n\nA type of mixture model where observations for one or more groups occur together but the group membership unknown\n\nZero-inflated models are a common type of mixture model; they apply beyond Poisson regression"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#zip-model-in-r",
    "href": "slides/04_poisson_ch4.html#zip-model-in-r",
    "title": "Poisson Regression",
    "section": "ZIP model in R",
    "text": "ZIP model in R\nFit ZIP models using the zeroinfl function from the pscl R package.\n\nlibrary(pscl)\n\ndrinks_zip &lt;- zeroinfl(drinks ~ off_campus + sex | first_year,\n                data = drinks)\ndrinks_zip\n\n\nCall:\nzeroinfl(formula = drinks ~ off_campus + sex | first_year, data = drinks)\n\nCount model coefficients (poisson with log link):\n(Intercept)   off_campus         sexm  \n     0.7543       0.4159       1.0209  \n\nZero-inflation model coefficients (binomial with logit link):\n(Intercept)   first_year  \n    -0.6036       1.1364"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#tidy-output",
    "href": "slides/04_poisson_ch4.html#tidy-output",
    "title": "Poisson Regression",
    "section": "Tidy output",
    "text": "Tidy output\nUse the tidy function from the poissonreg package for tidy model output.\n\nlibrary(poissonreg)\n\n\nMean number of drinks among those who drink\n\ntidy(drinks_zip, type = \"count\") %&gt;% kable(digits = 3)\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\ncount\n0.754\n0.144\n5.238\n0.000\n\n\noff_campus\ncount\n0.416\n0.206\n2.021\n0.043\n\n\nsexm\ncount\n1.021\n0.175\n5.827\n0.000"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#tidy-output-1",
    "href": "slides/04_poisson_ch4.html#tidy-output-1",
    "title": "Poisson Regression",
    "section": "Tidy output",
    "text": "Tidy output\nProportion of non-drinkers\n\ntidy(drinks_zip, type = \"zero\") %&gt;% kable(digits = 3)\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\nzero\n-0.604\n0.311\n-1.938\n0.053\n\n\nfirst_year\nzero\n1.136\n0.610\n1.864\n0.062"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#interpreting-the-model-coefficients",
    "href": "slides/04_poisson_ch4.html#interpreting-the-model-coefficients",
    "title": "Poisson Regression",
    "section": "Interpreting the model coefficients",
    "text": "Interpreting the model coefficients\n\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\ncount\n0.754\n0.144\n5.238\n0.000\n\n\noff_campus\ncount\n0.416\n0.206\n2.021\n0.043\n\n\nsexm\ncount\n1.021\n0.175\n5.827\n0.000\n\n\n\n\n\n\nQuestions\n\nInterpret the intercept.\nInterpret the coefficients of off_campus and sexm."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#estimated-proportion-zeros",
    "href": "slides/04_poisson_ch4.html#estimated-proportion-zeros",
    "title": "Poisson Regression",
    "section": "Estimated proportion zeros",
    "text": "Estimated proportion zeros\n\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\nzero\n-0.604\n0.311\n-1.938\n0.053\n\n\nfirst_year\nzero\n1.136\n0.610\n1.864\n0.062\n\n\n\n\n\nQuestions:\nBased on the model‚Ä¶\n\nWhat is the probability a first-year student is a non-drinker?\nWhat is the probability a upperclass student (sophomore, junior, senior) is a non-drinker?"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#these-are-just-a-few-of-the-many-models",
    "href": "slides/04_poisson_ch4.html#these-are-just-a-few-of-the-many-models",
    "title": "Poisson Regression",
    "section": "These are just a few of the many models‚Ä¶",
    "text": "These are just a few of the many models‚Ä¶\n\nUse the Vuong Test to compare the fit of the ZIP model to a regular Poisson model\n\nWhy can‚Äôt we use a drop-in-deviance test?\n\nWe‚Äôve just discussed the ZIP model here, but there are other model applications beyond the standard Poisson regression model (e.g., hurdle models, Zero-inflated Negative Binomial models, etc. )"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#estimating-coefficients-in-poisson-model",
    "href": "slides/04_poisson_ch4.html#estimating-coefficients-in-poisson-model",
    "title": "Poisson Regression",
    "section": "Estimating coefficients in Poisson model",
    "text": "Estimating coefficients in Poisson model\n\nLeast squares estimation would not work because the normality and equal variance assumptions don‚Äôt hold for Poisson regression\nMaximum likelihood estimation is used to estimate the coefficients of Poisson regression.\nThe likelihood is the product of the probabilities for the \\(n\\) independent observations in the data"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#likelihood-for-regular-poisson-model",
    "href": "slides/04_poisson_ch4.html#likelihood-for-regular-poisson-model",
    "title": "Poisson Regression",
    "section": "Likelihood for regular Poisson model",
    "text": "Likelihood for regular Poisson model\nLet‚Äôs go back to example about household size in the Philippines. We will focus on the model using the main effect of age to understand variability in mean household size.\n\nSuppose the first five observations have household sizes of 4, 2, 8, 6, and 1. Then the likelihood is\n\n\n\\(L = \\frac{e^{-\\lambda_1}\\lambda_1^4}{4!} * \\frac{e^{-\\lambda_2}\\lambda_2^2}{2!} * \\frac{e^{-\\lambda_3}\\lambda_3^8}{8!} *\n\\frac{e^{-\\lambda_4}\\lambda_4^6}{6!} * \\frac{e^{-\\lambda_5}\\lambda_5^1}{1!}\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#likelihood-for-regular-poisson-model-1",
    "href": "slides/04_poisson_ch4.html#likelihood-for-regular-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Likelihood for regular Poisson model",
    "text": "Likelihood for regular Poisson model\nWe will use the log likelihood to make finding the MLE easier\n\n\\(\\begin{aligned}\\log(L) &= -\\lambda_1 + 4\\log(\\lambda_1) - \\lambda_2 + 2\\log(\\lambda_2) - \\lambda_3 + 8\\log(\\lambda_3)\\\\ & -\\lambda_4 + 6 \\log(\\lambda_4) - \\lambda_5 + \\log(\\lambda_5) + C \\end{aligned}\\)\nwhere - \\(\\lambda\\) is the mean number in household depending on \\(x_i\\) - \\(C = -[\\log(4!) + \\log(2!) + \\log(8!) + \\log(6!)+ \\log(1!)]\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#likelihood-for-regular-poisson-model-2",
    "href": "slides/04_poisson_ch4.html#likelihood-for-regular-poisson-model-2",
    "title": "Poisson Regression",
    "section": "Likelihood for regular Poisson model",
    "text": "Likelihood for regular Poisson model\nGiven the age of the head of the household, we fit the model\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1~age_i\\]\nThen we replace each \\(\\lambda_i\\) in \\(\\log(L)\\) with \\(e^{\\beta_0 + \\beta_1~age_i}\\).\n\nSuppose the first five observations have ages \\(X = (32, 21, 55, 44, 28)\\). Then\n\n\n\\[\\begin{aligned} \\log(L) &= [-e^{\\beta_0 + \\beta_132}+ 4(\\beta_0 + \\beta_1 32)] + [ - e^{\\beta_0 + \\beta_121} + 2(\\beta_0 + \\beta_121)] \\\\ &+  [- e^{\\beta_0 + \\beta_155} + 8(\\beta_0 + \\beta_155)] +  [-e^{\\beta_0 + \\beta_144} + 6(\\beta_0 + \\beta_144)] \\\\ &+ [-e^{\\beta_0 + \\beta_128}(\\beta_0 + \\beta_128)] + C \\end{aligned}\\]\n\n\nUse search algorithm to find the values of \\(\\beta_0\\) and \\(\\beta_1\\) that maximize the above equation."
  },
  {
    "objectID": "slides/04_poisson_ch4.html#probabilities-under-zip-model",
    "href": "slides/04_poisson_ch4.html#probabilities-under-zip-model",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nThere are three different types of observations in the data:\n\nObserved zero and will always be 0 (true zeros)\nObserved 0 but will not always be 0\nObserved non-zero count and will not always be 0"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#probabilities-under-zip-model-1",
    "href": "slides/04_poisson_ch4.html#probabilities-under-zip-model-1",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nTrue zeros\n\\[P(0 | \\text{true zero})= \\alpha\\]\n\nObserved 0 but will not always be 0\n\\[P(0 | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^0}{0!}\\]\n\n\nDid not observe 0 and will not always be 0\n\\[P(z_i | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^{z_i}}{z_i!}\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#probabilities-under-zip-model-2",
    "href": "slides/04_poisson_ch4.html#probabilities-under-zip-model-2",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nPutting this all together. Let \\(y_i\\) be an observed response then\n\\[P(Y_i = y_i | x_i) = \\begin{cases}\n\\alpha + (1 - \\alpha)e^{-\\lambda_i} && \\text{ if } y_i = 0 \\\\\n(1 - \\alpha)\\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}{y_i!} && \\text{ if } y_i &gt; 0\n\\end{cases}\\]\n\nRecall from our example,\n\\[\\lambda_i = e^{\\beta_0 + \\beta_1~off\\_campus_i + \\beta_2 ~ sex_i}\\]\n\\[\\alpha_i = \\frac{e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}{1 + e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}\\]\n\nPlug in \\(\\lambda_i\\) and \\(\\alpha_i\\) into the above equation obtain the likelihood function"
  },
  {
    "objectID": "slides/04_poisson_ch4.html#acknowledgements",
    "href": "slides/04_poisson_ch4.html#acknowledgements",
    "title": "Poisson Regression",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 4\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html",
    "href": "slides/04_poisson_ch4_o.html",
    "title": "Poisson Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#setup",
    "href": "slides/04_poisson_ch4_o.html#setup",
    "title": "Poisson Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#learning-goals-12",
    "href": "slides/04_poisson_ch4_o.html#learning-goals-12",
    "title": "Poisson Regression",
    "section": "Learning goals (1/2)",
    "text": "Learning goals (1/2)\n\nDescribe properties of the Poisson random variable\nWrite the Poisson regression model\nDescribe how the Poisson regression differs from least-squares regression\nInterpret the coefficients for the Poisson regression model\nCompare two Poisson regression models\nDefine and calculate residuals for the Poisson regression model\nUse Goodness-of-fit to assess model fit"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#learning-goals-22",
    "href": "slides/04_poisson_ch4_o.html#learning-goals-22",
    "title": "Poisson Regression",
    "section": "Learning goals (2/2)",
    "text": "Learning goals (2/2)\n\nIdentify overdispersion\nApply modeling approaches to deal with overdispersion\nExplore properties of negative binomial versus Poisson response\nFit and interpret models with offset to adjust for differences in sampling effort\nFit and interpret Zero-inflated Poisson models\nWrite likelihood for Poisson and Zero-inflated Poisson model"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#scenarios-to-use-poisson-regression",
    "href": "slides/04_poisson_ch4_o.html#scenarios-to-use-poisson-regression",
    "title": "Poisson Regression",
    "section": "Scenarios to use Poisson regression",
    "text": "Scenarios to use Poisson regression\n\nDoes the number of employers conducting on-campus interviews during a year differ for public and private colleges?\nDoes the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices?\nDoes the number of paint defects per square foot of wall differ based on the years of experience of the painter?\n\n. . .\nEach response variable is a count per a unit of time or space."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#poisson-distribution",
    "href": "slides/04_poisson_ch4_o.html#poisson-distribution",
    "title": "Poisson Regression",
    "section": "Poisson distribution",
    "text": "Poisson distribution\nLet \\(Y\\) be the number of events in a given unit of time or space. Then \\(Y\\) can be modeled using a Poisson distribution\n. . .\n\\[P(Y=y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y=0,1,2,\\ldots, \\infty\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#poisson-features",
    "href": "slides/04_poisson_ch4_o.html#poisson-features",
    "title": "Poisson Regression",
    "section": "Poisson Features",
    "text": "Poisson Features\n\n\\(E(Y) = Var(Y) = \\lambda\\)\nThe distribution is typically skewed right, particularly if \\(\\lambda\\) is small\nThe distribution becomes more symmetric as \\(\\lambda\\) increases\n\nIf \\(\\lambda\\) is sufficiently large, it can be approximated using a normal distribution (Click here for an example.)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#poisson-graphs",
    "href": "slides/04_poisson_ch4_o.html#poisson-graphs",
    "title": "Poisson Regression",
    "section": "Poisson Graphs",
    "text": "Poisson Graphs\n\nGraphsTable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nVariance\n\n\n\n\nlambda = 1\n0.99351\n0.9902178\n\n\nlambda = 5\n4.99367\n4.9865798\n\n\nlambda = 50\n49.99288\n49.8962683"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#example",
    "href": "slides/04_poisson_ch4_o.html#example",
    "title": "Poisson Regression",
    "section": "Example",
    "text": "Example\nThe annual number of earthquakes registering at least 2.5 on the Richter Scale and having an epicenter within 40 miles of downtown Memphis follows a Poisson distribution with mean 6.5. What is the probability there will be at 3 or fewer such earthquakes next year?\n. . .\n\\[P(Y \\leq 3) = P(Y = 0) + P(Y = 1) + P(Y = 2) + P(Y = 3)\\]\n\\[ = \\frac{e^{-6.5}6.5^0}{0!} + \\frac{e^{-6.5}6.5^1}{1!} + \\frac{e^{-6.5}6.5^2}{2!} + \\frac{e^{-6.5}6.5^3}{3!}\\]\n\\[ = 0.112\\]\n. . .\n\nppois(3, 6.5)\n\n[1] 0.1118496\n\n\n\n\nExample adapted from Introduction to Probability Theory Example 28-2"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#poisson-regression-1",
    "href": "slides/04_poisson_ch4_o.html#poisson-regression-1",
    "title": "Poisson Regression",
    "section": "Poisson regression",
    "text": "Poisson regression\nThe data: Household size in the Philippines\n\nThe data fHH1.csv come from the 2015 Family Income and Expenditure Survey conducted by the Philippine Statistics Authority.\nGoal: Understand the association between household size and various characteristics of the household\nResponse: - total: Number of people in the household other than the head\n\n\nPredictors: - location: Where the house is located - age: Age of the head of household - roof: Type of roof on the residence (proxy for wealth)\n\nOther variables: - numLT5: Number in the household under 5 years old"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#the-data",
    "href": "slides/04_poisson_ch4_o.html#the-data",
    "title": "Poisson Regression",
    "section": "The data",
    "text": "The data\n\nhh_data &lt;- read_csv(\"data/fHH1.csv\")\nhh_data |&gt; slice(1:5) |&gt; kable()\n\n\n\n\nlocation\nage\ntotal\nnumLT5\nroof\n\n\n\n\nCentralLuzon\n65\n0\n0\nPredominantly Strong Material\n\n\nMetroManila\n75\n3\n0\nPredominantly Strong Material\n\n\nDavaoRegion\n54\n4\n0\nPredominantly Strong Material\n\n\nVisayas\n49\n3\n0\nPredominantly Strong Material\n\n\nMetroManila\n74\n3\n0\nPredominantly Strong Material"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#response-variable",
    "href": "slides/04_poisson_ch4_o.html#response-variable",
    "title": "Poisson Regression",
    "section": "Response variable",
    "text": "Response variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n3.685\n5.534"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#why-the-least-squares-model-doesnt-work",
    "href": "slides/04_poisson_ch4_o.html#why-the-least-squares-model-doesnt-work",
    "title": "Poisson Regression",
    "section": "Why the least-squares model doesn‚Äôt work",
    "text": "Why the least-squares model doesn‚Äôt work\nThe goal is to model \\(\\lambda\\), the expected number of people in the household (other than the head), as a function of the predictors (covariates)\n. . .\nWe might be tempted to try a linear model \\[\\lambda_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\dots + \\beta_px_{ip}\\]\n. . .\nThis model won‚Äôt work because‚Ä¶\n\nIt could produce negative values of \\(\\lambda\\) for certain values of the predictors\nThe equal variance assumption required to conduct inference for linear regression is violated."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#poisson-regression-model",
    "href": "slides/04_poisson_ch4_o.html#poisson-regression-model",
    "title": "Poisson Regression",
    "section": "Poisson regression model",
    "text": "Poisson regression model\nIf \\(Y_i \\sim Poisson\\) with \\(\\lambda = \\lambda_i\\) for the given values \\(x_{i1}, \\ldots, x_{ip}\\), then\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}\\]\n\nEach observation can have a different value of \\(\\lambda\\) based on its value of the predictors \\(x_1, \\ldots, x_p\\)\n\\(\\lambda\\) determines the mean and variance, so we don‚Äôt need to estimate a separate error term"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#poisson-vs.-multiple-linear-regression",
    "href": "slides/04_poisson_ch4_o.html#poisson-vs.-multiple-linear-regression",
    "title": "Poisson Regression",
    "section": "Poisson vs.¬†multiple linear regression",
    "text": "Poisson vs.¬†multiple linear regression\n\n\n\n\n\nRegression models: Linear regression (left) and Poisson regression (right).\n\n\n\n\n\n\nFrom BMLR Figure 4.1"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#assumptions-for-poisson-regression",
    "href": "slides/04_poisson_ch4_o.html#assumptions-for-poisson-regression",
    "title": "Poisson Regression",
    "section": "Assumptions for Poisson regression",
    "text": "Assumptions for Poisson regression\n\n\nPoisson response: The response variable is a count per unit of time or space, described by a Poisson distribution, at each level of the predictor(s)\nIndependence: The observations must be independent of one another\nMean = Variance: The mean must equal the variance\nLinearity: The log of the mean rate, \\(\\log(\\lambda)\\), must be a linear function of the predictor(s)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#model-1-number-in-household-vs.-age",
    "href": "slides/04_poisson_ch4_o.html#model-1-number-in-household-vs.-age",
    "title": "Poisson Regression",
    "section": "Model 1: Number in household vs.¬†age",
    "text": "Model 1: Number in household vs.¬†age\n\nmodel1 &lt;- glm(total ~ age, data = hh_data, family = poisson)\n\ntidy(model1) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n\n\n\n\n\n\\[\\log(\\hat{\\lambda}) = 1.5499  - 0.0047 ~ age\\]\n. . .\nQuestion: The coefficient for age is -0.0047. Interpret this coefficient in context."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#answers",
    "href": "slides/04_poisson_ch4_o.html#answers",
    "title": "Poisson Regression",
    "section": "Answers",
    "text": "Answers\n\nEach additional year older the head of household is, the estimated average log of the number of people in the household is .0047 lower.\nEach additional year older the head of household is, the estimated average number of people in the household reduces by 0.5%.\nEach additional year older the head of household is the estimated average number of people in the household changes by a factor of .995.\nFor every 10 years older the head of household is, the estimated average number of people in the household reduces by 5%."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#understanding-the-interpretation",
    "href": "slides/04_poisson_ch4_o.html#understanding-the-interpretation",
    "title": "Poisson Regression",
    "section": "Understanding the interpretation",
    "text": "Understanding the interpretation\nLet‚Äôs derive the change in predicted mean when we go from \\(x\\) to \\(x+1\\)\n(see boardwork)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#is-the-coefficient-of-age-statistically-significant",
    "href": "slides/04_poisson_ch4_o.html#is-the-coefficient-of-age-statistically-significant",
    "title": "Poisson Regression",
    "section": "Is the coefficient of age statistically significant?",
    "text": "Is the coefficient of age statistically significant?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n1.4512\n1.6482\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n-0.0065\n-0.0029\n\n\n\n\n\n\\[H_0: \\beta_1 = 0 \\hspace{2mm} \\text{ vs. } \\hspace{2mm} H_a: \\beta_1 \\neq 0\\]\n. . .\nTest statistic\n\\[Z = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)} = \\frac{-0.0047 - 0}{0.0009} = -5.026 \\text{ (using exact values)}\\]\n. . .\nP-value\n\\[P(|Z| &gt; |-5.026|) = 5.01 \\times 10^{-7} \\approx 0\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#what-are-plausible-values-for-the-coefficient-of-age",
    "href": "slides/04_poisson_ch4_o.html#what-are-plausible-values-for-the-coefficient-of-age",
    "title": "Poisson Regression",
    "section": "What are plausible values for the coefficient of age?",
    "text": "What are plausible values for the coefficient of age?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n1.4512\n1.6482\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n-0.0065\n-0.0029\n\n\n\n\n\n95% confidence interval for the coefficient of age\n\\[\\hat{\\beta}_1 \\pm Z^{*}\\times SE(\\hat{\\beta}_1)\\] \\[-0.0047 \\pm 1.96 \\times 0.0009 = \\mathbf{(-.0065, -0.0029)}\\]\n. . .\nQuestion: Interpret the interval in terms of the change in mean household size."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#which-can-best-help-us-determine-whether-model-1-is-a-good-fit",
    "href": "slides/04_poisson_ch4_o.html#which-can-best-help-us-determine-whether-model-1-is-a-good-fit",
    "title": "Poisson Regression",
    "section": "Which can best help us determine whether Model 1 is a good fit?",
    "text": "Which can best help us determine whether Model 1 is a good fit?\n:::{.panel-tabset}\n\nPlots\n\n\n\n\n\n\n\n\n\n\n\nCode\n\np1 &lt;- ggplot(data = hh_data, aes(x = age, y = total)) + \n  geom_point() + \n  labs(y = \"Total household size\", \n       title = \"Plot A\")\n\np2 &lt;- hh_data |&gt;\n  group_by(age) |&gt; \n  summarise(mean = mean(total)) |&gt;\n  ggplot(aes(x = age, y = mean))+ \n  geom_point() + \n  labs(y = \"Empirical mean household size\", \n       title = \"Plot B\")\n\np3 &lt;- hh_data |&gt;\n  group_by(age) |&gt; \n  summarise(log_mean = log(mean(total))) |&gt;\n  ggplot(aes(x = age, y = log_mean)) + \n  geom_point() + \n  labs(y = \"Log empirical mean household size\", \n       title = \"Plot C\")\n\np1 + p2 + p3 + plot_annotation(tag_levels = 'A')"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#model-2-add-a-quadratic-effect-for-age",
    "href": "slides/04_poisson_ch4_o.html#model-2-add-a-quadratic-effect-for-age",
    "title": "Poisson Regression",
    "section": "Model 2: Add a quadratic effect for age",
    "text": "Model 2: Add a quadratic effect for age\n\nhh_data &lt;- hh_data |&gt; \n  mutate(age2 = age*age)\n\nmodel2 &lt;- glm(total ~ age + age2, data = hh_data, family = poisson)\ntidy(model2, conf.int = T) |&gt; \n  kable(digits = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3325\n0.1788\n-1.8594\n0.063\n-0.6863\n0.0148\n\n\nage\n0.0709\n0.0069\n10.2877\n0.000\n0.0575\n0.0845\n\n\nage2\n-0.0007\n0.0001\n-11.0578\n0.000\n-0.0008\n-0.0006"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#model-2-add-a-quadratic-effect-for-age-1",
    "href": "slides/04_poisson_ch4_o.html#model-2-add-a-quadratic-effect-for-age-1",
    "title": "Poisson Regression",
    "section": "Model 2: Add a quadratic effect for age",
    "text": "Model 2: Add a quadratic effect for age\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3325\n0.1788\n-1.8594\n0.063\n-0.6863\n0.0148\n\n\nage\n0.0709\n0.0069\n10.2877\n0.000\n0.0575\n0.0845\n\n\nage2\n-0.0007\n0.0001\n-11.0578\n0.000\n-0.0008\n-0.0006\n\n\n\n\n\nWe can determine whether to keep \\(age^2\\) in the model in two ways:\n1Ô∏è‚É£ Use the p-value (or confidence interval) for the coefficient (since we are adding a single term to the model)\n2Ô∏è‚É£ Conduct a drop-in-deviance test"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#deviance",
    "href": "slides/04_poisson_ch4_o.html#deviance",
    "title": "Poisson Regression",
    "section": "Deviance",
    "text": "Deviance\nA deviance is a way to measure how the observed data deviates from the model predictions.\n\nIt‚Äôs a measure unexplained variability in the response variable (similar to SSE in linear regression )\nLower deviance means the model is a better fit to the data\n\n. . .\nWe can calculate the ‚Äúdeviance residual‚Äù for each observation in the data (more on the formula later). Let \\((\\text{deviance residual}_i\\) be the deviance residual for the \\(i^{th}\\) observation, then\n\\[\\text{deviance} = \\sum(\\text{deviance residual})_i^2\\]\n. . .\nNote: Deviance is also known as the ‚Äúresidual deviance‚Äù"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#drop-in-deviance-test",
    "href": "slides/04_poisson_ch4_o.html#drop-in-deviance-test",
    "title": "Poisson Regression",
    "section": "Drop-in-Deviance Test",
    "text": "Drop-in-Deviance Test\nWe can use a drop-in-deviance test to compare two models. To conduct the test\n1Ô∏è‚É£ Compute the deviance for each model\n2Ô∏è‚É£ Calculate the drop in deviance\n\\[\\text{drop-in-deviance =  Deviance(reduced model) - Deviance(larger model)}\\]\n. . .\n3Ô∏è‚É£ Given the reduced model is the true model \\((H_0 \\text{ true})\\), then \\[\\text{drop-in-deviance} \\sim \\chi_d^2\\]\nwhere \\(d\\) is the difference in degrees of freedom between the two models (i.e., the difference in number of terms)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#drop-in-deviance---model1-and-model2",
    "href": "slides/04_poisson_ch4_o.html#drop-in-deviance---model1-and-model2",
    "title": "Poisson Regression",
    "section": "Drop-in-deviance - Model1 and Model2",
    "text": "Drop-in-deviance - Model1 and Model2\n\nanova(model1, model2, test = \"Chisq\") |&gt;\n  kable(digits = 3)\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n1498\n2337.089\nNA\nNA\nNA\n\n\n1497\n2200.944\n1\n136.145\n0\n\n\n\n\n\n. . .\nQuestions:\n\nWrite the null and alternative hypotheses.\nWhat does the value 2337.089 tell you?\nWhat does the value 1 tell you?\nWhat is your conclusion?"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#add-location-to-the-model",
    "href": "slides/04_poisson_ch4_o.html#add-location-to-the-model",
    "title": "Poisson Regression",
    "section": "Add location to the model?",
    "text": "Add location to the model?\nSuppose we want to add location to the model, so we compare the following models:\nModel A: \\(\\lambda_i = \\beta_0 + \\beta_1 ~ age_i + \\beta_2 ~ age_i^2\\)\nModel B: \\(\\lambda_i =  \\beta_0 + \\beta_1 ~ age_i + \\beta_2 ~ age_i^2 + \\beta_3 ~ Loc1_i + \\beta_4 ~ Loc2_i + \\beta_5 ~ Loc3_i + \\beta_6 ~ Loc4_i\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#question",
    "href": "slides/04_poisson_ch4_o.html#question",
    "title": "Poisson Regression",
    "section": "Question",
    "text": "Question\nWhich of the following are reliable ways to determine if location should be added to the model?\n. . .\n\nDrop-in-deviance test\nUse the p-value for each coefficient\nLikelihood ratio test\nNested F Test\nBIC"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#add-location-to-the-model-1",
    "href": "slides/04_poisson_ch4_o.html#add-location-to-the-model-1",
    "title": "Poisson Regression",
    "section": "Add location to the model?",
    "text": "Add location to the model?\n\nmodel3 &lt;- glm(total ~ age + age2 + location, data = hh_data, family = poisson)\n\n. . .\nUse a drop-in-deviance test to determine if Model 2 or Model 3 (with location) is a better fit for the data.\n. . .\n\nanova(model2, model3, test = \"Chisq\") |&gt;\n  kable(digits = 3)\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n1497\n2200.944\nNA\nNA\nNA\n\n\n1493\n2187.800\n4\n13.144\n0.011\n\n\n\n\n\nThe p-value is small (0.01 &lt; 0.05), so we conclude that Model 3 is a better fit for the data."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#model-3",
    "href": "slides/04_poisson_ch4_o.html#model-3",
    "title": "Poisson Regression",
    "section": "Model 3",
    "text": "Model 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n-2.1107\n0.0348\n-0.7444\n-0.0306\n\n\nage\n0.0704\n0.0069\n10.1900\n0.0000\n0.0569\n0.0840\n\n\nage2\n-0.0007\n0.0001\n-10.9437\n0.0000\n-0.0008\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n-0.3605\n0.7185\n-0.1250\n0.0859\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n1.1580\n0.2468\n-0.0423\n0.1641\n\n\nlocationMetroManila\n0.0545\n0.0472\n1.1542\n0.2484\n-0.0378\n0.1473\n\n\nlocationVisayas\n0.1121\n0.0417\n2.6853\n0.0072\n0.0308\n0.1945\n\n\n\n\n\n. . .\nDoes this model sufficiently explain the variability in the mean household size?"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#pearson-residuals",
    "href": "slides/04_poisson_ch4_o.html#pearson-residuals",
    "title": "Poisson Regression",
    "section": "Pearson residuals",
    "text": "Pearson residuals\nWe can calculate two types of residuals for Poisson regression: Pearson residuals and deviance residuals\n. . .\n\\[\\text{Pearson residual}_i = \\frac{\\text{observed} - \\text{predicted}}{\\text{std. error}} = \\frac{y_i - \\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda}_i}}\\]\n. . .\n\nSimilar interpretation as standardized residuals from linear regression\nExpect most to fall between -2 and 2\nUsed to calculate overdispersion parameter"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#deviance-residuals",
    "href": "slides/04_poisson_ch4_o.html#deviance-residuals",
    "title": "Poisson Regression",
    "section": "Deviance residuals",
    "text": "Deviance residuals\nThe deviance residual indicates how much the observed data deviates from the fitted model\n\\[\\text{deviance residual}_i = \\text{sign}(y_i - \\hat{\\lambda}_i)\\sqrt{2\\Bigg[y_i\\log\\bigg(\\frac{y_i}{\\hat{\\lambda}_i}\\bigg) - (y_i - \\hat{\\lambda}_i)\\Bigg]}\\]\nwhere\n\\[\\text{sign}(y_i - \\hat{\\lambda}_i)  =  \\begin{cases}\n1 & \\text{ if }(y_i - \\hat{\\lambda}_i) &gt; 0 \\\\\n-1 & \\text{ if }(y_i - \\hat{\\lambda}_i) &lt; 0 \\\\\n0 & \\text{ if }(y_i - \\hat{\\lambda}_i) = 0\n\\end{cases}\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#model-3-residual-plots",
    "href": "slides/04_poisson_ch4_o.html#model-3-residual-plots",
    "title": "Poisson Regression",
    "section": "Model 3: Residual plots",
    "text": "Model 3: Residual plots\n\nmodel3_aug_pearson &lt;- augment(model3, type.residuals = \"pearson\") \nmodel3_aug_deviance &lt;- augment(model3, type.residuals = \"deviance\")\n\n\nPlotsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = model3_aug_pearson, aes(x = .fitted, y = .resid)) + \n  geom_point()  + \n  geom_smooth() + \n  labs(x = \"Fitted values\", \n       y = \"Pearson residuals\", \n       title = \"Pearson residuals vs. fitted\")\n\np2 &lt;-  ggplot(data = model3_aug_deviance, aes(x = .fitted, y = .resid)) + \n  geom_point()  + \n  geom_smooth() + \n  labs(x = \"Fitted values\", \n       y = \"Deviance residuals\", \n       title = \"Deviance residuals vs. fitted\")\n\np1 + p2"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#goodness-of-fit-1",
    "href": "slides/04_poisson_ch4_o.html#goodness-of-fit-1",
    "title": "Poisson Regression",
    "section": "Goodness-of-fit",
    "text": "Goodness-of-fit\n\nGoal: Use the (residual) deviance to assess how much the predicted values differ from the observed values. Recall \\((\\text{deviance}) = \\sum_{i=1}^{n}(\\text{deviance residual})_i^2\\)\nIf the model sufficiently fits the data, then\n\n\\[\\text{deviance} \\sim \\chi^2_{df}\\]\nwhere \\(df\\) is the model‚Äôs residual degrees of freedom\n. . .\n\nQuestion: What is the probability of observing a deviance larger than the one we‚Äôve observed, given this model sufficiently fits the data?\n\n. . .\n\\[P(\\chi^2_{df} &gt; \\text{ deviance})\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#model-3-goodness-of-fit-calculations",
    "href": "slides/04_poisson_ch4_o.html#model-3-goodness-of-fit-calculations",
    "title": "Poisson Regression",
    "section": "Model 3: Goodness-of-fit calculations",
    "text": "Model 3: Goodness-of-fit calculations\n\nmodel3$deviance\n\n[1] 2187.8\n\nmodel3$df.residual\n\n[1] 1493\n\n\n\npchisq(model3$deviance, model3$df.residual, lower.tail = FALSE)\n\n[1] 3.153732e-29\n\n\nThe probability of observing a deviance greater than 2187.8 is \\(\\approx 0\\), so there is significant evidence of lack-of-fit."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#lack-of-fit",
    "href": "slides/04_poisson_ch4_o.html#lack-of-fit",
    "title": "Poisson Regression",
    "section": "Lack-of-fit",
    "text": "Lack-of-fit\nThere are a few potential reasons for lack-of-fit:\n\nMissing important interactions or higher-order terms\nMissing important variables (perhaps this means a more comprehensive data set is required)\nThere could be extreme observations causing the deviance to be larger than expected (assess based on the residual plots)\nThere could be a problem with the Poisson model\n\nMay need more flexibility in the model to handle overdispersion"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#overdispersion",
    "href": "slides/04_poisson_ch4_o.html#overdispersion",
    "title": "Poisson Regression",
    "section": "Overdispersion",
    "text": "Overdispersion\nOverdispersion: There is more variability in the response than what is implied by the Poisson model\n\nTablesCode\n\n\n\n\nOverall\n\n\n\n\n\nmean\nvar\n\n\n\n\n3.685\n5.534\n\n\n\n\n\n\nby Location\n\n\n\n\n\nlocation\nmean\nvar\n\n\n\n\nCentralLuzon\n3.402\n4.152\n\n\nDavaoRegion\n3.390\n4.723\n\n\nIlocosRegion\n3.586\n5.402\n\n\nMetroManila\n3.707\n4.863\n\n\nVisayas\n3.902\n6.602\n\n\n\n\n\n\n\n\n\n\nhh_data |&gt;\n  summarise(mean = mean(total), var = var(total)) |&gt;\n  kable(digits = 3)\n\n\nhh_data |&gt;\n  group_by(location) |&gt;\n  summarise(mean = mean(total), var = var(total)) |&gt;\n  kable(digits = 3)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#why-overdispersion-matters",
    "href": "slides/04_poisson_ch4_o.html#why-overdispersion-matters",
    "title": "Poisson Regression",
    "section": "Why overdispersion matters",
    "text": "Why overdispersion matters\nIf there is overdispersion, then there is more variation in the response than what‚Äôs implied by a Poisson model. This means\n‚ùå The standard errors of the model coefficients are artificially small\n‚ùå The p-values are artificially small\n‚ùå This could lead to models that are more complex than what is needed\n. . .\nWe can take overdispersion into account by\n\ninflating standard errors by multiplying them by a dispersion factor\nusing a negative-binomial regression model"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#dispersion-parameter",
    "href": "slides/04_poisson_ch4_o.html#dispersion-parameter",
    "title": "Poisson Regression",
    "section": "Dispersion parameter",
    "text": "Dispersion parameter\nThe dispersion parameter is represented by \\(\\phi\\)\n\\[\\hat{\\phi} =\\frac{\\text{deviance}}{\\text{residual df}} = \\frac{\\sum_{i=1}^{n}(\\text{Pearson residuals})^2}{n - p}\\]\nwhere \\(p\\) is the number of terms in the model (including the intercept)\n\nIf there is no overdispersion \\(\\hat{\\phi} = 1\\)\nIf there is overdispersion \\(\\hat{\\phi} &gt;  1\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#accounting-for-dispersion-in-the-model",
    "href": "slides/04_poisson_ch4_o.html#accounting-for-dispersion-in-the-model",
    "title": "Poisson Regression",
    "section": "Accounting for dispersion in the model",
    "text": "Accounting for dispersion in the model\nWe inflate the standard errors of the coefficient by multiplying the variance by \\(\\hat{\\phi}\\)\n. . .\n\\[SE_{Q}(\\hat{\\beta}) = \\sqrt{\\hat{\\phi}}  * SE(\\hat{\\beta})\\] - ‚ÄúQ‚Äù stands for quasi-Poisson, since this is an ad-hoc solution - The process for model building and model comparison is called quasilikelihood (similar to likelihood without exact underlying distributions)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#model-3-quasi-poisson-model",
    "href": "slides/04_poisson_ch4_o.html#model-3-quasi-poisson-model",
    "title": "Poisson Regression",
    "section": "Model 3: Quasi-Poisson model",
    "text": "Model 3: Quasi-Poisson model\n\nmodel3_q &lt;- glm(total ~ age + age2 + location, data = hh_data, \n                family = quasipoisson) #&lt;&lt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n-1.7744\n0.0762\n-0.8134\n0.0358\n\n\nage\n0.0704\n0.0082\n8.5665\n0.0000\n0.0544\n0.0866\n\n\nage2\n-0.0007\n0.0001\n-9.2000\n0.0000\n-0.0009\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n-0.3030\n0.7619\n-0.1451\n0.1058\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n0.9735\n0.3304\n-0.0620\n0.1837\n\n\nlocationMetroManila\n0.0545\n0.0561\n0.9703\n0.3320\n-0.0552\n0.1649\n\n\nlocationVisayas\n0.1121\n0.0497\n2.2574\n0.0241\n0.0156\n0.2103"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#poisson-vs.-q-poisson",
    "href": "slides/04_poisson_ch4_o.html#poisson-vs.-q-poisson",
    "title": "Poisson Regression",
    "section": "Poisson vs.¬†Q-Poisson",
    "text": "Poisson vs.¬†Q-Poisson\n\n\nPoisson\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n\n\nage\n0.0704\n0.0069\n\n\nage2\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n\n\nlocationMetroManila\n0.0545\n0.0472\n\n\nlocationVisayas\n0.1121\n0.0417\n\n\n\n\n\n\nQuasi-Poisson\n\n\n\n\n\nestimate\nstd.error\n\n\n\n\n-0.3843\n0.2166\n\n\n0.0704\n0.0082\n\n\n-0.0007\n0.0001\n\n\n-0.0194\n0.0640\n\n\n0.0610\n0.0626\n\n\n0.0545\n0.0561\n\n\n0.1121\n0.0497"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#q-poisson-inference-for-coefficients",
    "href": "slides/04_poisson_ch4_o.html#q-poisson-inference-for-coefficients",
    "title": "Poisson Regression",
    "section": "Q-Poisson: Inference for coefficients",
    "text": "Q-Poisson: Inference for coefficients\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n\n\nage\n0.0704\n0.0082\n\n\nage2\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n\n\nlocationMetroManila\n0.0545\n0.0561\n\n\nlocationVisayas\n0.1121\n0.0497\n\n\n\n\n\n\nTest statistic \\[t = \\frac{\\hat{\\beta} - 0}{SE_{Q}(\\hat{\\beta})} \\sim t_{n-p}\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#negative-binomial-regression-model-1",
    "href": "slides/04_poisson_ch4_o.html#negative-binomial-regression-model-1",
    "title": "Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\nAnother approach to handle overdispersion is to use a negative binomial regression model\n\nThis has more flexibility than the quasi-Poisson model, because there is a new parameter in addition to \\(\\lambda\\)\n\n\n. . .\nLet \\(Y\\) be a negative binomial random variable, \\(Y\\sim NegBinom(r, p)\\), then\n\\[P(Y = y_i) = {y_i + r - 1 \\choose r - 1}(1-p)^{y_i}p^r \\hspace{5mm} y_i = 0, 1, 2, \\ldots, \\infty\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#negative-binomial-regression-model-2",
    "href": "slides/04_poisson_ch4_o.html#negative-binomial-regression-model-2",
    "title": "Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\n\nMain idea: Generate a \\(\\lambda\\) for each observation (household) and generate a count using the Poisson random variable with parameter \\(\\lambda\\)\n\nMakes the counts more dispersed than with a single parameter\n\nThink of it as a Poisson model such that \\(\\lambda\\) is also random\n\n. . .\n\\(\\begin{aligned} &\\text{If }Y|\\lambda \\sim Poisson(\\lambda)\\\\\n&\\text{ and } \\lambda \\sim Gamma\\bigg(r, \\frac{1-p}{p}\\bigg)\\\\\n&\\text{ then } Y \\sim NegBinom(r, p)\\end{aligned}\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#negative-binomial-regression-in-r",
    "href": "slides/04_poisson_ch4_o.html#negative-binomial-regression-in-r",
    "title": "Poisson Regression",
    "section": "Negative binomial regression in R",
    "text": "Negative binomial regression in R\n\nlibrary(MASS)\nmodel3_nb &lt;- glm.nb(total ~ age + age2 + location, data = hh_data)\ntidy(model3_nb) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.3753\n0.2076\n-1.8081\n0.0706\n\n\nage\n0.0699\n0.0079\n8.8981\n0.0000\n\n\nage2\n-0.0007\n0.0001\n-9.5756\n0.0000\n\n\nlocationDavaoRegion\n-0.0219\n0.0625\n-0.3501\n0.7262\n\n\nlocationIlocosRegion\n0.0577\n0.0615\n0.9391\n0.3477\n\n\nlocationMetroManila\n0.0562\n0.0551\n1.0213\n0.3071\n\n\nlocationVisayas\n0.1104\n0.0487\n2.2654\n0.0235"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#data-airbnbs-in-nyc",
    "href": "slides/04_poisson_ch4_o.html#data-airbnbs-in-nyc",
    "title": "Poisson Regression",
    "section": "Data: Airbnbs in NYC",
    "text": "Data: Airbnbs in NYC\nThe data set NYCairbnb-sample.csv contains information about a random sample of 1000 Airbnbs in New York City. It is a subset of the data on 40628 Airbnbs scraped by Awad et al.¬†(2017).\nVariables\n\nnumber_of_reviews: Number of reviews for the unit on Airbnb (proxy for number of rentals)\nprice: price per night in US dollars\nroom_type: Entire home/apartment, private room, or shared room\ndays: Number of days the unit has been listed (date when info scraped - date when unit first listed on Airbnb)\n\n\n\nData set pulled from BMLR Section 4.11.3."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#data-airbnbs-in-nyc-1",
    "href": "slides/04_poisson_ch4_o.html#data-airbnbs-in-nyc-1",
    "title": "Poisson Regression",
    "section": "Data: Airbnbs in NYC",
    "text": "Data: Airbnbs in NYC\n\nairbnb &lt;- read_csv(\"data/NYCairbnb-sample.csv\") |&gt;\n  dplyr::select(id, number_of_reviews, days, room_type, price)\n\n\n\n\n\n\nid\nnumber_of_reviews\ndays\nroom_type\nprice\n\n\n\n\n15756544\n16\n1144\nPrivate room\n120\n\n\n14218251\n15\n471\nPrivate room\n89\n\n\n21644\n0\n2600\nPrivate room\n89\n\n\n13667835\n1\n283\nEntire home/apt\n150\n\n\n265912\n0\n1970\nEntire home/apt\n89\n\n\n\n\n\nGoal: Use the price and room type of Airbnbs to describe variation in the number of reviews (a proxy for number of rentals)."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#eda",
    "href": "slides/04_poisson_ch4_o.html#eda",
    "title": "Poisson Regression",
    "section": "EDA",
    "text": "EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = airbnb, aes(x = number_of_reviews)) + \n  geom_histogram() + \n   labs(x = \"Number of reviews\",\n    title = \"Distribution of number of reviews\")\n\np2 &lt;- airbnb |&gt;\n  filter(price &lt;= 2000) |&gt;\n  group_by(price) |&gt;\n  summarise(log_mean = log(mean(number_of_reviews))) |&gt;\n  ggplot(aes(x = price, y = log_mean)) + \n  geom_point(alpha= 0.7) + \n  geom_smooth() + \n  labs(x = \"Price in  US dollars\",\n    y = \"Log(mean # reviews)\", \n    title = \"Log mean #  of reviews vs. price\", \n    subtitle = \"Airbnbs $2000 or less\")\n\np3 &lt;- airbnb |&gt;\n  filter(price &lt;= 500) |&gt;\n  group_by(price) |&gt;\n  summarise(log_mean = log(mean(number_of_reviews))) |&gt;\n  ggplot(aes(x = price, y = log_mean)) + \n  geom_point(alpha= 0.7) + \n  geom_smooth() + \n  labs(x = \"Price in  US dollars\",\n    y = \"Log(mean # reviews)\", \n    title = \"Log mean # of reviews vs. price\", \n    subtitle = \"Airbnbs $500 or less\")\n\np1  / (p2 + p3)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#eda-1",
    "href": "slides/04_poisson_ch4_o.html#eda-1",
    "title": "Poisson Regression",
    "section": "EDA",
    "text": "EDA\n\n\nOverall\n\n\n\n\n\nmean\nvar\n\n\n\n\n15.916\n765.969\n\n\n\n\n\n\nby Room type\n\n\n\n\n\nroom_type\nmean\nvar\n\n\n\n\nEntire home/apt\n16.283\n760.348\n\n\nPrivate room\n15.608\n786.399\n\n\nShared room\n15.028\n605.971"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#considerations-for-modeling",
    "href": "slides/04_poisson_ch4_o.html#considerations-for-modeling",
    "title": "Poisson Regression",
    "section": "Considerations for modeling",
    "text": "Considerations for modeling\nWe would like to fit the Poisson regression model\n\\[\\log(\\lambda) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2\\]\n. . .\nQuestion: - Based on the EDA, what are some potential issues we may want to address in the model building?\n\nSuppose any model fit issues are addressed. What are some potential limitations to the conclusions and interpretations from the model?"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#offset",
    "href": "slides/04_poisson_ch4_o.html#offset",
    "title": "Poisson Regression",
    "section": "Offset",
    "text": "Offset\n\nSometimes counts are not directly comparable because the observations differ based on some characteristic directly related to the counts, i.e.¬†the sampling effort.\nAn offset can be used to adjust for differences in sampling effort.\n\n. . .\n\nLet \\(x_{offset}\\) be the variable that accounts for differences in sampling effort, then \\(\\log(x_{offset})\\) will be added to the model.\n\n. . .\n\\(\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ x_{i1} + \\beta_2 ~ x_{i2} + ... + \\beta_p ~ x_{ip} + \\log(x_{offset_i})\\)\n\nThe offset is a term in the model with coefficient always equal to 1."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#adding-an-offset-to-the-airbnb-model",
    "href": "slides/04_poisson_ch4_o.html#adding-an-offset-to-the-airbnb-model",
    "title": "Poisson Regression",
    "section": "Adding an offset to the Airbnb model",
    "text": "Adding an offset to the Airbnb model\nWe will add the offset \\(\\log(days)\\) to the model. This accounts for the fact that we would expect Airbnbs that have been listed longer to have more reviews.\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i + \\log(days_i)\\] \nNote: The response variable for the model is still \\(\\log(\\lambda_i)\\), the log mean number of reviews"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#detail-on-the-offset",
    "href": "slides/04_poisson_ch4_o.html#detail-on-the-offset",
    "title": "Poisson Regression",
    "section": "Detail on the offset",
    "text": "Detail on the offset\nWe want to adjust for the number of days, so we are interested in \\(\\frac{reviews}{days}\\).\n. . .\nGiven \\(\\lambda\\) is the mean number of reviews\n\\[\\log\\Big(\\frac{\\lambda}{days}\\Big) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2\\]\n. . .\n\\[\\Rightarrow \\log({\\lambda}) - \\log(days) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2\\]\n. . .\n\\[\\Rightarrow \\log({\\lambda}) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2 + \\log(days)\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#airbnb-model-in-r",
    "href": "slides/04_poisson_ch4_o.html#airbnb-model-in-r",
    "title": "Poisson Regression",
    "section": "Airbnb model in R",
    "text": "Airbnb model in R\n\nairbnb_model &lt;- glm(number_of_reviews ~ price + room_type, \n                    data = airbnb, family = poisson, \n                    offset = log(days)) #&lt;&lt;\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1351\n0.0170\n-243.1397\n0\n\n\nprice\n-0.0005\n0.0001\n-7.0952\n0\n\n\nroom_typePrivate room\n-0.0994\n0.0174\n-5.6986\n0\n\n\nroom_typeShared room\n0.2436\n0.0452\n5.3841\n0\n\n\n\n\n\n. . .\nThe coefficient for \\(\\log(days)\\) is fixed at 1, so it is not in the model output."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#interpretations",
    "href": "slides/04_poisson_ch4_o.html#interpretations",
    "title": "Poisson Regression",
    "section": "Interpretations",
    "text": "Interpretations\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1351\n0.0170\n-243.1397\n0\n\n\nprice\n-0.0005\n0.0001\n-7.0952\n0\n\n\nroom_typePrivate room\n-0.0994\n0.0174\n-5.6986\n0\n\n\nroom_typeShared room\n0.2436\n0.0452\n5.3841\n0\n\n\n\n\n\n\nQuestion:\n\nInterpret the coefficient of price.\nInterpret the coefficient of room_typePrivate room"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#goodness-of-fit-2",
    "href": "slides/04_poisson_ch4_o.html#goodness-of-fit-2",
    "title": "Poisson Regression",
    "section": "Goodness-of-fit",
    "text": "Goodness-of-fit\n\\[\\begin{aligned}&H_0: \\text{ The model is a good fit for the data}\\\\\n&H_a: \\text{ There is significant lack of fit}\\end{aligned}\\]\n\npchisq(airbnb_model$deviance, airbnb_model$df.residual, lower.tail = F)\n\n[1] 0\n\n\n. . .\nThere is evidence of significant lack of fit in the model. Therefore, more models would need to be explored that address the issues mentioned earlier.\n. . .\nIn practice we would assess goodness-of-fit and finalize the model before any interpretations and conclusions."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#data-weekend-drinking",
    "href": "slides/04_poisson_ch4_o.html#data-weekend-drinking",
    "title": "Poisson Regression",
    "section": "Data: Weekend drinking",
    "text": "Data: Weekend drinking\nThe data weekend-drinks.csv contains information from a survey of 77 students in a introductory statistics course on a dry campus.\nVariables\n\ndrinks: Number of drinks they had in the past weekend\noff_campus: 1 - lives off campus, 0 otherwise\nfirst_year: 1 - student is a first-year, 0 otherwise\nsex: f - student identifies as female, m - student identifies as male\n\n. . .\nGoal: The goal is explore factors related to drinking behavior on a dry campus.\n\n\nCase study in BMLR - Section 4.10"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#eda-response-variable",
    "href": "slides/04_poisson_ch4_o.html#eda-response-variable",
    "title": "Poisson Regression",
    "section": "EDA: Response variable",
    "text": "EDA: Response variable"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#observed-vs.-expected-response",
    "href": "slides/04_poisson_ch4_o.html#observed-vs.-expected-response",
    "title": "Poisson Regression",
    "section": "Observed vs.¬†expected response",
    "text": "Observed vs.¬†expected response\n\n\n\n\n\n\n\n\n\n. . .\nWhat does it mean to be a ‚Äúzero‚Äù in this data?"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#two-types-of-zeros",
    "href": "slides/04_poisson_ch4_o.html#two-types-of-zeros",
    "title": "Poisson Regression",
    "section": "Two types of zeros",
    "text": "Two types of zeros\nThere are two types of zeros\n\nThose who happen to have a zero in the data set (people who drink but happened to not drink last weekend)\nThose who will always report a value of zero (non-drinkers)\n\nThese are called true zeros\n\n\n. . .\nWe introduce a new parameter \\(\\alpha\\) for the proportion of true zeros, then fit a model that has two components:\n. . .\n1Ô∏è‚É£ The association between mean number of drinks and various characteristics among those who drink\n2Ô∏è‚É£ The estimated proportion of non-drinkers"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#zero-inflated-poisson-model-1",
    "href": "slides/04_poisson_ch4_o.html#zero-inflated-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Zero-inflated Poisson model",
    "text": "Zero-inflated Poisson model\nZero-inflated Poisson (ZIP) model has two parts\n. . .\n1Ô∏è‚É£ Association, among those who drink, between the mean number of drinks and predictors sex and off campus residence\n. . .\n\\[\\log(\\lambda) = \\beta_0 + \\beta_1 ~ off\\_campus + \\beta_2 ~ sex\\] where \\(\\lambda\\) is the mean number of drinks among those who drink\n. . .\n2Ô∏è‚É£ Probability that a student does not drink\n\\[\\text{logit}(\\alpha) = \\log\\Big(\\frac{\\alpha}{1- \\alpha}\\Big) = \\beta_0 + \\beta_1 ~ first\\_year\\]\nwhere \\(\\alpha\\) is the proportion of non-drinkers\n. . .\nNote: The same variables can be used in each component"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#details-of-the-zip-model",
    "href": "slides/04_poisson_ch4_o.html#details-of-the-zip-model",
    "title": "Poisson Regression",
    "section": "Details of the ZIP model",
    "text": "Details of the ZIP model\n\nThe ZIP model is a special case of a latent variable model\n\nA type of mixture model where observations for one or more groups occur together but the group membership unknown\n\nZero-inflated models are a common type of mixture model; they apply beyond Poisson regression"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#zip-model-in-r",
    "href": "slides/04_poisson_ch4_o.html#zip-model-in-r",
    "title": "Poisson Regression",
    "section": "ZIP model in R",
    "text": "ZIP model in R\nFit ZIP models using the zeroinfl function from the pscl R package.\n\nlibrary(pscl)\n\ndrinks_zip &lt;- zeroinfl(drinks ~ off_campus + sex | first_year,\n                data = drinks)\ndrinks_zip\n\n\nCall:\nzeroinfl(formula = drinks ~ off_campus + sex | first_year, data = drinks)\n\nCount model coefficients (poisson with log link):\n(Intercept)   off_campus         sexm  \n     0.7543       0.4159       1.0209  \n\nZero-inflation model coefficients (binomial with logit link):\n(Intercept)   first_year  \n    -0.6036       1.1364"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#tidy-output",
    "href": "slides/04_poisson_ch4_o.html#tidy-output",
    "title": "Poisson Regression",
    "section": "Tidy output",
    "text": "Tidy output\nUse the tidy function from the poissonreg package for tidy model output.\n\nlibrary(poissonreg)\n\n. . .\nMean number of drinks among those who drink\n\ntidy(drinks_zip, type = \"count\") %&gt;% kable(digits = 3)\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\ncount\n0.754\n0.144\n5.238\n0.000\n\n\noff_campus\ncount\n0.416\n0.206\n2.021\n0.043\n\n\nsexm\ncount\n1.021\n0.175\n5.827\n0.000"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#tidy-output-1",
    "href": "slides/04_poisson_ch4_o.html#tidy-output-1",
    "title": "Poisson Regression",
    "section": "Tidy output",
    "text": "Tidy output\nProportion of non-drinkers\n\ntidy(drinks_zip, type = \"zero\") %&gt;% kable(digits = 3)\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\nzero\n-0.604\n0.311\n-1.938\n0.053\n\n\nfirst_year\nzero\n1.136\n0.610\n1.864\n0.062"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#interpreting-the-model-coefficients",
    "href": "slides/04_poisson_ch4_o.html#interpreting-the-model-coefficients",
    "title": "Poisson Regression",
    "section": "Interpreting the model coefficients",
    "text": "Interpreting the model coefficients\n\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\ncount\n0.754\n0.144\n5.238\n0.000\n\n\noff_campus\ncount\n0.416\n0.206\n2.021\n0.043\n\n\nsexm\ncount\n1.021\n0.175\n5.827\n0.000\n\n\n\n\n\n\nQuestions\n\nInterpret the intercept.\nInterpret the coefficients of off_campus and sexm."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#estimated-proportion-zeros",
    "href": "slides/04_poisson_ch4_o.html#estimated-proportion-zeros",
    "title": "Poisson Regression",
    "section": "Estimated proportion zeros",
    "text": "Estimated proportion zeros\n\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\nzero\n-0.604\n0.311\n-1.938\n0.053\n\n\nfirst_year\nzero\n1.136\n0.610\n1.864\n0.062\n\n\n\n\n\nQuestions:\nBased on the model‚Ä¶\n\nWhat is the probability a first-year student is a non-drinker?\nWhat is the probability a upperclass student (sophomore, junior, senior) is a non-drinker?"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#these-are-just-a-few-of-the-many-models",
    "href": "slides/04_poisson_ch4_o.html#these-are-just-a-few-of-the-many-models",
    "title": "Poisson Regression",
    "section": "These are just a few of the many models‚Ä¶",
    "text": "These are just a few of the many models‚Ä¶\n\nUse the Vuong Test to compare the fit of the ZIP model to a regular Poisson model\n\nWhy can‚Äôt we use a drop-in-deviance test?\n\nWe‚Äôve just discussed the ZIP model here, but there are other model applications beyond the standard Poisson regression model (e.g., hurdle models, Zero-inflated Negative Binomial models, etc. )"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#estimating-coefficients-in-poisson-model",
    "href": "slides/04_poisson_ch4_o.html#estimating-coefficients-in-poisson-model",
    "title": "Poisson Regression",
    "section": "Estimating coefficients in Poisson model",
    "text": "Estimating coefficients in Poisson model\n\nLeast squares estimation would not work because the normality and equal variance assumptions don‚Äôt hold for Poisson regression\nMaximum likelihood estimation is used to estimate the coefficients of Poisson regression.\nThe likelihood is the product of the probabilities for the \\(n\\) independent observations in the data"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#likelihood-for-regular-poisson-model",
    "href": "slides/04_poisson_ch4_o.html#likelihood-for-regular-poisson-model",
    "title": "Poisson Regression",
    "section": "Likelihood for regular Poisson model",
    "text": "Likelihood for regular Poisson model\nLet‚Äôs go back to example about household size in the Philippines. We will focus on the model using the main effect of age to understand variability in mean household size.\n. . .\nSuppose the first five observations have household sizes of 4, 2, 8, 6, and 1. Then the likelihood is\n. . .\n\\(L = \\frac{e^{-\\lambda_1}\\lambda_1^4}{4!} * \\frac{e^{-\\lambda_2}\\lambda_2^2}{2!} * \\frac{e^{-\\lambda_3}\\lambda_3^8}{8!} *\n\\frac{e^{-\\lambda_4}\\lambda_4^6}{6!} * \\frac{e^{-\\lambda_5}\\lambda_5^1}{1!}\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#likelihood-for-regular-poisson-model-1",
    "href": "slides/04_poisson_ch4_o.html#likelihood-for-regular-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Likelihood for regular Poisson model",
    "text": "Likelihood for regular Poisson model\nWe will use the log likelihood to make finding the MLE easier\n. . .\n\\(\\begin{aligned}\\log(L) &= -\\lambda_1 + 4\\log(\\lambda_1) - \\lambda_2 + 2\\log(\\lambda_2) - \\lambda_3 + 8\\log(\\lambda_3)\\\\ & -\\lambda_4 + 6 \\log(\\lambda_4) - \\lambda_5 + \\log(\\lambda_5) + C \\end{aligned}\\)\nwhere - \\(\\lambda\\) is the mean number in household depending on \\(x_i\\) - \\(C = -[\\log(4!) + \\log(2!) + \\log(8!) + \\log(6!)+ \\log(1!)]\\)"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#likelihood-for-regular-poisson-model-2",
    "href": "slides/04_poisson_ch4_o.html#likelihood-for-regular-poisson-model-2",
    "title": "Poisson Regression",
    "section": "Likelihood for regular Poisson model",
    "text": "Likelihood for regular Poisson model\nGiven the age of the head of the household, we fit the model\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1~age_i\\]\nThen we replace each \\(\\lambda_i\\) in \\(\\log(L)\\) with \\(e^{\\beta_0 + \\beta_1~age_i}\\).\n. . .\nSuppose the first five observations have ages \\(X = (32, 21, 55, 44, 28)\\). Then\n. . .\n\\[\\begin{aligned} \\log(L) &= [-e^{\\beta_0 + \\beta_132}+ 4(\\beta_0 + \\beta_1 32)] + [ - e^{\\beta_0 + \\beta_121} + 2(\\beta_0 + \\beta_121)] \\\\ &+  [- e^{\\beta_0 + \\beta_155} + 8(\\beta_0 + \\beta_155)] +  [-e^{\\beta_0 + \\beta_144} + 6(\\beta_0 + \\beta_144)] \\\\ &+ [-e^{\\beta_0 + \\beta_128}(\\beta_0 + \\beta_128)] + C \\end{aligned}\\]\n. . .\nUse search algorithm to find the values of \\(\\beta_0\\) and \\(\\beta_1\\) that maximize the above equation."
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#probabilities-under-zip-model",
    "href": "slides/04_poisson_ch4_o.html#probabilities-under-zip-model",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nThere are three different types of observations in the data:\n\nObserved zero and will always be 0 (true zeros)\nObserved 0 but will not always be 0\nObserved non-zero count and will not always be 0"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#probabilities-under-zip-model-1",
    "href": "slides/04_poisson_ch4_o.html#probabilities-under-zip-model-1",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nTrue zeros\n\\[P(0 | \\text{true zero})= \\alpha\\]\n. . .\nObserved 0 but will not always be 0\n\\[P(0 | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^0}{0!}\\]\n. . .\nDid not observe 0 and will not always be 0\n\\[P(z_i | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^{z_i}}{z_i!}\\]"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#probabilities-under-zip-model-2",
    "href": "slides/04_poisson_ch4_o.html#probabilities-under-zip-model-2",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nPutting this all together. Let \\(y_i\\) be an observed response then\n\\[P(Y_i = y_i | x_i) = \\begin{cases}\n\\alpha + (1 - \\alpha)e^{-\\lambda_i} && \\text{ if } y_i = 0 \\\\\n(1 - \\alpha)\\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}{y_i!} && \\text{ if } y_i &gt; 0\n\\end{cases}\\]\n. . .\nRecall from our example,\n\\[\\lambda_i = e^{\\beta_0 + \\beta_1~off\\_campus_i + \\beta_2 ~ sex_i}\\]\n\\[\\alpha_i = \\frac{e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}{1 + e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}\\]\n\nPlug in \\(\\lambda_i\\) and \\(\\alpha_i\\) into the above equation obtain the likelihood function"
  },
  {
    "objectID": "slides/04_poisson_ch4_o.html#acknowledgements",
    "href": "slides/04_poisson_ch4_o.html#acknowledgements",
    "title": "Poisson Regression",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 4\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#setup",
    "href": "slides/02_likelihoods_ch2.html#setup",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#learning-goals",
    "href": "slides/02_likelihoods_ch2.html#learning-goals",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Learning goals",
    "text": "Learning goals\n\nDescribe the concept of a likelihood\nConstruct the likelihood for a simple model\nDefine the Maximum Likelihood Estimate (MLE) and use it to answer an analysis question\nIdentify three ways to calculate or approximate the MLE and apply these methods to find the MLE for a simple model\nUse likelihoods to compare models (next week)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#what-is-the-likelihood",
    "href": "slides/02_likelihoods_ch2.html#what-is-the-likelihood",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "What is the likelihood?",
    "text": "What is the likelihood?\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values).\n\nUnlike Ordinary Least Squares (OLS), they do not require the responses be independent, identically distributed, and normal (iidN)\nThey are not the same as probability functions\n\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#fouls-in-college-basketball-games",
    "href": "slides/02_likelihoods_ch2.html#fouls-in-college-basketball-games",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\nThe data set 04-refs.csv includes 30 randomly selected NCAA men‚Äôs basketball games played in the 2009 - 2010 season.\nWe will focus on the variables foul1, foul2, and foul3, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.\n\nH: Foul was called on the home team\nV: Foul was called on the visiting team\n\n\nWe are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.\n\n[The dataset was derived from basektball0910.csv used in BMLR Section 11.2"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#fouls-in-college-basketball-games-1",
    "href": "slides/02_likelihoods_ch2.html#fouls-in-college-basketball-games-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\n\nrefs &lt;- read_csv(\"data/04-refs.csv\")\n\nRows: 30 Columns: 7\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (5): visitor, hometeam, foul1, foul2, foul3\ndbl (2): game, date\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrefs %&gt;% slice(1:5) %&gt;% kable()\n\n\n\n\ngame\ndate\nvisitor\nhometeam\nfoul1\nfoul2\nfoul3\n\n\n\n\n166\n20100126\nCLEM\nBC\nV\nV\nV\n\n\n224\n20100224\nDEPAUL\nCIN\nH\nH\nV\n\n\n317\n20100109\nMARQET\nNOVA\nH\nH\nH\n\n\n214\n20100228\nMARQET\nSETON\nV\nV\nH\n\n\n278\n20100128\nSETON\nSFL\nH\nV\nV\n\n\n\n\n\nWe will treat the games as independent in this analysis."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#different-likelihood-models",
    "href": "slides/02_likelihoods_ch2.html#different-likelihood-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Different likelihood models",
    "text": "Different likelihood models\nModel 1 (Unconditional Model): What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\nModel 2 (Conditional Model):\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?\n\n\nUltimately we want to decide which model is better."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#exploratory-data-analysis",
    "href": "slides/02_likelihoods_ch2.html#exploratory-data-analysis",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\nrefs %&gt;%\ncount(foul1, foul2, foul3) %&gt;% kable()\n\n\n\n\nfoul1\nfoul2\nfoul3\nn\n\n\n\n\nH\nH\nH\n3\n\n\nH\nH\nV\n2\n\n\nH\nV\nH\n3\n\n\nH\nV\nV\n7\n\n\nV\nH\nH\n7\n\n\nV\nH\nV\n1\n\n\nV\nV\nH\n5\n\n\nV\nV\nV\n2\n\n\n\n\n\n\nThere are\n\n46 total fouls on the home team\n44 total fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-1-unconditional-model",
    "href": "slides/02_likelihoods_ch2.html#model-1-unconditional-model",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Unconditional model",
    "text": "Model 1: Unconditional model\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihood-1",
    "href": "slides/02_likelihoods_ch2.html#likelihood-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood",
    "text": "Likelihood\nLet \\(p_H\\) be the probability the referees call a foul on the home team.\nThe likelihood for a single observation\n\\[Lik(p_H) = p_H^{y_i}(1 - p_H)^{n_i - y_i}\\]\nWhere \\(y_i\\) is the number of fouls called on the home team.\n(In this example, we know \\(n_i = 3\\) for all observations.)\n\nExample\nFor a single game where the first three fouls are \\(H, H, V\\), then\n\\[Lik(p_H) = p_H^{2}(1 - p_H)^{3 - 2} = p_H^{2}(1 - p_H)\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-1-likelihood-contribution",
    "href": "slides/02_likelihoods_ch2.html#model-1-likelihood-contribution",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Likelihood contribution",
    "text": "Model 1: Likelihood contribution\n\n\n\nFoul1\nFoul2\nFoul3\nn\nLikelihood Contribution\n\n\n\n\nH\nH\nH\n3\n\\(p_H^3\\)\n\n\nH\nH\nV\n2\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nH\n3\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nH\n5\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nV\n2\n\\((1 - p_H)^3\\)\n\n\n\n\nFill in A and B."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-1-likelihood-function",
    "href": "slides/02_likelihoods_ch2.html#model-1-likelihood-function",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Likelihood function",
    "text": "Model 1: Likelihood function\nBecause the observations (the games) are independent, the likelihood is\n\\[Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}\\]\nWe will use this function to find the maximum likelihood estimate (MLE). The MLE is the value between 0 and 1 where we are most likely to see the observed data."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#visualizing-the-likelihood",
    "href": "slides/02_likelihoods_ch2.html#visualizing-the-likelihood",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100\nlik &lt;- p^46 *(1 -p)^44\n\nx &lt;- tibble(p = p, lik = lik)\nggplot(data = x, aes(x = p, y = lik)) + \n  geom_point() + \n  geom_line() +\n  labs(y = \"Likelihood\",\n       title = \"Likelihood of p_H\")"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#q-what-is-your-best-guess-for-the-mle-hatp_h",
    "href": "slides/02_likelihoods_ch2.html#q-what-is-your-best-guess-for-the-mle-hatp_h",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: What is your best guess for the MLE, \\(\\hat{p}_H\\)?",
    "text": "Q: What is your best guess for the MLE, \\(\\hat{p}_H\\)?\nA. 0.489\nB. 0.500\nC. 0.511\nD. 0.556"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-maximum-likelihood-estimate",
    "href": "slides/02_likelihoods_ch2.html#finding-the-maximum-likelihood-estimate",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the maximum likelihood estimate",
    "text": "Finding the maximum likelihood estimate\nThere are three primary ways to find the MLE\n\n‚úÖ Approximate using a graph\n\n\n‚úÖ Numerical approximation\n\n\n‚úÖ Using calculus"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#approximate-mle-from-a-graph",
    "href": "slides/02_likelihoods_ch2.html#approximate-mle-from-a-graph",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Approximate MLE from a graph",
    "text": "Approximate MLE from a graph"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#find-the-mle-using-numerical-approximation",
    "href": "slides/02_likelihoods_ch2.html#find-the-mle-using-numerical-approximation",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Find the MLE using numerical approximation",
    "text": "Find the MLE using numerical approximation\nSpecify a finite set of possible values the for \\(p_H\\) and calculate the likelihood for each value\n\n# write an R function for the likelihood\nref_lik &lt;- function(ph) {\n  ph^46 *(1 - ph)^44\n}\n\n\n# use the optimize function to find the MLE\noptimize(ref_lik, interval = c(0,1), maximum = TRUE)\n\n$maximum\n[1] 0.5111132\n\n$objective\n[1] 8.25947e-28"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#find-mle-using-calculus",
    "href": "slides/02_likelihoods_ch2.html#find-mle-using-calculus",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\nFind the MLE by taking the first derivative of the likelihood function.\nThis can be tricky because of the Product Rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSince calculus is not a pre-req, we will forgo this quest."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-2-conditional-model",
    "href": "slides/02_likelihoods_ch2.html#model-2-conditional-model",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Conditional model",
    "text": "Model 2: Conditional model\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-2-likelihood-contributions",
    "href": "slides/02_likelihoods_ch2.html#model-2-likelihood-contributions",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\nNow let‚Äôs assume fouls are not independent within each game. We will specify this dependence using conditional probabilities.\n\nConditional probability: \\(P(A|B) =\\) Probability of \\(A\\) given \\(B\\) has occurred\n\n\n\nDefine new parameters:\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-2-likelihood-contributions-1",
    "href": "slides/02_likelihoods_ch2.html#model-2-likelihood-contributions-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\n\n\n\n\n\n\n\n\n\nFoul1\nFoul2\nFoul3\nn\nLikelihood Contribution\n\n\n\n\nH\nH\nH\n3\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(p_{H\\vert H Bias}) = (p_{H\\vert N})(p_{H\\vert H Bias})^2\\)\n\n\nH\nH\nV\n2\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(1 - p_{H\\vert H Bias})\\)\n\n\nH\nV\nH\n3\n\\((p_{H\\vert N})(1 - p_{H\\vert H Bias})(p_{H\\vert N}) = (p_{H\\vert N})^2(1 - p_{H\\vert H Bias})\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\((1 - p_{H\\vert N})(p_{H\\vert V Bias})(1 - p_{H\\vert N}) = (1 - p_{H\\vert N})^2(p_{H\\vert V Bias})\\)\n\n\nV\nV\nH\n5\n\\((1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(p_{H\\vert V Bias})\\)\n\n\nV\nV\nV\n2\n\\(\\begin{aligned}&(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(1-p_{H\\vert V Bias})\\\\ &=(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})^2\\end{aligned}\\)\n\n\n\nFill in A and B"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihood-function",
    "href": "slides/02_likelihoods_ch2.html#likelihood-function",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood function",
    "text": "Likelihood function\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n(Note: The exponents sum to 90, the total number of fouls in the data)\n\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#q-if-fouls-within-a-game-are-independent-how-would-you-expect-hatp_h-hatp_hvert-h-bias-and-hatp_hvert-v-bias-to-compare",
    "href": "slides/02_likelihoods_ch2.html#q-if-fouls-within-a-game-are-independent-how-would-you-expect-hatp_h-hatp_hvert-h-bias-and-hatp_hvert-v-bias-to-compare",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: If fouls within a game are independent, how would you expect \\(\\hat{p}_H\\), \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H\\vert V Bias}\\) to compare?",
    "text": "Q: If fouls within a game are independent, how would you expect \\(\\hat{p}_H\\), \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H\\vert V Bias}\\) to compare?\n\n\\(\\hat{p}_H\\) is greater than \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\n\\(\\hat{p}_{H\\vert H Bias}\\) is greater than \\(\\hat{p}_H\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\n\\(\\hat{p}_{H\\vert V Bias}\\) is greater than \\(\\hat{p}_H\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\nThey are all approximately equal."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#q-if-there-is-a-tendency-for-referees-to-call-a-foul-on-the-team-that-already-has-more-fouls-how-would-you-expect-hatp_h-and-hatp_hvert-h-bias-to-compare",
    "href": "slides/02_likelihoods_ch2.html#q-if-there-is-a-tendency-for-referees-to-call-a-foul-on-the-team-that-already-has-more-fouls-how-would-you-expect-hatp_h-and-hatp_hvert-h-bias-to-compare",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: If there is a tendency for referees to call a foul on the team that already has more fouls, how would you expect \\(\\hat{p}_H\\) and \\(\\hat{p}_{H\\vert H Bias}\\) to compare?",
    "text": "Q: If there is a tendency for referees to call a foul on the team that already has more fouls, how would you expect \\(\\hat{p}_H\\) and \\(\\hat{p}_{H\\vert H Bias}\\) to compare?\n\n\\(\\hat{p}_H\\) is greater than \\(\\hat{p}_{H\\vert H Bias}\\)\n\\(\\hat{p}_{H\\vert H Bias}\\) is greater than \\(\\hat{p}_H\\)\nThey are approximately equal."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihoods",
    "href": "slides/02_likelihoods_ch2.html#likelihoods",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihoods",
    "text": "Likelihoods\nModel 1 (Unconditional Model)\n\n\\(p_H\\): probability of a foul being called on the home team\n\n\nModel 2 (Conditional Model)\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihoods-1",
    "href": "slides/02_likelihoods_ch2.html#likelihoods-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihoods",
    "text": "Likelihoods\nModel 1 (Unconditional Model)\n\\[Lik(p_H) = p_H^{46}(1 - p_H)^{44}\\]\n\nModel 2 (Conditional Model)\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#maximum-likelihood-estimates",
    "href": "slides/02_likelihoods_ch2.html#maximum-likelihood-estimates",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Maximum likelihood estimates",
    "text": "Maximum likelihood estimates\nThe maximum likelihood estimate (MLE) is the value between 0 and 1 where we are most likely to see the observed data.\n\n\n\nModel 1 (Unconditional Model)\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\nModel 2 (Conditional Model)\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-mles-for-model-2",
    "href": "slides/02_likelihoods_ch2.html#finding-the-mles-for-model-2",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs for model 2",
    "text": "Finding the MLEs for model 2\nThe likelihood is\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n\nThe log-likelihood is\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]\n\n\nWe would like to find the MLEs for \\(p_{H| N}, p_{H|H Bias}, \\text{ and }p_{H |V Bias}\\)."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-mles-using-graphs",
    "href": "slides/02_likelihoods_ch2.html#finding-mles-using-graphs",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding MLEs using graphs",
    "text": "Finding MLEs using graphs\n\nWe need to find the MLEs for three parameters, therefore we would need to visualize a 4-dimensional object to find the MLEs from a graph. Given the difficulty of this task and the lack of precision in the estimates from this approach, we should rely on other approaches to find the MLEs in this instance.\n\n\n\nWe also can‚Äôt use calculus‚Ä¶ that leaves only 1 approach‚Ä¶. optimization via grid search or optim in R"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-13",
    "href": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-13",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (1/3)",
    "text": "Finding the MLEs using R (1/3)\nWe can write a function and do a grid search to find the values that maximize the log-likelihood.\n\n\nmaxloglik&lt;- function(nvals){\n  #nvals specifies the number of values\n  phn &lt;- seq(0, 1, length = nvals)\n  phh &lt;- seq(0, 1, length = nvals)\n  phv &lt;- seq(0, 1, length = nvals)\n  \n  loglik &lt;- expand.grid(phn, phh, phv) \n  colnames(loglik) &lt;- c(\"phn\", \"phh\", \"phv\")\n  \n  loglik &lt;- loglik %&gt;%\n    mutate(loglik  = log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9))\n  \n  loglik %&gt;%\n    arrange(desc(loglik)) %&gt;%\n    slice(1)\n}\n\n\nmaxloglik(100)\n\n        phn       phh       phv    loglik\n1 0.5252525 0.4040404 0.5858586 -61.57691"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-23",
    "href": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-23",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (2/3)",
    "text": "Finding the MLEs using R (2/3)\n\nDepending on the number of parameters, it may be hard to conduct a granular enough search to find the exact values of the MLEs.\nTherefore, one could use the function above to conduct a crude search to find starting values for R‚Äôs optim function.\nThe function optim differs from optimize in that it can optimize over multiple parameter values (The optimize function can only optimize over a single parameter value).\n\n\n\n# Function to calculate log-likelihood that will be used in the optim function\nloglik &lt;- function(params){\n  phn &lt;- params[1]\n  phh &lt;- params[2]\n  phv &lt;- params[3]\n\n  log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9)\n}"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-33",
    "href": "slides/02_likelihoods_ch2.html#finding-the-mles-using-r-33",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (3/3)",
    "text": "Finding the MLEs using R (3/3)\n\n# use manual search to get starting values \nstart_vals &lt;- maxloglik(50) %&gt;% select(-loglik)\n\n\n# Use optim function in R to find the values to maximize the log-likelihood\n#set fnscale = -1 to maximize (the default is minimize)\noptim(par = start_vals, fn = loglik, control=list(fnscale=-1))\n\n$par\n      phn       phh       phv \n0.5208272 0.4000361 0.5909793 \n\n$value\n[1] -61.57319\n\n$counts\nfunction gradient \n      66       NA \n\n$convergence\n[1] 0\n\n$message\nNULL"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#model-comparisons-1",
    "href": "slides/02_likelihoods_ch2.html#model-comparisons-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nNested models\nNon-nested models"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#nested-models-12",
    "href": "slides/02_likelihoods_ch2.html#nested-models-12",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Nested Models (1/2)",
    "text": "Nested Models (1/2)\nNested models: Models such that the parameters of the reduced model are a subset of the parameters for a larger model\nExample:\n\\[\\begin{aligned}&\\text{Model A: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\\\\\n&\\text{Model B: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\epsilon\\end{aligned}\\]\n\nModel A is nested in Model B. We could use likelihoods to test whether it is useful to add \\(x_3\\) and \\(x_4\\) to the model.\n\n\n\\[\\begin{aligned}&H_0: \\beta_3 = \\beta_4 = 0 \\\\\n&H_a: \\text{ at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#nested-models-22",
    "href": "slides/02_likelihoods_ch2.html#nested-models-22",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Nested models (2/2)",
    "text": "Nested models (2/2)\nAnother way to think about nested models: Parameters in larger model can be equated to get the simpler model or if some parameters can be set to constants\nExample:\n\\[\\begin{aligned}&\\text{Model 1: }p_H \\\\\n&\\text{Model 2: }p_{H| N}, p_{H| H Bias}, p_{H| V Bias}\\end{aligned}\\]\n\nModel 1 is nested in Model 2. The parameters \\(p_{H| N}\\), \\(p_{H|H Bias}\\), and \\(p_{H |V Bias}\\) can be set equal to \\(p_H\\) to get Model 1.\n\n\n\\[\\begin{aligned}&H_0: p_{H| N} = p_{H| H Bias} = p_{H| V Bias} = p_H \\\\\n&H_a: \\text{At least one of }p_{H| N}, p_{H| H Bias}, p_{H| V Bias} \\text{ differs from the others}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#steps-to-compare-models",
    "href": "slides/02_likelihoods_ch2.html#steps-to-compare-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Steps to compare models",
    "text": "Steps to compare models\n1Ô∏è‚É£ Find the MLEs for each model.\n2Ô∏è‚É£ Plug the MLEs into the log-likelihood function for each model to get the maximum value of the log-likelihood for each model.\n3Ô∏è‚É£ Find the difference in the maximum log-likelihoods\n4Ô∏è‚É£ Use the Likelihood Ratio Test to determine if the difference is statistically significant"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#steps-1---2",
    "href": "slides/02_likelihoods_ch2.html#steps-1---2",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Steps 1 - 2",
    "text": "Steps 1 - 2\nFind the MLEs for each model and plug them into the log-likelihood functions.\n\n\nModel 1:\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\n\nloglik1 &lt;- function(ph){\n log(ph^46 * (1 - ph)^44)\n}\nloglik1(46/90)\n\n[1] -62.36102\n\n\n. . .\nModel 2\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n. . .\n\nloglik2 &lt;- function(phn, phh, phv) {\n  log(phn^25 * (1 - phn)^23 * phh^8 * \n        (1 - phh)^12 * phv^13 * (1 - phv)^9)\n}\nloglik2(25/48, 8/20, 13/22)\n\n[1] -61.57319"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#step-3",
    "href": "slides/02_likelihoods_ch2.html#step-3",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Step 3",
    "text": "Step 3\nFind the difference in the log-likelihoods\n\n(diff &lt;- loglik2(25/48, 8/20, 13/22) - loglik1(46/90))\n\n[1] 0.7878318\n\n\n\n\nIs the difference in the maximum log-likelihoods statistically significant?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#likelihood-ratio-test",
    "href": "slides/02_likelihoods_ch2.html#likelihood-ratio-test",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood Ratio Test",
    "text": "Likelihood Ratio Test\nTest statistic\n\\[\\begin{aligned} LRT &= 2[\\max\\{\\log(Lik(\\text{larger model}))\\} - \\max\\{\\log(Lik(\\text{reduced model}))\\}]\\\\[10pt]\n&= 2\\log\\Bigg(\\frac{\\max\\{(Lik(\\text{larger model})\\}}{\\max\\{(Lik(\\text{reduced model})\\}}\\Bigg)\\end{aligned}\\]\n\n\nLRT follows a \\(\\chi^2\\) distribution where the degrees of freedom equal the difference in the number of parameters between the two models"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#step-4",
    "href": "slides/02_likelihoods_ch2.html#step-4",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Step 4",
    "text": "Step 4\n\n(LRT &lt;- 2 * (loglik2(25/48, 8/20, 13/22) - loglik1(46/90)))\n\n[1] 1.575664\n\n\n\nThe test statistic follows a \\(\\chi^2\\) distribution with 2 degrees of freedom. Therefore, the p-value is \\(P(\\chi^2 &gt; LRT)\\).\n\npchisq(LRT, 2, lower.tail = FALSE)\n\n[1] 0.4548299\n\n\n\n\nThe p-value is very large, so we fail to reject \\(H_0\\). We do not have convincing evidence that the conditional model is an improvement over the unconditional model. Therefore, we can stick with the unconditional model."
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#comparing-non-nested-models",
    "href": "slides/02_likelihoods_ch2.html#comparing-non-nested-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Comparing non-nested models",
    "text": "Comparing non-nested models\n\n\nAIC = -2(max log-likelihood) + 2p\n\n(Model1_AIC &lt;- 2 * loglik1(46/90) + 2 * 1)\n\n[1] -122.722\n\n(Model2_AIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 2 * 3)\n\n[1] -117.1464\n\n\n. . .\nBIC = -2(max log-likelihood) + plog(n)\n\n(Model1_BIC &lt;- 2 * loglik1(46/90) + 1 * log(30))\n\n[1] -121.3208\n\n(Model2_BIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 3 * log(30))\n\n[1] -112.9428\n\n\nChoose Model 1, the unconditional model, based on AIC and BIC"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#looking-ahead",
    "href": "slides/02_likelihoods_ch2.html#looking-ahead",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nLikelihoods help us answer the question of how likely we are to observe the data given different parameters\nIn this example, we did not consider covariates, so in practice the parameters we want to estimate will look more similar to this\n\n\n\\[p_H = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}\\]\n\n\n\nFinding the MLE becomes much more complex and numerical methods may be required.\n\nWe will primarily rely on software to find the MLE, but the conceptual ideas will be the same"
  },
  {
    "objectID": "slides/02_likelihoods_ch2.html#acknowledgements",
    "href": "slides/02_likelihoods_ch2.html#acknowledgements",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html",
    "href": "slides/02_likelihoods_ch2_o.html",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "",
    "text": "library(tidyverse)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#setup",
    "href": "slides/02_likelihoods_ch2_o.html#setup",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "",
    "text": "library(tidyverse)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#learning-goals",
    "href": "slides/02_likelihoods_ch2_o.html#learning-goals",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Learning goals",
    "text": "Learning goals\n\nDescribe the concept of a likelihood\nConstruct the likelihood for a simple model\nDefine the Maximum Likelihood Estimate (MLE) and use it to answer an analysis question\nIdentify three ways to calculate or approximate the MLE and apply these methods to find the MLE for a simple model\nUse likelihoods to compare models (next week)"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#what-is-the-likelihood",
    "href": "slides/02_likelihoods_ch2_o.html#what-is-the-likelihood",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "What is the likelihood?",
    "text": "What is the likelihood?\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values).\n\nUnlike Ordinary Least Squares (OLS), they do not require the responses be independent, identically distributed, and normal (iidN)\nThey are not the same as probability functions\n\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#fouls-in-college-basketball-games",
    "href": "slides/02_likelihoods_ch2_o.html#fouls-in-college-basketball-games",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\nThe data set 04-refs.csv includes 30 randomly selected NCAA men‚Äôs basketball games played in the 2009 - 2010 season.\nWe will focus on the variables foul1, foul2, and foul3, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.\n\nH: Foul was called on the home team\nV: Foul was called on the visiting team\n\n. . .\nWe are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.\n\n[The dataset was derived from basektball0910.csv used in BMLR Section 11.2"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#fouls-in-college-basketball-games-1",
    "href": "slides/02_likelihoods_ch2_o.html#fouls-in-college-basketball-games-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\n\nrefs &lt;- read_csv(\"data/04-refs.csv\")\n\nRows: 30 Columns: 7\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (5): visitor, hometeam, foul1, foul2, foul3\ndbl (2): game, date\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrefs %&gt;% slice(1:5) %&gt;% kable()\n\n\n\n\ngame\ndate\nvisitor\nhometeam\nfoul1\nfoul2\nfoul3\n\n\n\n\n166\n20100126\nCLEM\nBC\nV\nV\nV\n\n\n224\n20100224\nDEPAUL\nCIN\nH\nH\nV\n\n\n317\n20100109\nMARQET\nNOVA\nH\nH\nH\n\n\n214\n20100228\nMARQET\nSETON\nV\nV\nH\n\n\n278\n20100128\nSETON\nSFL\nH\nV\nV\n\n\n\n\n\nWe will treat the games as independent in this analysis."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#different-likelihood-models",
    "href": "slides/02_likelihoods_ch2_o.html#different-likelihood-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Different likelihood models",
    "text": "Different likelihood models\nModel 1 (Unconditional Model): What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\nModel 2 (Conditional Model):\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?\n\n. . .\nUltimately we want to decide which model is better."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#exploratory-data-analysis",
    "href": "slides/02_likelihoods_ch2_o.html#exploratory-data-analysis",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\nrefs %&gt;%\ncount(foul1, foul2, foul3) %&gt;% kable()\n\n\n\n\nfoul1\nfoul2\nfoul3\nn\n\n\n\n\nH\nH\nH\n3\n\n\nH\nH\nV\n2\n\n\nH\nV\nH\n3\n\n\nH\nV\nV\n7\n\n\nV\nH\nH\n7\n\n\nV\nH\nV\n1\n\n\nV\nV\nH\n5\n\n\nV\nV\nV\n2\n\n\n\n\n\n\nThere are\n\n46 total fouls on the home team\n44 total fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-1-unconditional-model",
    "href": "slides/02_likelihoods_ch2_o.html#model-1-unconditional-model",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Unconditional model",
    "text": "Model 1: Unconditional model\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihood-1",
    "href": "slides/02_likelihoods_ch2_o.html#likelihood-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood",
    "text": "Likelihood\nLet \\(p_H\\) be the probability the referees call a foul on the home team.\nThe likelihood for a single observation\n\\[Lik(p_H) = p_H^{y_i}(1 - p_H)^{n_i - y_i}\\]\nWhere \\(y_i\\) is the number of fouls called on the home team.\n(In this example, we know \\(n_i = 3\\) for all observations.)\n. . .\nExample\nFor a single game where the first three fouls are \\(H, H, V\\), then\n\\[Lik(p_H) = p_H^{2}(1 - p_H)^{3 - 2} = p_H^{2}(1 - p_H)\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-1-likelihood-contribution",
    "href": "slides/02_likelihoods_ch2_o.html#model-1-likelihood-contribution",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Likelihood contribution",
    "text": "Model 1: Likelihood contribution\n\n\n\nFoul1\nFoul2\nFoul3\nn\nLikelihood Contribution\n\n\n\n\nH\nH\nH\n3\n\\(p_H^3\\)\n\n\nH\nH\nV\n2\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nH\n3\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nH\n5\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nV\n2\n\\((1 - p_H)^3\\)\n\n\n\n. . .\nFill in A and B."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-1-likelihood-function",
    "href": "slides/02_likelihoods_ch2_o.html#model-1-likelihood-function",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 1: Likelihood function",
    "text": "Model 1: Likelihood function\nBecause the observations (the games) are independent, the likelihood is\n\\[Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}\\]\nWe will use this function to find the maximum likelihood estimate (MLE). The MLE is the value between 0 and 1 where we are most likely to see the observed data."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#visualizing-the-likelihood",
    "href": "slides/02_likelihoods_ch2_o.html#visualizing-the-likelihood",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100\nlik &lt;- p^46 *(1 -p)^44\n\nx &lt;- tibble(p = p, lik = lik)\nggplot(data = x, aes(x = p, y = lik)) + \n  geom_point() + \n  geom_line() +\n  labs(y = \"Likelihood\",\n       title = \"Likelihood of p_H\")"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#q-what-is-your-best-guess-for-the-mle-hatp_h",
    "href": "slides/02_likelihoods_ch2_o.html#q-what-is-your-best-guess-for-the-mle-hatp_h",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: What is your best guess for the MLE, \\(\\hat{p}_H\\)?",
    "text": "Q: What is your best guess for the MLE, \\(\\hat{p}_H\\)?\nA. 0.489\nB. 0.500\nC. 0.511\nD. 0.556"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-maximum-likelihood-estimate",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-maximum-likelihood-estimate",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the maximum likelihood estimate",
    "text": "Finding the maximum likelihood estimate\nThere are three primary ways to find the MLE\n. . .\n‚úÖ Approximate using a graph\n. . .\n‚úÖ Numerical approximation\n. . .\n‚úÖ Using calculus"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#approximate-mle-from-a-graph",
    "href": "slides/02_likelihoods_ch2_o.html#approximate-mle-from-a-graph",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Approximate MLE from a graph",
    "text": "Approximate MLE from a graph"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#find-the-mle-using-numerical-approximation",
    "href": "slides/02_likelihoods_ch2_o.html#find-the-mle-using-numerical-approximation",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Find the MLE using numerical approximation",
    "text": "Find the MLE using numerical approximation\nSpecify a finite set of possible values the for \\(p_H\\) and calculate the likelihood for each value\n\n# write an R function for the likelihood\nref_lik &lt;- function(ph) {\n  ph^46 *(1 - ph)^44\n}\n\n\n# use the optimize function to find the MLE\noptimize(ref_lik, interval = c(0,1), maximum = TRUE)\n\n$maximum\n[1] 0.5111132\n\n$objective\n[1] 8.25947e-28"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#find-mle-using-calculus",
    "href": "slides/02_likelihoods_ch2_o.html#find-mle-using-calculus",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\nFind the MLE by taking the first derivative of the likelihood function.\nThis can be tricky because of the Product Rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood)\n\n. . .\n\n\n\n\n\n\n\n\n\n. . .\nSince calculus is not a pre-req, we will forgo this quest."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-2-conditional-model",
    "href": "slides/02_likelihoods_ch2_o.html#model-2-conditional-model",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Conditional model",
    "text": "Model 2: Conditional model\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-2-likelihood-contributions",
    "href": "slides/02_likelihoods_ch2_o.html#model-2-likelihood-contributions",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\nNow let‚Äôs assume fouls are not independent within each game. We will specify this dependence using conditional probabilities.\n\nConditional probability: \\(P(A|B) =\\) Probability of \\(A\\) given \\(B\\) has occurred\n\n\n. . .\nDefine new parameters:\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-2-likelihood-contributions-1",
    "href": "slides/02_likelihoods_ch2_o.html#model-2-likelihood-contributions-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\n\n\n\n\n\n\n\n\n\nFoul1\nFoul2\nFoul3\nn\nLikelihood Contribution\n\n\n\n\nH\nH\nH\n3\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(p_{H\\vert H Bias}) = (p_{H\\vert N})(p_{H\\vert H Bias})^2\\)\n\n\nH\nH\nV\n2\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(1 - p_{H\\vert H Bias})\\)\n\n\nH\nV\nH\n3\n\\((p_{H\\vert N})(1 - p_{H\\vert H Bias})(p_{H\\vert N}) = (p_{H\\vert N})^2(1 - p_{H\\vert H Bias})\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\((1 - p_{H\\vert N})(p_{H\\vert V Bias})(1 - p_{H\\vert N}) = (1 - p_{H\\vert N})^2(p_{H\\vert V Bias})\\)\n\n\nV\nV\nH\n5\n\\((1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(p_{H\\vert V Bias})\\)\n\n\nV\nV\nV\n2\n\\(\\begin{aligned}&(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(1-p_{H\\vert V Bias})\\\\ &=(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})^2\\end{aligned}\\)\n\n\n\nFill in A and B"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihood-function",
    "href": "slides/02_likelihoods_ch2_o.html#likelihood-function",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood function",
    "text": "Likelihood function\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n(Note: The exponents sum to 90, the total number of fouls in the data)\n. . .\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#q-if-fouls-within-a-game-are-independent-how-would-you-expect-hatp_h-hatp_hvert-h-bias-and-hatp_hvert-v-bias-to-compare",
    "href": "slides/02_likelihoods_ch2_o.html#q-if-fouls-within-a-game-are-independent-how-would-you-expect-hatp_h-hatp_hvert-h-bias-and-hatp_hvert-v-bias-to-compare",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: If fouls within a game are independent, how would you expect \\(\\hat{p}_H\\), \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H\\vert V Bias}\\) to compare?",
    "text": "Q: If fouls within a game are independent, how would you expect \\(\\hat{p}_H\\), \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H\\vert V Bias}\\) to compare?\n\n\\(\\hat{p}_H\\) is greater than \\(\\hat{p}_{H\\vert H Bias}\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\n\\(\\hat{p}_{H\\vert H Bias}\\) is greater than \\(\\hat{p}_H\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\n\\(\\hat{p}_{H\\vert V Bias}\\) is greater than \\(\\hat{p}_H\\) and \\(\\hat{p}_{H \\vert V Bias}\\)\nThey are all approximately equal."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#q-if-there-is-a-tendency-for-referees-to-call-a-foul-on-the-team-that-already-has-more-fouls-how-would-you-expect-hatp_h-and-hatp_hvert-h-bias-to-compare",
    "href": "slides/02_likelihoods_ch2_o.html#q-if-there-is-a-tendency-for-referees-to-call-a-foul-on-the-team-that-already-has-more-fouls-how-would-you-expect-hatp_h-and-hatp_hvert-h-bias-to-compare",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Q: If there is a tendency for referees to call a foul on the team that already has more fouls, how would you expect \\(\\hat{p}_H\\) and \\(\\hat{p}_{H\\vert H Bias}\\) to compare?",
    "text": "Q: If there is a tendency for referees to call a foul on the team that already has more fouls, how would you expect \\(\\hat{p}_H\\) and \\(\\hat{p}_{H\\vert H Bias}\\) to compare?\n\n\\(\\hat{p}_H\\) is greater than \\(\\hat{p}_{H\\vert H Bias}\\)\n\\(\\hat{p}_{H\\vert H Bias}\\) is greater than \\(\\hat{p}_H\\)\nThey are approximately equal."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihoods",
    "href": "slides/02_likelihoods_ch2_o.html#likelihoods",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihoods",
    "text": "Likelihoods\nModel 1 (Unconditional Model)\n\n\\(p_H\\): probability of a foul being called on the home team\n\n. . .\nModel 2 (Conditional Model)\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihoods-1",
    "href": "slides/02_likelihoods_ch2_o.html#likelihoods-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihoods",
    "text": "Likelihoods\nModel 1 (Unconditional Model)\n\\[Lik(p_H) = p_H^{46}(1 - p_H)^{44}\\]\n. . .\nModel 2 (Conditional Model)\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#maximum-likelihood-estimates",
    "href": "slides/02_likelihoods_ch2_o.html#maximum-likelihood-estimates",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Maximum likelihood estimates",
    "text": "Maximum likelihood estimates\nThe maximum likelihood estimate (MLE) is the value between 0 and 1 where we are most likely to see the observed data.\n. . .\n\n\nModel 1 (Unconditional Model)\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\nModel 2 (Conditional Model)\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-mles-for-model-2",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-mles-for-model-2",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs for model 2",
    "text": "Finding the MLEs for model 2\nThe likelihood is\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n. . .\nThe log-likelihood is\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]\n. . .\nWe would like to find the MLEs for \\(p_{H| N}, p_{H|H Bias}, \\text{ and }p_{H |V Bias}\\)."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-mles-using-graphs",
    "href": "slides/02_likelihoods_ch2_o.html#finding-mles-using-graphs",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding MLEs using graphs",
    "text": "Finding MLEs using graphs\n\nWe need to find the MLEs for three parameters, therefore we would need to visualize a 4-dimensional object to find the MLEs from a graph. Given the difficulty of this task and the lack of precision in the estimates from this approach, we should rely on other approaches to find the MLEs in this instance.\n\n. . .\n\nWe also can‚Äôt use calculus‚Ä¶ that leaves only 1 approach‚Ä¶. optimization via grid search or optim in R"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-13",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-13",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (1/3)",
    "text": "Finding the MLEs using R (1/3)\nWe can write a function and do a grid search to find the values that maximize the log-likelihood.\n. . .\n\nmaxloglik&lt;- function(nvals){\n  #nvals specifies the number of values\n  phn &lt;- seq(0, 1, length = nvals)\n  phh &lt;- seq(0, 1, length = nvals)\n  phv &lt;- seq(0, 1, length = nvals)\n  \n  loglik &lt;- expand.grid(phn, phh, phv) \n  colnames(loglik) &lt;- c(\"phn\", \"phh\", \"phv\")\n  \n  loglik &lt;- loglik %&gt;%\n    mutate(loglik  = log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9))\n  \n  loglik %&gt;%\n    arrange(desc(loglik)) %&gt;%\n    slice(1)\n}\n\n\nmaxloglik(100)\n\n        phn       phh       phv    loglik\n1 0.5252525 0.4040404 0.5858586 -61.57691"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-23",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-23",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (2/3)",
    "text": "Finding the MLEs using R (2/3)\n\nDepending on the number of parameters, it may be hard to conduct a granular enough search to find the exact values of the MLEs.\nTherefore, one could use the function above to conduct a crude search to find starting values for R‚Äôs optim function.\nThe function optim differs from optimize in that it can optimize over multiple parameter values (The optimize function can only optimize over a single parameter value).\n\n. . .\n\n# Function to calculate log-likelihood that will be used in the optim function\nloglik &lt;- function(params){\n  phn &lt;- params[1]\n  phh &lt;- params[2]\n  phv &lt;- params[3]\n\n  log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9)\n}"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-33",
    "href": "slides/02_likelihoods_ch2_o.html#finding-the-mles-using-r-33",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Finding the MLEs using R (3/3)",
    "text": "Finding the MLEs using R (3/3)\n\n# use manual search to get starting values \nstart_vals &lt;- maxloglik(50) %&gt;% select(-loglik)\n\n\n# Use optim function in R to find the values to maximize the log-likelihood\n#set fnscale = -1 to maximize (the default is minimize)\noptim(par = start_vals, fn = loglik, control=list(fnscale=-1))\n\n$par\n      phn       phh       phv \n0.5208272 0.4000361 0.5909793 \n\n$value\n[1] -61.57319\n\n$counts\nfunction gradient \n      66       NA \n\n$convergence\n[1] 0\n\n$message\nNULL"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#model-comparisons-1",
    "href": "slides/02_likelihoods_ch2_o.html#model-comparisons-1",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nNested models\nNon-nested models"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#nested-models-12",
    "href": "slides/02_likelihoods_ch2_o.html#nested-models-12",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Nested Models (1/2)",
    "text": "Nested Models (1/2)\nNested models: Models such that the parameters of the reduced model are a subset of the parameters for a larger model\nExample:\n\\[\\begin{aligned}&\\text{Model A: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\\\\\n&\\text{Model B: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\epsilon\\end{aligned}\\]\n. . .\nModel A is nested in Model B. We could use likelihoods to test whether it is useful to add \\(x_3\\) and \\(x_4\\) to the model.\n. . .\n\\[\\begin{aligned}&H_0: \\beta_3 = \\beta_4 = 0 \\\\\n&H_a: \\text{ at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#nested-models-22",
    "href": "slides/02_likelihoods_ch2_o.html#nested-models-22",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Nested models (2/2)",
    "text": "Nested models (2/2)\nAnother way to think about nested models: Parameters in larger model can be equated to get the simpler model or if some parameters can be set to constants\nExample:\n\\[\\begin{aligned}&\\text{Model 1: }p_H \\\\\n&\\text{Model 2: }p_{H| N}, p_{H| H Bias}, p_{H| V Bias}\\end{aligned}\\]\n. . .\nModel 1 is nested in Model 2. The parameters \\(p_{H| N}\\), \\(p_{H|H Bias}\\), and \\(p_{H |V Bias}\\) can be set equal to \\(p_H\\) to get Model 1.\n. . .\n\\[\\begin{aligned}&H_0: p_{H| N} = p_{H| H Bias} = p_{H| V Bias} = p_H \\\\\n&H_a: \\text{At least one of }p_{H| N}, p_{H| H Bias}, p_{H| V Bias} \\text{ differs from the others}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#steps-to-compare-models",
    "href": "slides/02_likelihoods_ch2_o.html#steps-to-compare-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Steps to compare models",
    "text": "Steps to compare models\n1Ô∏è‚É£ Find the MLEs for each model.\n2Ô∏è‚É£ Plug the MLEs into the log-likelihood function for each model to get the maximum value of the log-likelihood for each model.\n3Ô∏è‚É£ Find the difference in the maximum log-likelihoods\n4Ô∏è‚É£ Use the Likelihood Ratio Test to determine if the difference is statistically significant"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#steps-1---2",
    "href": "slides/02_likelihoods_ch2_o.html#steps-1---2",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Steps 1 - 2",
    "text": "Steps 1 - 2\nFind the MLEs for each model and plug them into the log-likelihood functions.\n\n\nModel 1:\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\n\nloglik1 &lt;- function(ph){\n log(ph^46 * (1 - ph)^44)\n}\nloglik1(46/90)\n\n[1] -62.36102\n\n\n. . .\nModel 2\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n. . .\n\nloglik2 &lt;- function(phn, phh, phv) {\n  log(phn^25 * (1 - phn)^23 * phh^8 * \n        (1 - phh)^12 * phv^13 * (1 - phv)^9)\n}\nloglik2(25/48, 8/20, 13/22)\n\n[1] -61.57319"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#step-3",
    "href": "slides/02_likelihoods_ch2_o.html#step-3",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Step 3",
    "text": "Step 3\nFind the difference in the log-likelihoods\n\n(diff &lt;- loglik2(25/48, 8/20, 13/22) - loglik1(46/90))\n\n[1] 0.7878318\n\n\n\n. . .\nIs the difference in the maximum log-likelihoods statistically significant?"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#likelihood-ratio-test",
    "href": "slides/02_likelihoods_ch2_o.html#likelihood-ratio-test",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Likelihood Ratio Test",
    "text": "Likelihood Ratio Test\nTest statistic\n\\[\\begin{aligned} LRT &= 2[\\max\\{\\log(Lik(\\text{larger model}))\\} - \\max\\{\\log(Lik(\\text{reduced model}))\\}]\\\\[10pt]\n&= 2\\log\\Bigg(\\frac{\\max\\{(Lik(\\text{larger model})\\}}{\\max\\{(Lik(\\text{reduced model})\\}}\\Bigg)\\end{aligned}\\]\n\n. . .\nLRT follows a \\(\\chi^2\\) distribution where the degrees of freedom equal the difference in the number of parameters between the two models"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#step-4",
    "href": "slides/02_likelihoods_ch2_o.html#step-4",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Step 4",
    "text": "Step 4\n\n(LRT &lt;- 2 * (loglik2(25/48, 8/20, 13/22) - loglik1(46/90)))\n\n[1] 1.575664\n\n\n. . .\nThe test statistic follows a \\(\\chi^2\\) distribution with 2 degrees of freedom. Therefore, the p-value is \\(P(\\chi^2 &gt; LRT)\\).\n\npchisq(LRT, 2, lower.tail = FALSE)\n\n[1] 0.4548299\n\n\n. . .\nThe p-value is very large, so we fail to reject \\(H_0\\). We do not have convincing evidence that the conditional model is an improvement over the unconditional model. Therefore, we can stick with the unconditional model."
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#comparing-non-nested-models",
    "href": "slides/02_likelihoods_ch2_o.html#comparing-non-nested-models",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Comparing non-nested models",
    "text": "Comparing non-nested models\n\n\nAIC = -2(max log-likelihood) + 2p\n\n(Model1_AIC &lt;- 2 * loglik1(46/90) + 2 * 1)\n\n[1] -122.722\n\n(Model2_AIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 2 * 3)\n\n[1] -117.1464\n\n\n. . .\nBIC = -2(max log-likelihood) + plog(n)\n\n(Model1_BIC &lt;- 2 * loglik1(46/90) + 1 * log(30))\n\n[1] -121.3208\n\n(Model2_BIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 3 * log(30))\n\n[1] -112.9428\n\n\nChoose Model 1, the unconditional model, based on AIC and BIC"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#looking-ahead",
    "href": "slides/02_likelihoods_ch2_o.html#looking-ahead",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nLikelihoods help us answer the question of how likely we are to observe the data given different parameters\nIn this example, we did not consider covariates, so in practice the parameters we want to estimate will look more similar to this\n\n. . .\n\\[p_H = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}\\]\n. . .\n\nFinding the MLE becomes much more complex and numerical methods may be required.\n\nWe will primarily rely on software to find the MLE, but the conceptual ideas will be the same"
  },
  {
    "objectID": "slides/02_likelihoods_ch2_o.html#acknowledgements",
    "href": "slides/02_likelihoods_ch2_o.html#acknowledgements",
    "title": "Beyond Least Squares: Using Likelihoods",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Class Project",
    "section": "",
    "text": "You will be analyzing a dataset using regression analysis and a classification analysis.\nCollaboration: You can work individually or in groups of up to 3.\nAs one of my past professors liked to say, ‚ÄúKeep it Simple Stupid (KISS)‚Äù"
  },
  {
    "objectID": "project.html#part-1-research-questions-and-data",
    "href": "project.html#part-1-research-questions-and-data",
    "title": "Class Project",
    "section": "Part 1: Research Questions and Data",
    "text": "Part 1: Research Questions and Data\n\nDetermine a topic\nFind data that goes with that topic. See HERE.\n\n\nMust have at least 5 variables that may be useful in a classification and/or regression model.\n\n\nClean and prepare that data.\nWrite two research questions that you will use that data to investigate.\n\n\nOne question that can be answered with regression; make clear the outcome variable and its units.\nOne question that can be answered with classification; make clear the outcome variable and its possible categories.\n\n\nSubmit a project-proposal_last_names.html document that includes\n\n\nsource or sources of your data\na glimpse of your data (run glimpse())\nvariable definitions\nYour research questions\n\nMoodle link: HERE"
  },
  {
    "objectID": "project.html#part-2-eda",
    "href": "project.html#part-2-eda",
    "title": "Class Project",
    "section": "Part 2: EDA",
    "text": "Part 2: EDA\n\nConduct a full EDA on your dataset including any variables being considered for either research question. Minimally this should include the following. All included graphs/tables must have comments and discussion.\n\n\nClearly describe what the cases in the final clean dataset represent.\nWho collected the data? When, why, and how? Answer as much of this as the available information allows.\nUnivariate distributions of all variables.\nGraphs that specifically compare potential predictors to the variables that will be your response variables.\n\n\nSubmit a eda_last_names.html document to Moodle HERE."
  },
  {
    "objectID": "project.html#part-3-modeling",
    "href": "project.html#part-3-modeling",
    "title": "Class Project",
    "section": "Part 3: Modeling",
    "text": "Part 3: Modeling\nThe following should be included in your modeling report (generated from a Quarto file, or files).\n\nRegression\n\nRegression: Methods\n\nDescribe the models used.\nDescribe what you did to evaluate models.\n\nIndicate how you estimated quantitative evaluation metrics.\nIndicate what plots you used to evaluate models.\n\nDescribe the goals / purpose of the methods used in the overall context of your research investigations.\n\n\n\nRegression: Results\n\nSummarize your final model and justify your model choice (see below for ways to justify your choice).\n\nCompare the different models in light of evaluation metrics, plots, variable importance, and data context.\nDisplay evaluation metrics for different models in a clean, organized way. This display should include both the estimated CV metric as well as its standard deviation.\nBroadly summarize conclusions from looking at these CV evaluation metrics and their measures of uncertainty.\nSummarize conclusions from residual plots from initial models (don‚Äôt have to display them though).\n\nShow and interpret some representative examples of residual plots for your final model. Does the model show acceptable results in terms of any systematic biases?\n\n\n\nRegression: Conclusions\n\nInterpret you final model (show plots of estimated non-linear functions, or slope coefficients) for important predictors, and provide some general interpretations of what you learn from these\nInterpret evaluation metric(s) for the final model in context with units. Does the model show an acceptable amount of error?\nSummarization should show evidence of acknowledging the data context in thinking about the sensibility of these results.\n\n\n\n\nClassification\n\nClassification: Methods\n\nIndicate at least 2 different methods used to answer your classification research question.\n\nDescribe what you did to evaluate the models explored.\nIndicate how you estimated quantitative evaluation metrics.\n\nDescribe the goals / purpose of the methods used in the overall context of your research investigations.\n\n\n\nClassification: Results\n\nSummarize your final model and justify your model choice (see below for ways to justify your choice).\n\nCompare the different classification models tried in light of evaluation metrics, variable importance, and data context.\nDisplay evaluation metrics for different models in a clean, organized way. This display should include both the estimated metric as well as its standard deviation. (This won‚Äôt be available from OOB error estimation. If using OOB, don‚Äôt worry about reporting the SD.)\nBroadly summarize conclusions from looking at these evaluation metrics and their measures of uncertainty.\n\n\n\n\nClassification: Conclusions\n\nInterpret evaluation metric(s) for the final model in context. Does the model show an acceptable amount of error?\n\nIf using OOB error estimation, display the test (OOB) confusion matrix, and use it to interpret the strengths and weaknesses of the final model.\n\nSummarization should show evidence of acknowledging the data context in thinking about the sensibility of these results.\n\n\n\n\nSubmit\nSubmit one (or two) model_last_names.html document(s) with your analysis from the parts above. Submit on Moodle HERE."
  },
  {
    "objectID": "project.html#part-4-tell-people-about-it.",
    "href": "project.html#part-4-tell-people-about-it.",
    "title": "Class Project",
    "section": "Part 4: Tell people about it.",
    "text": "Part 4: Tell people about it.\nA 5-10 minute video presentation of your project. (Recording the presentation over Zoom is a good option for creating the video. You can record to your computer or to the cloud.)\n\nUpload the video to Google Drive.\nAll team members should have an equal speaking role in the presentation.\n\nIn order to record your presentation,\n\nStart a Zoom meeting and invite your project mates.\nOne of your share your screen with presentation slides (recommended: Quarto Presentation, Google Slides, or Powerpoint).\nPlease have everyone turn your video on so that we can see who is speaking.\nWhen you are ready to start, the host of the meeting (who ever started the meeting) can click Record on this Computer. I highly recommend that someone else start a timer so that you can make sure you keep the presentation to 10 minutes max.\nStart presenting!\nYou can Pause the recording, as needed, and then press start recording again.\nWhen you have finished recording, you can press Stop Recording. When you end the meeting, the recording (an mp4 file) will be downloaded to the computer of the individual who pressed Record.\nUpload the video to Google Drive.\n\nWe will watch these in class!\nSource: Brianna Heggeseth, STA 253"
  },
  {
    "objectID": "mini_project/01_project_poisson.html",
    "href": "mini_project/01_project_poisson.html",
    "title": "Mini Project 1",
    "section": "",
    "text": "Pick a partner.\nOne student should create a new R project in the class shared folder, STA363_inst_files-&gt;mini_projects (not your own folder). This allows both students to have access. Put both member‚Äôs initials in the project name.\nCreate a new folder inside your project folder called data\nCreate qmd or script files as needed."
  },
  {
    "objectID": "mini_project/01_project_poisson.html#project-setup",
    "href": "mini_project/01_project_poisson.html#project-setup",
    "title": "Mini Project 1",
    "section": "",
    "text": "Pick a partner.\nOne student should create a new R project in the class shared folder, STA363_inst_files-&gt;mini_projects (not your own folder). This allows both students to have access. Put both member‚Äôs initials in the project name.\nCreate a new folder inside your project folder called data\nCreate qmd or script files as needed."
  },
  {
    "objectID": "mini_project/01_project_poisson.html#instructions",
    "href": "mini_project/01_project_poisson.html#instructions",
    "title": "Mini Project 1",
    "section": "Instructions",
    "text": "Instructions\nFind data with a reasonable poisson response that you are interested in. Clean that data. Fit and interpret poisson regression models. Summarize your findings.\nData Options. Check out Data Links on the Useful Links part of the course website. TidyTuesday has quickly accessible data.\nThis project will be in a workshop style. The intention is for you to start and finish by the end of class time. We will follow a timeline:\n\n\n\n\n\n\n\nTask\nTiming\n\n\n\n\nFind Appropriate Data\n9:00 am - 9:20 am\n\n\nClean Data\n9:20 am - 9:50 am\n\n\nPerform EDA\n10:00 am - 10:30 am\n\n\nFit, Assess, and Compare Regression Models\n10:30 am - 11:00 am, 1:00 pm - 2:00 pm\n\n\nPrepare presentation\n2:00 pm - 2:20 pm\n\n\nPresent your findings\n2:20 pm - 2:40 pm\n\n\nSubmit your Final Report\nSubmit HTML Sunday 9/1 at 11:59 pm\n\n\n\n\nGrading\nEach Mini Project is worth 50 points (Labs are 10 points each).\n\n\n\n\n\n\n\nCategory\nPoints\n\n\n\n\nThe data chosen is appropriate, and the cleaning steps are correct and explained.\n5\n\n\nEDA is thorough. All included graphs and tables are paired with a discussion. EDA supports the choice of modeling technique.\n15\n\n\nThe model fitting process has a logical flow. Multiple models are considered and compared using statistical tests and multiple metrics. Any model that is interpreted has been assessed using residual plots and appropriate statistical tests.\n15\n\n\nThe code follows a sensible order and has been appropriately commented on.\n5\n\n\nThe presentation is concise, describes the data, highlights key parts of the EDA, describes minimally the final model, gives at least 1 interpretation in the context of a coefficient, and discusses limitations and potential future work.\n5\n\n\nThe report is well written, with correct spelling and grammar. The used code is included either inline or in an appendix at the end.\n5\n\n\n\n\n\nSubmission\nAdd format part of your final report document and then re-render:\n```{r}\n#| label: yaml_example\n#| eval: false\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\n    embed-resources: true\n---\n```\nWhen you are finished with your homework, be sure to Render the final document. Once rendered, you can download your file by:\n\nFinding the .html file in your File pane (on the bottom right of the screen)\nClick the check box next to the file\nClick the blue gear above and then click ‚ÄúExport‚Äù to download\nSubmit your final html document to the respective assignment on Moodle"
  },
  {
    "objectID": "labs/03_poisson/03_FullMoon_fillable.html",
    "href": "labs/03_poisson/03_FullMoon_fillable.html",
    "title": "Chapter 4 - Poisson Regression",
    "section": "",
    "text": "Is there initial evidence of more bites during full moon phases?\nWhy can‚Äôt we just perform a t-test comparing full moon periods to non-full moon periods using period-level data (n=10)?\nWhat options can you think of for handling the fact that Period 5 is based on only 2 lunar days? What are the modeling implications of including number of days in a period as an offset term?\nInterpret model parameters from fit1.\nIs there any evidence of lack of fit in fit1? What factors may lead to lack of fit?\nDoes full moon have an effect above and beyond the linear cycle trend? Interpret the coefficient and a 95% confidence interval for the fullmoon term in fit3.\nWhat is fit4 doing? Does it offer an improvement over fit3?\nWhat evidence is there that fit5 (which uses bitesbyday.csv) is the analysis performed by the authors of this paper?\nBased on this analysis, does it make you more wary of animal bites during full moons?\n\n\n\n\nIs there evidence of lack of fit in fit5? Cite evidence both from a goodness of fit test and from comparing means and variances by period.\nIf overdispersion goes uncorrected, what are implications for p-values and CIs for model coefficients?\n\n\n\nOne solution is to simply add a second parameter to inflate variances, so that \\(Var(Y_i)=\\phi\\lambda_i\\). This is called a ‚Äúquasi-Poisson‚Äù or, in general, a ‚Äúquasi-likelihood‚Äù approach, because our data no longer follows a true Poisson distribution.\n\n\n\nAnother solution is to model response using a negative binomial distribution, so that \\(Y\\sim NegBinom(\\theta,p)\\). This distribution comes about if \\(Y|Œª\\sim Poisson(Œª)\\), but the \\(\\lambda\\)‚Äôs themselves are randomly chosen according to a gamma distribution: \\(\\lambda \\sim gamma(Œ∏,\\frac{(1-p)}{p})\\). In this case, $E(Y)==$ and \\(Var(Y)=\\theta \\frac{p}{(1-p)^2} =\\mu+\\frac{\\mu^2}{\\theta}\\), so that \\(\\frac{\\mu^2}{\\theta}\\) is the amount of overdispersion.\n\nCompare the following estimates, tests, and intervals under usual Poisson regression, quasi-Poisson regression, and negative binomial regression:\n\n\n\n\n\n\n\n\n\n\n\nPoisson\nQuasi-poisson\nNegative Binomial\n\n\n\n\n\\(\\phi\\)\n\n\n\n\n\n\\(SE(\\hat{\\beta}_4\\))\n\n\n\n\n\nWald-type test stat\n\n\n\n\n\nWald-type p-value\n\n\n\n\n\nLRT-type test stat\n\n\n\n\n\nLRT-type test stat\n\n\n\n\n\nLRT-type p-value\n\n\n\n\n\nCI - profile for \\(e^{\\beta_4}\\)\n\n\n\n\n\nCI-Wald-type for \\(e^{\\beta_4}\\)"
  },
  {
    "objectID": "labs/03_poisson/03_FullMoon_fillable.html#questions",
    "href": "labs/03_poisson/03_FullMoon_fillable.html#questions",
    "title": "Chapter 4 - Poisson Regression",
    "section": "",
    "text": "Is there initial evidence of more bites during full moon phases?\nWhy can‚Äôt we just perform a t-test comparing full moon periods to non-full moon periods using period-level data (n=10)?\nWhat options can you think of for handling the fact that Period 5 is based on only 2 lunar days? What are the modeling implications of including number of days in a period as an offset term?\nInterpret model parameters from fit1.\nIs there any evidence of lack of fit in fit1? What factors may lead to lack of fit?\nDoes full moon have an effect above and beyond the linear cycle trend? Interpret the coefficient and a 95% confidence interval for the fullmoon term in fit3.\nWhat is fit4 doing? Does it offer an improvement over fit3?\nWhat evidence is there that fit5 (which uses bitesbyday.csv) is the analysis performed by the authors of this paper?\nBased on this analysis, does it make you more wary of animal bites during full moons?\n\n\n\n\nIs there evidence of lack of fit in fit5? Cite evidence both from a goodness of fit test and from comparing means and variances by period.\nIf overdispersion goes uncorrected, what are implications for p-values and CIs for model coefficients?\n\n\n\nOne solution is to simply add a second parameter to inflate variances, so that \\(Var(Y_i)=\\phi\\lambda_i\\). This is called a ‚Äúquasi-Poisson‚Äù or, in general, a ‚Äúquasi-likelihood‚Äù approach, because our data no longer follows a true Poisson distribution.\n\n\n\nAnother solution is to model response using a negative binomial distribution, so that \\(Y\\sim NegBinom(\\theta,p)\\). This distribution comes about if \\(Y|Œª\\sim Poisson(Œª)\\), but the \\(\\lambda\\)‚Äôs themselves are randomly chosen according to a gamma distribution: \\(\\lambda \\sim gamma(Œ∏,\\frac{(1-p)}{p})\\). In this case, $E(Y)==$ and \\(Var(Y)=\\theta \\frac{p}{(1-p)^2} =\\mu+\\frac{\\mu^2}{\\theta}\\), so that \\(\\frac{\\mu^2}{\\theta}\\) is the amount of overdispersion.\n\nCompare the following estimates, tests, and intervals under usual Poisson regression, quasi-Poisson regression, and negative binomial regression:\n\n\n\n\n\n\n\n\n\n\n\nPoisson\nQuasi-poisson\nNegative Binomial\n\n\n\n\n\\(\\phi\\)\n\n\n\n\n\n\\(SE(\\hat{\\beta}_4\\))\n\n\n\n\n\nWald-type test stat\n\n\n\n\n\nWald-type p-value\n\n\n\n\n\nLRT-type test stat\n\n\n\n\n\nLRT-type test stat\n\n\n\n\n\nLRT-type p-value\n\n\n\n\n\nCI - profile for \\(e^{\\beta_4}\\)\n\n\n\n\n\nCI-Wald-type for \\(e^{\\beta_4}\\)"
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood_fillable.html",
    "href": "labs/02_likelihood/02_likelihood_fillable.html",
    "title": "Chapter 2 - Likelihoods",
    "section": "",
    "text": "Consider a small example with 3 families with compositions of children given by BBG, GBG, and GG.\nFind the maximum likelihood estimator (MLE) for by:\n\n\nConducting a numerical search in R for the largest likelihood over a fine grid of values 0-1.\nConducting a numerical search in R for the largest log-likelihood between 0 and 1. Illustrate the process graphically, and report the maximum value of the likelihood and log-likelihood functions. Does it make sense that both methods would agree (and agree with the mathematical approach)?\n\n\nApply Model 1 to the NLSY data (families in Table 2 with 3 or fewer children). Find the MLE for by adapting the R code for (1).\n\n\n\n\n= probability of a boy when previously have had an equal number of boys and girls (neutral)\n= probability of a boy when previously have had more boys than girls (boy bias)\n= probability of a boy when previously have had more girls than boys (girl bias)\n\nWrite out the likelihood function given Model 2 for the small set of data in (1). [You could also try BGG, GGB, BBB just for fun.]"
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood_fillable.html#questions",
    "href": "labs/02_likelihood/02_likelihood_fillable.html#questions",
    "title": "Chapter 2 - Likelihoods",
    "section": "",
    "text": "Consider a small example with 3 families with compositions of children given by BBG, GBG, and GG.\nFind the maximum likelihood estimator (MLE) for by:\n\n\nConducting a numerical search in R for the largest likelihood over a fine grid of values 0-1.\nConducting a numerical search in R for the largest log-likelihood between 0 and 1. Illustrate the process graphically, and report the maximum value of the likelihood and log-likelihood functions. Does it make sense that both methods would agree (and agree with the mathematical approach)?\n\n\nApply Model 1 to the NLSY data (families in Table 2 with 3 or fewer children). Find the MLE for by adapting the R code for (1).\n\n\n\n\n= probability of a boy when previously have had an equal number of boys and girls (neutral)\n= probability of a boy when previously have had more boys than girls (boy bias)\n= probability of a boy when previously have had more girls than boys (girl bias)\n\nWrite out the likelihood function given Model 2 for the small set of data in (1). [You could also try BGG, GGB, BBB just for fun.]"
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary_fillable.html",
    "href": "labs/01_linear_regression/01_banksalary_fillable.html",
    "title": "Linear Regression Review Lab",
    "section": "",
    "text": "Example: Sex discrimination in bank salaries. In the 1970‚Äôs, Harris Trust was sued for sex discrimination in the salaries it paid its employees. One approach to addressing this issue was to examine the starting salaries of all skilled, entry-level clerical workers between 1965 and 1975. The data is saved under banksalary.csv, and relevant R code can be found in the STA363_inst_files folder on the home directory of the RStudio Server. banksalary.qmd.\nFirst, we will speculate on what we expect to find and then we will perform an analysis using the data.\nRead the data in and use aview() to see the data, but do not do anything else with the data on the computer until question 6.\n\nIdentify the observational units, the response variable, and explanatory variables.\nGiven the mean starting salary of male workers ($5957) was 16% higher than the mean starting salary of female workers ($5139): Is this enough evidence to conclude sex discrimination exists? If not, what further evidence would you need?\nHow would you expect age, experience, and education to each be related to starting salary?\nWhy might it be important to control for seniority (number of years with the bank) if we are only concerned with the salary when the worker started?\nDo you expect any explanatory variables (including sex) to be closely related to each other? What implications would this have for modeling?\n\nUsing the data‚Ä¶\nOne approach is to construct a good model for beginning salaries while requiring sex as a predictor, to determine the significance of sex after controlling for the other covariates. Then we can explore interactions with sex to see if its effect is consistent across levels of other predictors.\n\nUse the data to address the primary question of interest here using only the beginning salary and sex variables. Be sure to discuss plots and summary statistics first, and then look at test(s) of significance.\nConstruct plots to investigate how each of the potential confounders (age, experience, education) is related to beginning salaries. Describe your findings.\nDoes seniority play a role in the variation of starting salaries? In what way?\nExamine how the explanatory variables (including sex) are related to each other, if at all. What implications would this have for modeling?\nFit a simple linear regression model with starting salary as the response and education as the sole explanatory variable. Interpret the intercept and slope of this model; also interpret the R-squared value. Is there a significant relationship between education and starting salary?\n\nIntercept:\nSlope:\nR2\nSignificance:\n\nDoes model1 from question 10 meet all linear regression assumptions? List each assumption and how you decided if it was met or not.\nIs a model with all 4 confounding variables better than a model with just education? Justify with an appropriate significance test in addition to summary statistics of model performance.\nYou should have noticed that the term for age was not significant in the model3. What does this imply about age and about future modeling steps?\nThe relationship between experience and beginning salary exhibits some curvature. How might it be interpreted in this context? Determine whether a quadratic term in experience improves a model without curvature.\nBased on model6, what conclusions can be drawn about sex discrimination at Harris Trust? Do these conclusions have to be qualified at all, or are they pretty clear cut? Interpret a 95% confidence interval for the male indicator variable in context to help with your response.\nDo any explanatory variables exhibit an interaction with sex. If so, what are the implications for your answer in (15)?\nOften salary data is logged before analysis. Would you recommend logging starting salary in this study? Support your decision analytically.\nRegardless of your answer to (17), provide an interpretation for the coefficient for the male coefficient in model6a after logging starting salary."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Regression Schedule",
    "section": "",
    "text": "Note: The timeline of topics and assignments might be updated throughout the semester.\n\n\n\n\n\n\n\n\n\nDay\nDate\nTopic\nSlides\nOutline\nProject\nLab\nHomework\nExam\n\n\n\n\n1\n26 Aug\nSyllabus, Chapter 1 - Review MLR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\n27 Aug\nChapter 2 - Likelihoods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n28 Aug\nChapter 3 - Distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\n29 Aug\nChapter 4 - Poisson Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\n30 Aug\nPoisson Regression Mini Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\n2 Sep\nCh 4 - Poisson Reg. & Ch 5 - GLMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7\n3 Sep\nCh 5 - GLMs & Ch 6 - Logistics Reg.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\n4 Sep\nCh 6 - Logistics Reg. & Ch 7 - Correlated Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\n5 Sep\nGLM Mini Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\n6 Sep\nExam\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\n9 Sep\nChapter 8 - Multilevel Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\n10 Sep\nChapter 8 - Multilevel Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13\n11 Sep\nChapter 9 - Two-Level Longitudinal Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14\n12 Sep\nMultilevel Model Practice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\n13 Sep\nPolynomial Regression, Splines, and GAMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16\n16 Sep\nPolynomial Regression, Splines, and GAMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n17\n17 Sep\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n18\n18 Sep\nExam",
    "crumbs": [
      "Course Contents",
      "Schedule & Assignments"
    ]
  },
  {
    "objectID": "hw/05_hw_ch4_5.html",
    "href": "hw/05_hw_ch4_5.html",
    "title": "Homework 5",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_4 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw4.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/05_hw_ch4_5.html#setup",
    "href": "hw/05_hw_ch4_5.html#setup",
    "title": "Homework 5",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_4 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw4.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/05_hw_ch4_5.html#instructions",
    "href": "hw/05_hw_ch4_5.html#instructions",
    "title": "Homework 5",
    "section": "Instructions",
    "text": "Instructions\nBe sure to include the relevant R code as well as full sentences answering each of the questions (i.e.¬†if I ask for the average, you can output the answer in R but also write a full sentence with the answer). Be sure to frequently save your files!\nData for the homework will be in the STA363_inst_files -&gt; data folder."
  },
  {
    "objectID": "hw/05_hw_ch4_5.html#exercises",
    "href": "hw/05_hw_ch4_5.html#exercises",
    "title": "Homework 5",
    "section": "Exercises",
    "text": "Exercises\nAll problems are from The main textbook is: Beyond Multiple Linear Regression by Paul Roback and Julie Legler ‚Äì it is freely available online. Chapters 1-9. Abbreviated BMLR.\nUse the numbering on the left. The codes are for instructor use (Ex: C1)."
  },
  {
    "objectID": "hw/05_hw_ch4_5.html#exercise-1",
    "href": "hw/05_hw_ch4_5.html#exercise-1",
    "title": "Homework 5",
    "section": "Exercise 1",
    "text": "Exercise 1\n\n(C15) Dating online. Researchers are interested in the number of dates respondents arranged online and whether the rates differ by age group. Questions which elicit responses similar to this can be found in the Pew Survey concerning dating online and relationships [@Duggan2013]. Each survey respondent was asked how many dates they have arranged online in the past 3 months as well as the typical amount of time, \\(t\\), in hours, they spend online weekly. Some rows of data appear in Table 1.\n\nIdentify the response, predictor, and offset in this context. Does using an offset make sense?\nWrite out a model for this data. As part of your model description, define the parameter, \\(\\lambda\\).\nConsider a zero-inflated Poisson model for this data. Describe what the `true zeros‚Äô would be in this setting.\n\n\n\n\n\n\nTable 1: Sample data for Exercise 1.\n\n\nAge\nTime Online\nNumber of Dates Arranged Online\n\n\n\n\n19\n35\n3\n\n\n29\n20\n5\n\n\n38\n15\n0\n\n\n55\n10\n0"
  },
  {
    "objectID": "hw/05_hw_ch4_5.html#exercise-2",
    "href": "hw/05_hw_ch4_5.html#exercise-2",
    "title": "Homework 5",
    "section": "Exercise 2",
    "text": "Exercise 2\n\n(C16) Poisson approximation: rare events. For rare diseases, the probability of a case occurring, \\(p\\), in a very large population, \\(n\\), is small. With a small \\(p\\) and large \\(n\\), the random variable \\(Y\\)= the number of cases out of \\(n\\) people can be approximated using a Poisson random variable with \\(\\lambda = np\\). If the count of those with the disease is observed in several different populations independently of one another, the \\(Y_i\\) represents the number of cases in the \\(i^{th}\\) population and can be approximated using a Poisson random variable with \\(\\lambda_i=n_ip_i\\) where \\(p_i\\) is the probability of a case for the \\(i^{th}\\) population. Poisson regression can take into account the differences in the population sizes, \\(n_i\\), using as an offset log(\\(n_i\\)) as well as differences in a population characteristic like \\(x_i\\). The coefficient of the offset is set at one; it is not estimated like the other coefficients. Thus the model statement has the form: \\(log(\\lambda_i) = \\beta_0+\\beta_1x_i + log(n_i)\\), where \\(Y_i  \\sim\\) Poisson(\\(\\lambda_i = n_i p_i\\)). Note that \\(\\lambda_i\\) depends on \\(x_i\\) which may differ for the different populations.\n@Scotto1974 wondered if skin cancer rates by age group differ by city. Based on their data in Table 2, identify and describe the following quantities which appear in the description of the Poisson approximation for rare events:\n\nA case,\nThe population size, \\(n_i\\),\nProbability, \\(p_i\\),\nPoisson parameter, \\(\\lambda_i\\),\nPoisson random variables, \\(Y_i\\), and\nThe predictors, \\(X_i\\).\n\n\n\n\n\n\nTable 2: Data from Scotto et al. (1974) on the number of cases of non-melanoma skin cancer for women by age group in two metropolitan areas (Minneapolis-St. Paul and Dallas-Ft. Worth); the year is unknown.\n\n\nNumber of Cases\nPopulation\nAge Group\nCity\n\n\n\n\n1\n172675\n15-24\n1\n\n\n16\n123065\n25-34\n1\n\n\n...\n...\n...\n...\n\n\n226\n29007\n75-84\n2\n\n\n65\n7538\n85+\n2\n\n\n\n The columns contain: number of cases, population size, age group, and city (1=Minneapolis-St. Paul, 2=Dallas-Ft. Worth)."
  },
  {
    "objectID": "hw/05_hw_ch4_5.html#exercise-3",
    "href": "hw/05_hw_ch4_5.html#exercise-3",
    "title": "Homework 5",
    "section": "Exercise 3",
    "text": "Exercise 3\n\n(G6) U.S. National Medical Expenditure Survey. The data set NMES1988 in the AER package contains a sample of individuals over 65 who are covered by Medicare in order to assess the demand for health care through physician office visits, outpatient visits, ER visits, hospital stays, etc. The data can be accessed by installing and loading the AER package and then running data(NMES1988). More background information and references about the NMES1988 data can be found in help pages for the AER package.\n\nShow through graphical means that there are more respondents with 0 visits than might be expected under a Poisson model.\nFit a ZIP model for the number of physician office visits using chronic, health, and insurance as predictors for the Poisson count, and chronic and insurance as the predictors for the binary part of the model. Then, provide interpretations in context for the following model parameters:\n\n\nchronic in the Poisson part of the model\npoor health in the Poisson part of the model\nthe Intercept in the logistic part of the model\ninsurance in the logistic part of the model\n\n\nIs there significant evidence that the ZIP model is an improvement over a simple Poisson regression model?"
  },
  {
    "objectID": "hw/05_hw_ch4_5.html#exercise-4",
    "href": "hw/05_hw_ch4_5.html#exercise-4",
    "title": "Homework 5",
    "section": "Exercise 4",
    "text": "Exercise 4\n\n(C1) For each distribution below,\n\nWrite the pmf or pdf in one-parameter exponential form, if possible.\nDescribe an example of a setting where this random variable might be used.\nIdentify the canonical link function, and\nCompute \\(\\mu = -\\frac{c'(\\theta)}{b'(\\theta)}\\) and \\(\\sigma^2 = \\frac{b''(\\theta)c'(\\theta)-c''(\\theta)b'(\\theta)}{[b'(\\theta)]^3}\\) and compare with known \\(\\operatorname{E}(Y)\\) and \\(\\operatorname{Var}(Y)\\).\n\n\n\nBinomial (for fixed \\(n\\)): Y = number of successes in \\(n\\) independent, identical trials\n\n\\[P(Y=y;p)=\\left(\\begin{array} {c}  n\\\\y  \\end{array}\\right) p^y(1-p)^{(n-y)}\\]\n\nGamma (for fixed \\(r\\)): Y = time spent waiting for the \\(r^{th}\\) event in a Poisson process with an average rate of \\(\\lambda\\) events per unit of time\n\n\\[f(y; \\lambda) = \\frac{\\lambda^r}{\\Gamma(r)} y^{r-1} e^{-\\lambda y}\\]"
  },
  {
    "objectID": "hw/03_hw_ch3.html",
    "href": "hw/03_hw_ch3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_3 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw3.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/03_hw_ch3.html#setup",
    "href": "hw/03_hw_ch3.html#setup",
    "title": "Homework 3",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_3 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw3.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/03_hw_ch3.html#instructions",
    "href": "hw/03_hw_ch3.html#instructions",
    "title": "Homework 3",
    "section": "Instructions",
    "text": "Instructions\nBe sure to include the relevant R code as well as full sentences answering each of the questions (i.e.¬†if I ask for the average, you can output the answer in R but also write a full sentence with the answer). Be sure to frequently save your files!\nData for the homework will be in the STA363_inst_files -&gt; data folder."
  },
  {
    "objectID": "hw/03_hw_ch3.html#exercises",
    "href": "hw/03_hw_ch3.html#exercises",
    "title": "Homework 3",
    "section": "Exercises",
    "text": "Exercises\nAll problems are from The main textbook is: Beyond Multiple Linear Regression by Paul Roback and Julie Legler ‚Äì it is freely available online. Chapters 1-9.. Abbreviated BMLR.\nUse the numbering on the left. The codes are for instructor use (Ex: C1).\n\nExercise 1\n\n(C1) At what value of \\(p\\) is the standard deviation of a binary random variable smallest? When is standard deviation largest?\n\n\n\nExercise 2\n\n(C3) How are exponential and Poisson random variables related?\n\n\n\nExercise 3\n\n(C7) Chapter 1 also asked you to consider a scenario where ‚ÄúResearchers are attempting to see if socioeconomic status and parental stability are predictive of low birthweight. They classify a low birthweight as below 2500 g, hence our response is binary: 1 for low birthweight, and 0 when the birthweight is not low.‚Äù What distribution might be useful to model if a newborn has low birthweight?\n\n\n\nExercise 4\n\n(C9) Describe a scenario which could be modeled using a gamma distribution.\n\n\n\nExercise 5\n\n(G2) Gamma-Poisson mixture I. Use the R function rpois() to generate 10,000 \\(x_i\\) from a plain old vanilla Poisson random variable, \\(X \\sim \\textrm{Poisson}(\\lambda=1.5)\\). Plot a histogram of this distribution and note its mean and standard deviation. Next, let \\(Y \\sim \\textrm{Gamma}(r = 3, \\lambda = 2)\\) and use rgamma() to generate 10,000 random \\(y_i\\) from this distribution. Now, consider 10,000 different Poisson distributions where \\(\\lambda_i = y_i\\). Randomly generate one \\(z_i\\) from each Poisson distribution. Plot a histogram of these \\(z_i\\) and compare it to your original histogram of \\(X\\) (where \\(X \\sim \\textrm{Poisson}(1.5)\\)). How do the means and standard deviations compare?"
  },
  {
    "objectID": "hw/01_hw_ch1.html",
    "href": "hw/01_hw_ch1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Go to our RStudio Server at http://turing.cornellcollege.edu:8787/\nGo to your class folder you made named ‚ÄúSTA363‚Äù\nCreate a new folder called FirstInitial_Last_Initial_HW with your initials.\n\n\n\n\nEach of your assignments will begin with the following steps.\n\nFinding the instructions on our website: https://stats-tgeorge.github.io/STA363_AdvReg/\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new project. and giving it a sensible name such as homework_1 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw1.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/01_hw_ch1.html#this-one-time",
    "href": "hw/01_hw_ch1.html#this-one-time",
    "title": "Homework 1",
    "section": "",
    "text": "Go to our RStudio Server at http://turing.cornellcollege.edu:8787/\nGo to your class folder you made named ‚ÄúSTA363‚Äù\nCreate a new folder called FirstInitial_Last_Initial_HW with your initials."
  },
  {
    "objectID": "hw/01_hw_ch1.html#every-homework",
    "href": "hw/01_hw_ch1.html#every-homework",
    "title": "Homework 1",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nFinding the instructions on our website: https://stats-tgeorge.github.io/STA363_AdvReg/\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new project. and giving it a sensible name such as homework_1 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw1.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Advanced Regression",
    "section": "",
    "text": "Course Description\nFollowing a second regression course, this class will begin with a review of multiple linear regression, but now using R. New topics will include probability distributions, likelihoods, differentiating binary vs binomial logistic regression, and poisson regression including its variants. The class of generalized linear models will then be presented which unifies all past modeling approaches. All methods are presented using realistic case studies. Conducting and communicating the modeling process including exploratory data analysis, model exploration and selection, and inferences are all emphasized.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-instructor.html",
    "href": "course-instructor.html",
    "title": "Instructor",
    "section": "",
    "text": "Dr.¬†Tyler George (he/him) is a Assistant Professor of Statistics at Cornell College. He received his PhD in Statistics and Analytics from Central Michigan University. During his PhD he also studied mathematics and statistics education. His dissertation work involved creating a new lack of fit test for linear regression models. His interests are broadly in statistics, data science and best pedagogy to teach them.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMonday - Thursday 3:05pm - 4:05pm\nWest 311\n\n\nOther Times by Appointment\nWest 311\n\n\n\nOffice hours are for STUDENTS. Please take advantage of them to get help with class, advising, and/or getting to know your professor! If you miss class, check out course calendar to verify there have been no changes.",
    "crumbs": [
      "Course information",
      "Instructor"
    ]
  },
  {
    "objectID": "course-instructor.html#instructor",
    "href": "course-instructor.html#instructor",
    "title": "Instructor",
    "section": "",
    "text": "Dr.¬†Tyler George (he/him) is a Assistant Professor of Statistics at Cornell College. He received his PhD in Statistics and Analytics from Central Michigan University. During his PhD he also studied mathematics and statistics education. His dissertation work involved creating a new lack of fit test for linear regression models. His interests are broadly in statistics, data science and best pedagogy to teach them.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMonday - Thursday 3:05pm - 4:05pm\nWest 311\n\n\nOther Times by Appointment\nWest 311\n\n\n\nOffice hours are for STUDENTS. Please take advantage of them to get help with class, advising, and/or getting to know your professor! If you miss class, check out course calendar to verify there have been no changes.",
    "crumbs": [
      "Course information",
      "Instructor"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources the course, Introduction to Data Science, offered by the Cornell College Department of Mathematics and Statistics, go to the RStudio Server while on campus and connected to campus internet.\nYour account will be pre-created before the class begins and will use your Cornell College username. The default password will be shared in class and you will need to change it.",
    "crumbs": [
      "Course information",
      "R/RStudio Access"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\nüîó on Cornell College Cluster\n\n\nCourse GitHub organization\nüîó on GitHub\n\n\nGradebook\nüîó on Moodle",
    "crumbs": [
      "Course Contents",
      "Useful links"
    ]
  },
  {
    "objectID": "course-links.html#course-links",
    "href": "course-links.html#course-links",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\nüîó on Cornell College Cluster\n\n\nCourse GitHub organization\nüîó on GitHub\n\n\nGradebook\nüîó on Moodle",
    "crumbs": [
      "Course Contents",
      "Useful links"
    ]
  },
  {
    "objectID": "course-links.html#other-useful-links",
    "href": "course-links.html#other-useful-links",
    "title": "Useful links",
    "section": "Other Useful Links",
    "text": "Other Useful Links\n\nData Wrangling and Viz Interactive Tutorials\nRStudio Cheatsheets\nIntroduction to dplyr\nR Date Examples\nNY Times Cornell College Sign-up\nR for Data Science 2nd Ed\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Course Contents",
      "Useful links"
    ]
  },
  {
    "objectID": "course-links.html#data-links",
    "href": "course-links.html#data-links",
    "title": "Useful links",
    "section": "Data Links",
    "text": "Data Links\n\nTidyTuesday\nR Data Sources for Regression Analysis\nFiveThirtyEight data\nAmazon Registry of Open Data\nOpen data StackExchange\nData.gov\nUS Census\nNew York City data\nGeorge Mason University Data Link List\nToward Data Science list of Data Sources\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland‚Äôs official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nAndrew G. Reiter Poly Scie Datasets\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\nU.S. Data\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nState of Iowa Open Geospatial Data\nIf you know of others, let me know!",
    "crumbs": [
      "Course Contents",
      "Useful links"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nYou are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in person, so office hours are a valuable resource. I encourage every one of you to take advantage of this resource! Pledge to stop by during office hours at least once during the first few days of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of your professor‚Äôs office hours here.\n\nProfessor Email\nIf you are not available during office hours times or have a questions later in the evening or other times outside of class, email your professor at tgeorge@cornellcollege.edu. If your question involves code - it is very likely you will need to meet with him to get help. Please reach out with any concerns you have during the course!",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\n\nQuantitative Reasoning Studio (QRS)\nThere are times you may need help outside of class or office hours. Or, maybe you need something explained differently. In those instances, I encourage you to visit the Quantitative Reasoning Studio in Cole Library room 322. The Quantitative Reasoning Studio (QRS) offers free tutoring to all students at Cornell College. There will be at least 1 peer tutor who has taken this course and will be able to help you if you arrive at a time they are working. Feel free to email Jessica Johanningmeier at QRS@cornellcollege.edu to ask when the tutor for this class will be available. They often will have a schedule posted on the wall in the studio.\n\n\nQRS Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n3 p.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\n\n\n\nDungy Writing Studio\nFor help with your writing, visit the Dungy Writing Studio. You can make online appointments individually or in groups to get help with items such as your group project. If you have any questions about the studio, email Dungy Writing Studio Director and Director of Fellowships and Scholarships, Laura Farmer, at lfarmer@cornellcollege.edu.\n\n\nWriting Studio Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n1 p.m. - 5 p.m.\n\n\n\n\n\nAcademic Support Services\nThere are a variety of support services offered to all students. See more information at: https://www.cornellcollege.edu/academics/support-services/index.shtml&gt;",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#ebersole-health-and-wellbeing-center",
    "href": "course-support.html#ebersole-health-and-wellbeing-center",
    "title": "Course support",
    "section": "Ebersole Health and Wellbeing Center",
    "text": "Ebersole Health and Wellbeing Center\nThe mission of Cornell College Student Health Services complements the mission of the college by promoting the optimal well-being of students. We do this by:\n\nproviding and coordinating quality health care services\nadvocating for students in their pursuit of health and wellness\npreparing students to be their own health advocates and informed consumers of appropriate health care services\nproviding health education to promote the development of healthy lifestyles\n\nThe Student Health Center is located in the Ebersole Building, directly south of the Thomas Commons. Appointments are preferred. You can schedule an appointment online or by phone at 319-895-4292. Walk-ins will be accommodated as time permits. Appointments with the nurse are free.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#technology-support",
    "href": "course-support.html#technology-support",
    "title": "Course support",
    "section": "Technology Support",
    "text": "Technology Support\nIf you have issues with your computer during the block, IT may be able to help. Please submit a ticket.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "hw/02_hw_ch2.html",
    "href": "hw/02_hw_ch2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_2 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw2.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/02_hw_ch2.html#setup",
    "href": "hw/02_hw_ch2.html#setup",
    "title": "Homework 2",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_2 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw2.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/02_hw_ch2.html#instructions",
    "href": "hw/02_hw_ch2.html#instructions",
    "title": "Homework 2",
    "section": "Instructions",
    "text": "Instructions\nBe sure to include the relevant R code as well as full sentences answering each of the questions (i.e.¬†if I ask for the average, you can output the answer in R but also write a full sentence with the answer). Be sure to frequently save your files!\nData for the homework will be in the STA363_inst_files -&gt; data folder."
  },
  {
    "objectID": "hw/02_hw_ch2.html#exercises",
    "href": "hw/02_hw_ch2.html#exercises",
    "title": "Homework 2",
    "section": "Exercises",
    "text": "Exercises\nAll problems are from The main textbook is: Beyond Multiple Linear Regression by Paul Roback and Julie Legler ‚Äì it is freely available online. Chapters 1-9.. Abbreviated BMLR.\nUse the numbering on the left. The codes are for instructor use (Ex: C1).\n\nExercise 1\n\n(C1) Suppose we plan to use data to estimate one parameter, \\(p_B\\).\n\nWhen using a likelihood to obtain an estimate for the parameter, which is preferred: a large or a small likelihood value? Why?\nThe height of a likelihood curve is the probability of the data for the given parameter. The horizontal axis represents different possible parameter values. Does the area under the likelihood curve for an interval from .25 to .75 equal the probability that the true probability of a boy is between 0.25 and 0.75?\n\n\n\n\nExercise 2\n\n(C2) Suppose the families with an ‚Äúonly child‚Äù were excluded for the Sex Conditional Model. How might the estimates for the three parameters be affected? Would it still be possible to perform a Likelihood Ratio Test to compare the Sex Unconditional and Sex Conditional Models? Why or why not?\n\n\n\nExercise 3\n\n(G2) Case 3 In Case 1 we used hypothetical data with 30 boys and 20 girls. Case 2 was a much larger study with 600 boys and 400 girls. Consider Case 3, a hypothetical data set with 6000 boys and 4000 girls.\n\nUse the methods for Case 1 and Case 2 and determine the MLE for \\(p_B\\) for the case 3 independence model. Compare your result to the MLEs for Cases 1 and 2.\nDescribe how the graph of the log-likelihood for Case 3 would compare to the log-likelihood graphs for Cases 1 and 2.\nCompute the log-likelihood for Case 3. Why is it incorrect to perform an LRT comparing Cases 1, 2, and 3?\n\n\n\n\nExercise 4\n\n(G3) Write out an expression for the likelihood of seeing our NLSY data (5,416 boys and 5,256 girls) if the true probability of a boy is:\n\n\\(p_B=0.5\\)\n\n\\(p_B=0.45\\)\n\n\\(p_B= 0.55\\)\n\n\\(p_B= 0.5075\\)\n\n\n\nCompute the value of the log-likelihood for each of the values of \\(p_B\\) above.\nWhich of these four possibilities, \\(p_B=0.45, p_B=0.5,  p_B=0.55,\\) or \\(p_B=0.5075\\) would be the best estimate of \\(p_B\\) given what we observed (our data)?\n\n\n\n\nExercise 5\n\n(O2) The hot hand in basketball. @Gilovich1985 wrote a controversial but compelling article claiming that there is no such thing as ‚Äúthe hot hand‚Äù in basketball. That is, there is no empirical evidence that shooters have stretches where they are more likely to make consecutive shots, and basketball shots are essentially independent events. One of the many ways they tested for evidence of a ‚Äúhot hand‚Äù was to record sequences of shots for players under game conditions and determine if players are more likely to make shots after made baskets than after misses. For instance, assume we recorded data from one player‚Äôs first 5 three-point attempts over a 5-game period. We can assume games are independent, but we‚Äôll consider two models for shots within a game:\n\nNo Hot Hand (1 parameter): \\(p_B\\) = probability of making a basket (thus \\(1-p_B\\) = probability of not making a basket).\nHot Hand (2 parameters): \\(p_B\\) = probability of making a basket after a miss (or the first shot of a game); \\(p_{B|B}\\) = probability of making a basket after making the previous shot.\n\n\nFill out Table @ref(tab:hothandchp2)‚Äîwrite out the contribution of each game to the likelihood for both models along with the total likelihood for each model.\nGiven that, for the No Hot Hand model, \\(\\textrm{Lik}(p_B)=p_B^{10}(1-p_B)^{15}\\) for the 5 games where we collected data, how do we know that 0.40 (the maximum likelihood estimator (MLE) of \\(p_B\\)) is a better estimate than, say, 0.30?\nFind the MLEs for the parameters in each model, and then use those MLEs to determine if there‚Äôs significant evidence that the hot hand exists.\n\n\n\n\n\n\nData for Open-ended Exercise 2. (B = made basket. M = missed basket.)\n\n\nGame\nFirst 5 shots\nLikelihood (No Hot Hand)\nLikelihood (Hot Hand)\n\n\n\n\n1\nBMMBB\n\n\n\n\n2\nMBMBM\n\n\n\n\n3\nMMBBB\n\n\n\n\n4\nBMMMB\n\n\n\n\n5\nMMMMM\n\n\n\n\nTotal"
  },
  {
    "objectID": "hw/04_hw_ch4.html",
    "href": "hw/04_hw_ch4.html",
    "title": "Homework 4",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_4 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw4.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/04_hw_ch4.html#setup",
    "href": "hw/04_hw_ch4.html#setup",
    "title": "Homework 4",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_4 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw4.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/04_hw_ch4.html#instructions",
    "href": "hw/04_hw_ch4.html#instructions",
    "title": "Homework 4",
    "section": "Instructions",
    "text": "Instructions\nBe sure to include the relevant R code as well as full sentences answering each of the questions (i.e.¬†if I ask for the average, you can output the answer in R but also write a full sentence with the answer). Be sure to frequently save your files!\nData for the homework will be in the STA363_inst_files -&gt; data folder."
  },
  {
    "objectID": "hw/04_hw_ch4.html#exercises",
    "href": "hw/04_hw_ch4.html#exercises",
    "title": "Homework 4",
    "section": "Exercises",
    "text": "Exercises\nAll problems are from The main textbook is: Beyond Multiple Linear Regression by Paul Roback and Julie Legler ‚Äì it is freely available online. Chapters 1-9. Abbreviated BMLR.\nUse the numbering on the left. The codes are for instructor use (Ex: C1).\n\nExercise 1 & 2\nExercises 1 & 2 involve predicting a response using one or more explanatory variables, where these examples have response variables that are counts per some unit of time or space. List the response (both what is being counted and over what unit of time or space) and relevant explanatory variables.\n\n\nExercise 1\n\n(C1) Are the number of motorcycle deaths in a given year related to a state‚Äôs helmet laws?\n\n\n\nExercise 2\n\n(C2) Does the number of employers conducting on-campus interviews during a year differ for public and private colleges?\n\n\n\nExercise 3\n\n(C5) Models of the form \\(Y_i=\\beta_0+\\beta_1X_i+\\epsilon_i, \\epsilon_i \\sim iidN(0,\\sigma)\\) are fit using the method of least squares. What method is used to fit Poisson regression models?\n\n\n\nExercise 4\n\n(C6) What should be done before adjusting for overdispersion?\n\n\n\nExercise 5\n\n(C7) Why are quasi-Poisson models used, and how do the results typically compare for corresponding models using regular Poisson regression?\n\n\n\nExercise 6\n\n(C8) Why is the log of mean counts, log(\\(\\bar{Y}\\)), not \\(\\bar{Y}\\), plotted against X when assessing the assumptions for Poisson regression?\n\n\n\nExercise 7\n\n(C9) How can the assumption of mean=variance be checked for Poisson regression? What if there are not many repeated observations at each level of X?\n\n\n\nExercise 8\n\n(C10) Is it possible that a predictor is significant for a model fit using Poisson regression, but not for a model for the same data fit using quasi-Poisson regression? Explain.\n\n\n\nExercise 9\n\n(C11) Fish (or, as they say in French, poisson). A state wildlife biologist collected data from 250 park visitors as they left at the end of their stay. Each was asked to report the number of fish they caught during their one-week stay. On average, visitors caught 21.5 fish per week.\n\n\nDefine the response.\nWhat are the possible values for the response?\nWhat does \\(\\lambda\\) represent?\n\n\n\nExercise 10\n\n(G2) Elephant mating. How does age affect male elephant mating patterns? An article by @Poole1989 investigated whether mating success in male elephants increases with age and whether there is a peak age for mating success. To address this question, the research team followed 41 elephants for one year and recorded both their ages and their number of matings. The data [@Ramsey2002] is found in elephant.csv, and the variables are:\n\nMATINGS = the number of matings in a given year\nAGE = the age of the elephant in years.\n\n\nCreate a histogram of MATINGS. Is there preliminary evidence that number of matings could be modeled as a Poisson response? Explain.\nPlot MATINGS by AGE. Add a least squares line. Is there evidence that modeling matings using a linear regression with age might not be appropriate? Explain. (Hints: fit a smoother; check residual plots).\nFor each age, calculate the mean number of matings. Take the log of each mean and plot it by AGE.\n\nWhat assumption can be assessed with this plot?\nIs there evidence of a quadratic trend on this plot?\n\nFit a Poisson regression model with a linear term for AGE. Exponentiate and then interpret the coefficient for AGE.\nConstruct a 95% confidence interval for the slope and interpret in context (you may want to exponentiate endpoints).\nAre the number of matings significantly related to age? Test with\n\na Wald test and\na drop in deviance test.\n\nAdd a quadratic term in AGE to determine whether there is a maximum age for the number of matings for elephants. Is a quadratic model preferred to a linear model? To investigate this question, use\n\na Wald test and\na drop in deviance test.\n\nWhat can we say about the goodness-of-fit of the model with age as the sole predictor? Compare the residual deviance for the linear model to a \\(\\chi^2\\) distribution with the residual model degrees of freedom.\nFit the linear model using quasi-Poisson regression. (Why?)\n\nHow do the estimated coefficients change?\nHow do the standard errors change?\nWhat is the estimated dispersion parameter?\nAn estimated dispersion parameter greater than 1 suggests overdispersion. When adjusting for overdispersion, are you more or less likely to obtain a significant result when testing coefficients? Why?"
  },
  {
    "objectID": "hw/06_hw_ch6_7.html",
    "href": "hw/06_hw_ch6_7.html",
    "title": "Homework 6",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_6 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw6.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/06_hw_ch6_7.html#setup",
    "href": "hw/06_hw_ch6_7.html#setup",
    "title": "Homework 6",
    "section": "",
    "text": "Each of your assignments will begin with the following steps.\n\nGoing to our RStudio Server at http://turing.cornellcollege.edu:8787/\nCreating a new R project, inside your homework folder on the server, and giving it a sensible name such as homework_6 and having that project in the course folder you created.\nCreate a new quarto document and give it a sensible name such as hw6.\nIn the YAML add the following (add what you don‚Äôt have). The embed-resources component will make your final rendered html self-contained.\n\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\nembed-resources: true\n---"
  },
  {
    "objectID": "hw/06_hw_ch6_7.html#instructions",
    "href": "hw/06_hw_ch6_7.html#instructions",
    "title": "Homework 6",
    "section": "Instructions",
    "text": "Instructions\nBe sure to include the relevant R code as well as full sentences answering each of the questions (i.e.¬†if I ask for the average, you can output the answer in R but also write a full sentence with the answer). Be sure to frequently save your files!\nData for the homework will be in the STA363_inst_files -&gt; data folder."
  },
  {
    "objectID": "hw/06_hw_ch6_7.html#exercises",
    "href": "hw/06_hw_ch6_7.html#exercises",
    "title": "Homework 6",
    "section": "Exercises",
    "text": "Exercises\nAll problems are from The main textbook is: Beyond Multiple Linear Regression by Paul Roback and Julie Legler ‚Äì it is freely available online. Chapters 1-9. Abbreviated BMLR.\nUse the numbering on the left. The codes are for instructor use (Ex: C1)."
  },
  {
    "objectID": "hw/06_hw_ch6_7.html#part-1-logistic-regression",
    "href": "hw/06_hw_ch6_7.html#part-1-logistic-regression",
    "title": "Homework 6",
    "section": "Part 1: Logistic Regression",
    "text": "Part 1: Logistic Regression\n\nExercise 1\n\n(C2) Interpret the odds ratios in the following abstract.\nDaycare Centers and Respiratory Health [@Nafstad1999]\n\nObjective. To estimate the effects of the type of daycare on respiratory health in preschool children.\nMethods. A population-based, cross-sectional study of Oslo children born in 1992 was conducted at the end of 1996. A self-administered questionnaire inquired about daycare arrangements, environmental conditions, and family characteristics (n = 3853; response rate, 79%).\nResults. In a logistic regression controlling for confounding, children in daycare centers had more often nightly cough (adjusted odds ratio, 1.89; 95% confidence interval 1.34-2.67), and blocked or runny nose without common cold (1.55; 1.07-1.61) during the past 12 months compared with children in home care.\n\n\n\n\nExercise 2\n\n(C3) Construct a table and calculate the corresponding odds and odds ratios. Comment on the reported and calculated results in this New York Times article from @Kolata2009.\n\nIn November, the Centers for Disease Control and Prevention published a paper reporting that babies conceived with IVF, or with a technique in which sperm are injected directly into eggs, have a slightly increased risk of several birth defects, including a hole between the two chambers of the heart, a cleft lip or palate, an improperly developed esophagus and a malformed rectum. The study involved 9,584 babies with birth defects and 4,792 babies without. Among the mothers of babies without birth defects, 1.1% had used IVF or related methods, compared with 2.4% of mothers of babies with birth defects.\nThe findings are considered preliminary, and researchers say they believe IVF does not carry excessive risks. There is a 3% chance that any given baby will have a birth defect.\n\n\n\n\nExercise 3\n\n(G4) Birdkeeping and lung cancer: a retrospective observational study. A 1972-1981 health survey in The Hague, Netherlands, discovered an association between keeping pet birds and increased risk of lung cancer. To investigate birdkeeping as a risk factor, researchers conducted a case-control study of patients in 1985 at four hospitals in The Hague. They identified 49 cases of lung cancer among patients who were registered with a general practice, who were age 65 or younger, and who had resided in the city since 1965. Each patient (case) with cancer was matched with two control subjects (without cancer) by age and sex. Further details can be found in @Holst1988.\nAge, sex, and smoking history are all known to be associated with lung cancer incidence. Thus, researchers wished to determine after age, sex, socioeconomic status, and smoking have been controlled for, is an additional risk associated with birdkeeping? The data [@Ramsey2002] is found in birdkeeping.csv, and the variables are listed below. In addition, R code at the end of the problem can be used to input the data and create additional useful variables.\n\nfemale = sex (1 = Female, 0 = Male)\nage = age, in years\nhighstatus = socioeconomic status (1 = High, 0 = Low), determined by the occupation of the household‚Äôs primary wage earner\nyrsmoke = years of smoking prior to diagnosis or examination\ncigsday = average rate of smoking, in cigarettes per day\nbird = indicator of birdkeeping (1 = Yes, 0 = No), determined by whether or not there were caged birds in the home for more than 6 consecutive months from 5 to 14 years before diagnosis (cases) or examination (controls)\ncancer = indicator of lung cancer diagnosis (1 = Cancer, 0 = No Cancer)\n\n\nPerform an exploratory data analysis to see how each explanatory variable is related to the response (cancer). Summarize each relationship in one sentence.\n\nFor quantitative explanatory variables (age, yrsmoke, cigsday), produce a cdplot, a boxplot, and summary statistics by cancer diagnosis.\nFor categorical explanatory variables (female or sex, highstatus or socioecon_status, bird or keep_bird), produce a segmented bar chart and an appropriate table of proportions showing the relationship with cancer diagnosis.\n\nIn (a), you should have found no relationship between whether or not a patient develops lung cancer and either their age or sex. Why might this be? What implications will this have on your modeling?\nBased on a two-way table with keeping birds and developing lung cancer from (a), find an unadjusted odds ratio comparing birdkeepers to non-birdkeepers and interpret this odds ratio in context. (Note: an unadjusted odds ratio is found by not controlling for any other variables.) Also, find an analogous relative risk and interpret it in context as well.\nAre the elogits reasonably linear relating number of years smoked to the estimated log odds of developing lung cancer? Demonstrate with an appropriate plot.\nDoes there appear to be an interaction between number of years smoked and whether the subject keeps a bird? Demonstrate with an interaction plot and a coded scatterplot with empirical logits on the y-axis.\n\n\n\nBefore answering the next questions, fit logistic regression models in R with cancer as the response and the following sets of explanatory variables:\n  i. `model1` = `age`, `yrsmoke`, `cigsday`, `female`, `highstatus`, `bird`\n  ii. `model2` = `yrsmoke`, `cigsday`, `highstatus`, `bird` \n  iii. `model4` = `yrsmoke`, `bird`\n  iv. `model5` = the complete second order version of `model4` (add squared terms and an interaction)\n  v. `model6` = `yrsmoke`, `bird`, `yrsmoke:bird`\n\nf. Is there evidence that we can remove `age` and `female` from our model?  Perform an appropriate test comparing `model1` to `model2`; give a test statistic and p-value, and state a conclusion in context.\n\ng. Is there evidence that the complete second order version of `model4` improves its performance?  Perform an appropriate test comparing `model4` to `model5`; give a test statistic and p-value, and state a conclusion in context.\n\nh. Carefully interpret each of the four model coefficients in `model6` in context.\n\ni. If you replaced `yrsmoke` everywhere it appears in `model6` with a mean-centered version of `yrsmoke`, tell what would change among these elements: the 4 coefficients, the 4 p-values for coefficients, and the residual deviance.\n\nj. `model4` is a potential final model based on this set of explanatory variables.  Find and carefully interpret 95% confidence intervals based on profile likelihoods for the coefficients of `yrsmoke` and `bird`. \n\nk. How does the adjusted odds ratio for birdkeeping from `model4` compare with the unadjusted odds ratio you found in (c)?  Is birdkeeping associated with a significant increase in the odds of developing lung cancer, even after adjusting for other factors?\n\nl. Use the categorical variable `years_factor` based on `yrsmoke` and replace `yrsmoke` in `model4` with your new variable to create `model4a`.  First, interpret the coefficient for `years_factorOver 25 years` in context.  Then tell if you prefer `model4` with years smoked as a numeric predictor or `model4a` with years smoked as a categorical predictor, and explain your reasoning.\n\nm. Discuss the scope of inference in this study.  Can we generalize our findings beyond the subjects in this study?  Can we conclude that birdkeeping causes increased odds of developing lung cancer?  Do you have other concerns with this study design or the analysis you carried out?\n\nn. Read the article that appeared in the *British Medical Journal*.  What similarities and differences do you see between their analyses and yours?  What are a couple of things you learned from the article that weren‚Äôt apparent in the short summary at the beginning of the assignment.\n\nbirds &lt;- read_csv(\"data/birdkeeping.csv\") %&gt;%\n  mutate(sex = ifelse(female == 1, \"Female\", \"Male\"),\n         socioecon_status = ifelse(highstatus == 1, \n                                   \"High\", \"Low\"),\n         keep_bird = ifelse(bird == 1, \"Keep Bird\", \"No Bird\"),\n         lung_cancer = ifelse(cancer == 1, \"Cancer\", \n                              \"No Cancer\")) %&gt;%\n  mutate(years_factor = cut(yrsmoke, \n                            breaks = c(-Inf, 0, 25, Inf),\n            labels = c(\"No smoking\", \"1-25 years\", \n                       \"Over 25 years\")))"
  },
  {
    "objectID": "hw/06_hw_ch6_7.html#part-2-correlated-data",
    "href": "hw/06_hw_ch6_7.html#part-2-correlated-data",
    "title": "Homework 6",
    "section": "Part 2: Correlated Data",
    "text": "Part 2: Correlated Data\n\nExercise 4\n\n(C1) Examples with correlated data. For each of the following studies:\n\nIdentify the most basic observational units\nIdentify the grouping units (could be multiple levels of grouping)\nState the response(s) measured and variable type (normal, binary, Poisson, etc.)\nWrite a sentence describing the within-group correlation.\nIdentify fixed and random effects\n\n\n\nEpilepsy study. Researchers conducted a randomized controlled study where patients were randomly assigned to either an anti-epileptic drug or a placebo. For each patient, the number of seizures at baseline was measured over a 2-week period. For four consecutive visits the number of seizures were determined over the past 2-week period. Patient age and sex along with visit number were recorded.\nPrairie restoration. Researchers at a small Midwestern college decided to experimentally explore the underlying causes of variation in soil reconstruction projects in order to make future projects more effective. Introductory ecology classes were organized to collect weekly data on plants in pots containing soil samples. Data will be examined to compare:\n\ngermination and growth of two species of prairie plants‚Äî‚Äìleadplants (Amorpha canescens) and coneflowers (Ratibida pinnata).\nsoil from a cultivated (agricultural) field, a natural prairie, and a restored (reconstructed) prairie.\nthe effect of sterilization, since half of the sampled soil was sterilized to determine if rhizosphere differences were responsible for the observed variation.\n\nRadon in Minnesota. Radon is a carcinogen ‚Äì a naturally occurring radioactive gas whose decay products are also radioactive ‚Äì known to cause lung cancer in high concentrations. The EPA sampled more than 80,000 homes across the U.S. Each house came from a randomly selected county and measurements were made on each level of each home. Uranium measurements at the county level were included to improve the radon estimates."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html",
    "href": "labs/01_linear_regression/01_banksalary.html",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "",
    "text": "Since this our first lab, I suggest you get setup for files in the following way:\n\nLog into the course RStudio Server. http://turing.cornellcollege.edu:8787/ Make sure to close out of any projects on the top right corner.\nClick the ‚ÄúFile‚Äù tab in the bottom right corner. Then click ‚ÄúHome‚Äù across the top of the panel.\nIf ones does not exists already, use the ‚Äú+üìÇ‚Äù button to create a new folder and call it ‚ÄúSTA363‚Äù\nCopy project folder called ‚Äú01_linear_regression‚Äù located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file 01_banksalary_fillable.qmd."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html#first-lab-setup",
    "href": "labs/01_linear_regression/01_banksalary.html#first-lab-setup",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "",
    "text": "Since this our first lab, I suggest you get setup for files in the following way:\n\nLog into the course RStudio Server. http://turing.cornellcollege.edu:8787/ Make sure to close out of any projects on the top right corner.\nClick the ‚ÄúFile‚Äù tab in the bottom right corner. Then click ‚ÄúHome‚Äù across the top of the panel.\nIf ones does not exists already, use the ‚Äú+üìÇ‚Äù button to create a new folder and call it ‚ÄúSTA363‚Äù\nCopy project folder called ‚Äú01_linear_regression‚Äù located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file 01_banksalary_fillable.qmd."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html#introduction",
    "href": "labs/01_linear_regression/01_banksalary.html#introduction",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "Introduction",
    "text": "Introduction\nExample: Sex discrimination in bank salaries. In the 1970‚Äôs, Harris Trust was sued for sex discrimination in the salaries it paid its employees. One approach to addressing this issue was to examine the starting salaries of all skilled, entry-level clerical workers between 1965 and 1975. The data is saved under banksalary.csv, and relevant R code can be found in the STA363_inst_files folder on the home directory of the RStudio Server. banksalary.qmd.\nData from skilled entry-level clerical workers at bank being sued for sex discrimination in 1970s (from Statistical Sleuth, Ch 12):\n\nbsal = beginning salary (annual salary at time of hire)\nsal77 = annual salary in 1977\nsex = MALE or FEMALE\nsenior = months since hired\nage = age in months\neduc = years of education\nexper = months of prior work experience\n\nFirst, we will speculate on what we expect to find and then we will perform an analysis using the data.\n\nRead the data in and use aview() to see the data, but do not do anything else with the data on the computer until question 6."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html#questions",
    "href": "labs/01_linear_regression/01_banksalary.html#questions",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "Questions",
    "text": "Questions\n\nIdentify the observational units, the response variable, and explanatory variables.\nGiven the mean starting salary of male workers ($5957) was 16% higher than the mean starting salary of female workers ($5139): Is this enough evidence to conclude sex discrimination exists? If not, what further evidence would you need?\nHow would you expect age, experience, and education to each be related to starting salary?\nWhy might it be important to control for seniority (number of years with the bank) if we are only concerned with the salary when the worker started?\nDo you expect any explanatory variables (including sex) to be closely related to each other? What implications would this have for modeling?\n\nUsing the data‚Ä¶\nOne approach is to construct a good model for beginning salaries while requiring sex as a predictor, to determine the significance of sex after controlling for the other covariates. Then we can explore interactions with sex to see if its effect is consistent across levels of other predictors.\n\nUse the data to address the primary question of interest here using only the beginning salary and sex variables. Be sure to discuss plots and summary statistics first, and then look at test(s) of significance.\nConstruct plots to investigate how each of the potential confounders (age, experience, education) is related to beginning salaries. Describe your findings.\nDoes seniority play a role in the variation of starting salaries? In what way?\nExamine how the explanatory variables (including sex) are related to each other, if at all. What implications would this have for modeling?\nFit a simple linear regression model with starting salary as the response and education as the sole explanatory variable. Interpret the intercept and slope of this model; also interpret the R-squared value. Is there a significant relationship between education and starting salary?\n\nIntercept:\nSlope:\nR2\nSignificance:\n\nDoes model1 from question 10 meet all linear regression assumptions? List each assumption and how you decided if it was met or not.\nIs a model with all 4 confounding variables better than a model with just education? Justify with an appropriate significance test in addition to summary statistics of model performance.\nYou should have noticed that the term for age was not significant in the model3. What does this imply about age and about future modeling steps?\nThe relationship between experience and beginning salary exhibits some curvature. How might it be interpreted in this context? Determine whether a quadratic term in experience improves a model without curvature.\nBased on model6, what conclusions can be drawn about sex discrimination at Harris Trust? Do these conclusions have to be qualified at all, or are they pretty clear cut? Interpret a 95% confidence interval for the male indicator variable in context to help with your response.\nDo any explanatory variables exhibit an interaction with sex. If so, what are the implications for your answer in (15)?\nOften salary data is logged before analysis. Would you recommend logging starting salary in this study? Support your decision analytically.\nRegardless of your answer to (17), provide an interpretation for the coefficient for the male coefficient in model6a after logging starting salary."
  },
  {
    "objectID": "labs/01_linear_regression/01_banksalary.html#code",
    "href": "labs/01_linear_regression/01_banksalary.html#code",
    "title": "Stat 363: Multiple Linear Regression Review",
    "section": "Code",
    "text": "Code\n\nlibrary(mosaic)\nlibrary(skimr)   # may have to install\nlibrary(dplyr)  \nlibrary(ggplot2)\nlibrary(gridExtra)\nbank &lt;- read.csv(\"data/banksalary.csv\")\n\nData from skilled entry-level clerical workers at bank being sued for sex discrimination in 1970s (from Statistical Sleuth, Ch 12):\n\nbsal = beginning salary (annual salary at time of hire)\nsal77 = annual salary in 1977\nsex = MALE or FEMALE\nsenior = months since hired\nage = age in months\neduc = years of education\nexper = months of prior work experience\n\n\n# Examine data frame\nhead(bank)       # print first 6 rows\n\n# Generate relevant summary statistics for response variable\nfavstats(~ bsal, data = bank)\n\n# Look at marginal relationship between sex and beginning salary\n\n# Three options for getting summary statistics\nfavstats(~ bsal | sex, data = bank)\n\nbank |&gt;\n  group_by(sex) |&gt;\n  summarize(mean = mean(bsal),\n            median = median(bsal),\n            sd = sd(bsal),\n            iqr = IQR(bsal),\n            n = n())\n\n# Doesn't seem to render as a pdf\n#bank |&gt;\n#  group_by(sex) |&gt;\n#  skim()\n\n# Several options for plotting 1 categorical and 1 numeric variable\nboxplot(bsal ~ sex, ylab=\"Beginning salary\", data = bank)\nbwplot(sex ~ bsal, data = bank)\nggplot(bank, aes(x = sex, y = bsal)) +\n  geom_boxplot() + coord_flip()\nggplot(data = bank, mapping = aes(x = bsal, y = ..density..)) + \n  geom_freqpoly(mapping = aes(colour = sex), binwidth = 250)\nggplot(data = bank, mapping = aes(x = bsal, y = ..density..)) + \n  geom_density(mapping = aes(colour = sex))\nggplot(bank, aes(x=bsal, fill=sex)) +\n  geom_density(alpha=0.4)\nggplot(bank, aes(x = sex, y = bsal)) +\n  geom_violin() \nggplot(data = bank) + \n  geom_histogram(mapping = aes(x = bsal)) + \n  facet_wrap(~ sex, nrow = 2)\nggplot(data = bank) + \n  geom_histogram(mapping = aes(x = bsal, y = ..density..)) + \n  facet_wrap(~ sex, nrow = 2)\n\n# Initial analysis of sex vs salary, ignoring other covariates\nt.test(bsal ~ sex, data = bank)\n\nmodel1 = lm(bsal ~ sex, data = bank)\nsummary(model1)\n\nbank &lt;- bank |&gt;\n  mutate(male = ifelse(sex==\"MALE\",1,0))   # create our own indicator for sex\nt.test(bsal ~ male, var.equal = TRUE, data = bank)\n\n# How are covariates related to response?\nggplot(bank, aes(y = bsal, age)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, exper)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, educ)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, senior)) + \n  geom_point() + \n  geom_smooth(method = lm)\n\n# How are explanatory variables related to each other?\nbank0 &lt;- bank |&gt; select(bsal, age, exper, educ, senior, male)\npairs(bank0)     # matrix of scatterplots \ncor(bank0)       # matrix of correlations\n\n# How are explanatory variables related to sex?\nfavstats(~ age | sex, data = bank)\nggplot(bank, aes(x = sex, y = age)) +\n  geom_boxplot() + coord_flip()\n\nfavstats(~ exper | sex, data = bank)\nggplot(bank, aes(x = sex, y = exper)) +\n  geom_boxplot() + coord_flip()\n\nfavstats(~ educ | sex, data = bank)\nggplot(bank, aes(x = sex, y = educ)) +\n  geom_boxplot() + coord_flip()\n\nfavstats(~ senior | sex, data = bank)\nggplot(bank, aes(x = sex, y = senior)) +\n  geom_boxplot() + coord_flip()\n\n# Fit linear regression with single predictor (education)\nmodel2 = lm(bsal ~ educ, data = bank)\nsummary(model2)\n\n\n# Residual plots - run off the page unless redo margins\npar(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(0.5,0.5,0.5,0))\nplot(model2)   # Generate residual diagnostic plots\npar(mfrow=c(1,1))\n\n\n# Fit multiple regression model with four predictors\nmodel3 = lm(bsal ~ senior + age + educ + exper, data = bank)\nsummary(model3)\nanova(model2, model3, test=\"F\")\n\n# Examine AIC and BIC scores (lower is better)\nAIC(model2)                     # AIC-model2\nAIC(model3)                     # AIC-model3\nAIC(model2, k=log(nrow(bank)))  # BIC-model2\nAIC(model3, k=log(nrow(bank)))  # BIC-model3\n\n# Fit linear regression with experience\nmodel4 = lm(bsal ~ exper, data = bank)\nsummary(model4)\n\n\n# Residual plots - run off the page unless redo margins\npar(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(0.5,0.5,0.5,0))\nplot(model4)   # Generate residual diagnostic plots\npar(mfrow=c(1,1))\n\n\nbank &lt;- bank |&gt;\n  mutate(exper2 = exper^2)\nmodel5 = lm(bsal ~ exper + exper2, data = bank)\nsummary(model5)\n\n\n# Residual plots - run off the page unless redo margins\npar(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(0.5,0.5,0.5,0))\nplot(model5)   # Generate residual diagnostic plots\npar(mfrow=c(1,1))\n\n\n# One potential final model\nmodel6 = lm(bsal ~ senior + educ + exper + male, data = bank)\nsummary(model6)\n\n# Construct 95% CIs for model coefficients the hard way...\nbetas = summary(model6)$coef[,1]   # store model betas\nSEs = summary(model6)$coef[,2]    # store SEs of betas\ntstar = qt(.975,model6$df)\nlb = betas - tstar*SEs\nub = betas + tstar*SEs\ncbind(lb,ub)\n\n# ... or more simply:\nconfint(model6)\n\n# Investigate interactions with sex\nggplot(bank, aes(y = bsal, x = age, color = sex)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, x = exper, color = sex)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, x = educ, color = sex)) + \n  geom_point() + \n  geom_smooth(method = lm)\nggplot(bank, aes(y = bsal, x = senior, color = sex)) + \n  geom_point() + \n  geom_smooth(method = lm)\n\n# Examine interaction between sex and education\nmodel7 = lm(bsal ~ educ + male + educ:male, data = bank)\nsummary(model7)\n\n\n# Should beginning salary be log transformed?\nbank &lt;- bank |&gt; \n  mutate(logbsal = log(bsal))\nhist1 &lt;- ggplot(bank, aes(bsal)) + geom_histogram(bins = 10)\nhist2 &lt;- ggplot(bank, aes(logbsal)) + geom_histogram(bins = 10)\ngrid.arrange(hist1, hist2, ncol=2)\n\n# Look at marginal relationship between sex and beginning salary\nmodel6a = lm(logbsal ~ senior + educ + exper + male, data = bank)\nsummary(model6a)\n\n\n# Residual plots - run off the page unless redo margins\npar(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(0.5,0.5,0.5,0))\nplot(model6a)   # Generate residual diagnostic plots\npar(mfrow=c(1,1))\n\n\n# Bonus code: to help with HW1 when looking at 2 categorical variables\nytable &lt;- tally(~ sex + educ, data = bank)\nytable\nmosaicplot(ytable, color = c(\"blue\", \"light blue\"))\nprop.table(ytable, 1)\n\n# Other ways to visualize two categorical variables\nbank &lt;- bank |&gt;\n  mutate(education = ifelse(educ &lt; 12, \"No high school\", \"High school\"),\n         education = ifelse(educ &gt; 12, \"Some college\", education))\nggplot(data = bank) + \n  geom_bar(mapping = aes(x = sex, fill = education)) \nggplot(data = bank) + \n  geom_bar(mapping = aes(x = sex, fill = education), position = \"fill\") \nlibrary(ggmosaic)  # need to have ggmosaic package installed\nggplot(data = bank) +\n   geom_mosaic(aes(x = product(education, sex), fill=education), na.rm = TRUE)\n\n# Other ways to summarize relationship between two categorical variables\nbank |&gt;\n  group_by(sex, education) |&gt;\n  summarise (n = n()) |&gt;\n  mutate(freq = n / sum(n))"
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html",
    "href": "labs/02_likelihood/02_likelihood.html",
    "title": "Chapter 2 - Likelihoods",
    "section": "",
    "text": "Copy the project lab folder located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file qmd file included."
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html#lab-setup",
    "href": "labs/02_likelihood/02_likelihood.html#lab-setup",
    "title": "Chapter 2 - Likelihoods",
    "section": "",
    "text": "Copy the project lab folder located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file qmd file included."
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html#introduction",
    "href": "labs/02_likelihood/02_likelihood.html#introduction",
    "title": "Chapter 2 - Likelihoods",
    "section": "Introduction",
    "text": "Introduction\nDoes having boys or girls run in the family? Using demographic data from the National Longitudinal Survey of Youth, can we identify biases in sex composition patterns of children? The data is found in Table 2 in the Rodgers and Doughty (2001) article, and relevant R code can be found under below."
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html#questions",
    "href": "labs/02_likelihood/02_likelihood.html#questions",
    "title": "Chapter 2 - Likelihoods",
    "section": "Questions",
    "text": "Questions\n\nModel 1 ‚Äì Sex Unconditional Model. Each child is independent of the others, and there is a constant probability ( ) that a child is a boy.\n\nConsider a small example with 3 families with compositions of children given by BBG, GBG, and GG.\nFind the maximum likelihood estimator (MLE) for by:\n\n\nConducting a numerical search in R for the largest likelihood over a fine grid of values 0-1.\nConducting a numerical search in R for the largest log-likelihood between 0 and 1. Illustrate the process graphically, and report the maximum value of the likelihood and log-likelihood functions. Does it make sense that both methods would agree (and agree with the mathematical approach)?\n\n\nApply Model 1 to the NLSY data (families in Table 2.4 below who have 3 or fewer children). Find the MLE for by adapting the R code for (1). There are 5,626 families in the table.\n\n\n#Family comp data table\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\ntable5chp2 &lt;- data.frame(Famcomp, Numfams, Numchild)\n\ntable5chp2 |&gt; kbl(col.names = c(\"Family Composition\",\n    \"Number of families\", \"Number of children\"),\n      caption = \"Table 2.4 Number of families and children in families with given composition in NLSY data.\") \n\n\n\nTable 2.4 Number of families and children in families with given composition in NLSY data.\n\n\nFamily Composition\nNumber of families\nNumber of children\n\n\n\n\nB\n930\n930\n\n\nG\n951\n951\n\n\nBB\n582\n1164\n\n\nBG\n666\n1332\n\n\nGB\n666\n1332\n\n\nGG\n530\n1060\n\n\nBBB\n186\n558\n\n\nBBG\n177\n531\n\n\nBGG\n173\n519\n\n\nBGB\n148\n444\n\n\nGBB\n151\n453\n\n\nGGB\n125\n375\n\n\nGBG\n182\n546\n\n\nGGG\n159\n477\n\n\n\n\n\n\n\n\n\n\nModel 2 ‚Äì Sex Conditional Model. The probability of having a boy depends on whether you‚Äôve had boys previously, so Model 2 will have three parameters:\n= probability of a boy when previously have had an equal number of boys and girls (neutral)\n= probability of a boy when previously have had more boys than girls (boy bias)\n= probability of a boy when previously have had more girls than boys (girl bias)\n\nWrite out the likelihood function given Model 2 for the small set of data in (1). [You could also try BGG, GGB, BBB just for fun.]"
  },
  {
    "objectID": "labs/02_likelihood/02_likelihood.html#code",
    "href": "labs/02_likelihood/02_likelihood.html#code",
    "title": "Chapter 2 - Likelihoods",
    "section": "Code",
    "text": "Code\n\nModel 1: Sex Unconditional Model\nAssumes the sex for each birth is independent of other births\n\n# Evaluate small set of possible values of pb\npb &lt;- c(.3, .35, .375, .4, .45)  # possible values for prob a boy is born\nlik &lt;- pb^3 * (1 - pb)^5         # likelihood of getting observed data\ncbind(pb, lik)                   # print table of results\nplot(pb, lik, xlab = \"possible values of pb\", ylab = \"Likelihood\")\nmax(lik)                         # maximum likelihood over 5 values of pb\npb[lik == max(lik)]              # value of pb where likelihood maximized\n\n# Evaluate finer grid of possible values of pb\npb &lt;- seq(0, 1, length = 1001)   # possible values for prob a boy is born\nlik &lt;- pb^3 * (1 - pb)^5         # likelihood of getting observed data\nplot(pb, lik, xlab = \"possible values of pb\", ylab = \"Likelihood\", type = \"l\")\nmax(lik)                         # maximum likelihood over 1001 values of pb\npb[lik == max(lik)]              # value of pb where likelihood maximized\n\nloglik &lt;- 3 * log(pb) + 5 * log(1 - pb)      # find log likelihoods\nplot(pb, loglik, xlab = \"possible values of pb\", ylab = \"Loglikelihood\", \n     type = \"l\")\nmax(loglik)                    # maximum loglikelihood over 1001 values of pb\npb[loglik == max(loglik)]      # likelihood and loglikelihood max at same spot\nmle_pb_m1_small &lt;- pb[loglik == max(loglik)]\nmax_logL_m1_small &lt;- max(loglik)\n\n# Create ggplot of likelihood and log-likelihood functions\nmodel1grid &lt;- data.frame(pb = pb, lik1 = lik, loglik1 = loglik)\nggplot(data = model1grid, aes(x = pb, y = lik1)) +\n  geom_line() +\n  labs(x = \"possible values of pb\", y = \"Likelihood\")\nggplot(data = model1grid, aes(x = pb, y = loglik1)) +\n  geom_line() +\n  labs(x = \"possible values of pb\", y = \"log Likelihood\")\n\n\n# Apply Model 1 to NLSY data (for families with 3 or fewer children)\npb &lt;- seq(0, 1, length = 10001)   # possible values for prob a boy is born\nlik &lt;- pb^5416 * (1 - pb)^5256    # likelihood (too small)\nmax(lik)\nsummary(lik)  \n\n# loglikelihood of getting observed data\nloglik &lt;- 5416 * log(pb) + 5256 * log(1 - pb)   \nplot(pb, loglik, xlab = \"possible values of pb\", ylab = \"Loglikelihood\", \n     type = \"l\")\nplot(pb[loglik &gt; (-7500)], loglik[loglik &gt; (-7500)],\n  xlab = \"possible values of pb\", \n  ylab = \"Loglikelihood\", type = \"l\")  # zoom plot\nmax(loglik)                 # maximum loglikelihood over all values of pb\npb[loglik == max(loglik)]   # MLE of pb\nmle_pb_m1_nlsy &lt;- pb[loglik == max(loglik)]\nmax_logL_m1_nlsy &lt;- max(loglik)\n\n# Create ggplot of likelihood and log-likelihood functions\nmodel1grid &lt;- data.frame(pb = pb, lik1 = lik, loglik1 = loglik)\nggplot(data = model1grid, aes(x = pb, y = lik1)) +\n  geom_line() +\n  labs(x = \"possible values of pb\", y = \"Likelihood\")\nggplot(data = model1grid, aes(x = pb, y = loglik1)) +\n  geom_line() +\n  labs(x = \"possible values of pb\", y = \"log Likelihood\")\nmodel1grid |&gt;\n  filter(loglik1 &gt; (-7500)) |&gt;\n  ggplot(aes(x = pb, y = loglik1)) +\n    geom_line() +\n    labs(x = \"possible values of pb with loglik above -7500\", \n         y = \"log Likelihood\")\n\n\n\nModel 2: Sex Conditional Model (small 3 famly data set)\nAssumes probability of having a boy depends on whether you‚Äôve had boys previously\n\n# Find MLEs with 3-dimensional grid search\npbb &lt;- seq(0, 1, length = 101)\npbg &lt;- seq(0, 1, length = 101)\npbn &lt;- seq(0, 1, length = 101)\nmodel2_grid &lt;- expand.grid(pbb = pbb, pbg = pbg, pbn = pbn)\n\nlik &lt;- model2_grid$pbn^1 * (1 - model2_grid$pbn)^3 * model2_grid$pbb^1 * \n  (1 - model2_grid$pbb)^1 * model2_grid$pbg^1 * (1 - model2_grid$pbg)^1\nloglik &lt;- 1 * log(model2_grid$pbn) + 3 * log(1 - model2_grid$pbn) + \n  1 * log(model2_grid$pbb) + 1 * log(1 - model2_grid$pbb) + \n  1 * log(model2_grid$pbg) + 1 * log(1 - model2_grid$pbg)\n\n# Print results\nmax(lik)        # maximum likelihood over all combos of pbb, pbg, pbn\nmax(loglik)     # maximum loglikelihood over all combos of pbb, pbg, pbn\n\nmodel2_grid$pbb[loglik == max(loglik)]   # MLE of pbb\nmodel2_grid$pbg[loglik == max(loglik)]   # MLE of pbg\nmodel2_grid$pbn[loglik == max(loglik)]   # MLE of pbn\n\n# Store results\nmle_pbb_m2_small &lt;- model2_grid$pbb[loglik == max(loglik)]   # MLE of pbb\nmle_pbg_m2_small &lt;- model2_grid$pbg[loglik == max(loglik)]   # MLE of pbg\nmle_pbn_m2_small &lt;- model2_grid$pbn[loglik == max(loglik)]   # MLE of pbn\n\nmax_L_m2_small &lt;- max(lik)\nmax_logL_m2_small &lt;- max(loglik)\n\n\n\nModel comparisons - Model 1 vs.¬†Model 2\n\nlrt &lt;- 2 * (max_logL_m2_small - max_logL_m1_small)   \nlrt                       # likelihood ratio test statistic\n1 - pchisq(lrt, df = 2)   # p-value for testing Ho: no diff between Models 1&2\n\n# AIC and BIC values for Models 1 and 2\naic1 &lt;- -2 * max_logL_m1_small + 2 * 1\naic1\nbic1 &lt;- -2 * max_logL_m1_small + log(8) * 1\nbic1\naic2 &lt;- -2 * max_logL_m2_small + 2 * 3\naic2\nbic2 &lt;- -2 * max_logL_m2_small + log(8) * 3\nbic2"
  },
  {
    "objectID": "labs/03_poisson/03_FullMoon.html",
    "href": "labs/03_poisson/03_FullMoon.html",
    "title": "Chapter 4 - Poisson Regression",
    "section": "",
    "text": "Copy the project lab folder located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file qmd file included."
  },
  {
    "objectID": "labs/03_poisson/03_FullMoon.html#lab-setup",
    "href": "labs/03_poisson/03_FullMoon.html#lab-setup",
    "title": "Chapter 4 - Poisson Regression",
    "section": "",
    "text": "Copy the project lab folder located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file qmd file included."
  },
  {
    "objectID": "labs/03_poisson/03_FullMoon.html#introduction",
    "href": "labs/03_poisson/03_FullMoon.html#introduction",
    "title": "Chapter 4 - Poisson Regression",
    "section": "Introduction",
    "text": "Introduction\nAn article in the British Medical Journal by Bhattacharjee et al.¬†(2000) investigated whether animals bite more often during full moons. To address this question, the researchers conducted a retrospective observational analysis of 1621 consecutive patients who presented at an English hospital ER between 1997 and 1999 with an animal bite. The data is found in bites.csv, and relevant R code can be found below.\nVariables include:\n\nlunar.cycle = period of lunar cycle (1-10), where 10 = full moon\nn.days = number of days in that period\nn.bites = number of patients presenting with an animal bite during that period"
  },
  {
    "objectID": "labs/03_poisson/03_FullMoon.html#questions",
    "href": "labs/03_poisson/03_FullMoon.html#questions",
    "title": "Chapter 4 - Poisson Regression",
    "section": "Questions",
    "text": "Questions\n\nIs there initial evidence of more bites during full moon phases?\nWhy can‚Äôt we just perform a t-test comparing full moon periods to non-full moon periods using period-level data (n=10)?\nWhat options can you think of for handling the fact that Period 5 is based on only 2 lunar days? What are the modeling implications of including number of days in a period as an offset term?\nInterpret model parameters from fit1.\nIs there any evidence of lack of fit in fit1? What factors may lead to lack of fit?\nDoes full moon have an effect above and beyond the linear cycle trend? Interpret the coefficient and a 95% confidence interval for the fullmoon term in fit3.\nWhat is fit4 doing? Does it offer an improvement over fit3?\nWhat evidence is there that fit5 (which uses bitesbyday.csv) is the analysis performed by the authors of this paper?\nBased on this analysis, does it make you more wary of animal bites during full moons?\n\n\nAddressing issues of overdispersion in fit5.\n\nIs there evidence of lack of fit in fit5? Cite evidence both from a goodness of fit test and from comparing means and variances by period.\nIf overdispersion goes uncorrected, what are implications for p-values and CIs for model coefficients?\n\n\nOverdispersion parameter adjustment.\nOne solution is to simply add a second parameter to inflate variances, so that \\(Var(Y_i)=\\phi\\lambda_i\\). This is called a ‚Äúquasi-Poisson‚Äù or, in general, a ‚Äúquasi-likelihood‚Äù approach, because our data no longer follows a true Poisson distribution.\n\n\nNegative binomial modeling.\nAnother solution is to model response using a negative binomial distribution, so that \\(Y\\sim NegBinom(\\theta,p)\\). This distribution comes about if \\(Y|Œª\\sim Poisson(Œª)\\), but the \\(\\lambda\\)‚Äôs themselves are randomly chosen according to a gamma distribution: \\(\\lambda \\sim gamma(Œ∏,\\frac{(1-p)}{p})\\). In this case, $E(Y)==$ and \\(Var(Y)=\\theta \\frac{p}{(1-p)^2} =\\mu+\\frac{\\mu^2}{\\theta}\\), so that \\(\\frac{\\mu^2}{\\theta}\\) is the amount of overdispersion.\n\nCompare the following estimates, tests, and intervals under usual Poisson regression, quasi-Poisson regression, and negative binomial regression:\n\n\n\n\n\n\n\n\n\n\n\nPoisson\nQuasi-poisson\nNegative Binomial\n\n\n\n\n\\(\\phi\\)\n\n\n\n\n\n\\(SE(\\hat{\\beta}_4\\))\n\n\n\n\n\nWald-type test stat\n\n\n\n\n\nWald-type p-value\n\n\n\n\n\nLRT-type test stat\n\n\n\n\n\nLRT-type test stat\n\n\n\n\n\nLRT-type p-value\n\n\n\n\n\nCI - profile for \\(e^{\\beta_4}\\)\n\n\n\n\n\nCI-Wald-type for \\(e^{\\beta_4}\\)"
  },
  {
    "objectID": "labs/03_poisson/03_FullMoon.html#code",
    "href": "labs/03_poisson/03_FullMoon.html#code",
    "title": "Chapter 4 - Poisson Regression",
    "section": "Code",
    "text": "Code\n\nSetup\n\nlibrary(MASS)\nlibrary(dplyr)\nlibrary(maxLik)   # will have to install first\nlibrary(ggplot2)\nlibrary(gridExtra) \n\nbites.data &lt;- read.csv(\"data/bites.csv\")\nbites.day &lt;- read.csv(\"data/bitesbyday.csv\")\n\n\n\nbites.csv: analysis and offsets\n\n# Exploratory Data Analysis\nbites.data\n\n# Average n.bites by day for each cycle to make them comparable\nbites.data &lt;- mutate(bites.data, avg.bites=n.bites/n.days, \n                     fullmoon = ifelse(lunar.cycle==10,1,0))\nwith(bites.data, summary(avg.bites))\nwith(bites.data, summary(n.bites))\nwith(bites.data, by(avg.bites,fullmoon,summary))\n# t.test(avg.bites~fullmoon, data=bites.data)    # produces an error -why?\n\nggplot(data = bites.data, aes(x = avg.bites)) + \n  geom_histogram(bins = 4)\nggplot(data = bites.data, aes(x = n.bites)) + \n  geom_histogram(bins = 4)\nggplot(data = bites.data, aes(x = lunar.cycle, y = avg.bites)) + \n  geom_point() + geom_smooth(method=\"lm\") \n\n# Now try modeling as Poisson counts for each cycle.\n# However, Cycle 5 contains only 2 days whereas all others have 3.  \n\n# The simplest model (Model 1) uses only an indicator for the full moon cycle\n#   plus an offset for the number of days so the counts are comparable.\nfit1 &lt;-  glm(n.bites ~ fullmoon, family=poisson, offset=log(n.days),\n             data=bites.data)\nsummary(fit1)\nexp(fit1$coef)\nexp(confint(fit1))\n\n# Alternative (Wald) confidence intervals\nfit1coef &lt;- summary(fit1)$coefficients[,1]\nfit1se &lt;- summary(fit1)$coefficients[,2]\nlb &lt;- fit1coef - qnorm(.975)*fit1se\nub &lt;- fit1coef + qnorm(.975)*fit1se\ncbind(exp(lb),exp(ub))\n\n#Signs of lack-of-fit with Simple Model\ngof &lt;- 1-pchisq(fit1$deviance, fit1$df.residual)\ngof \n\n# Model 2:  Linear cycle trend\nfit2 &lt;-  glm(n.bites ~ lunar.cycle, family=poisson, offset=log(n.days),\n             data=bites.data)\nsummary(fit2)\ngof &lt;- 1-pchisq(fit2$deviance, fit2$df.residual)\ngof \n\n# Model 3: Does full moon have effect above and beyond linear cycle trend?\nfit3 &lt;- glm(n.bites ~ lunar.cycle + fullmoon, family=poisson, \n            offset=log(n.days), data=bites.data)\nsummary(fit3)\nexp(fit3$coef)\nexp(confint(fit3))\nanova(fit2, fit3, test = \"Chisq\")\ngof &lt;- 1-pchisq(fit3$deviance, fit3$df.residual)\ngof \n\n# Model 4: What does this model do?\nbites.data4 &lt;- mutate(bites.data, dist = c(3,6,9,12,14.5,12,9,6,3,0))\nfit2a &lt;- glm(n.bites ~ dist, family=poisson, offset=log(n.days), data=bites.data4)\nsummary(fit2a)\n\nfit4 &lt;- glm(n.bites ~ dist + fullmoon, family=poisson, offset=log(n.days),\n            data=bites.data4)\nsummary(fit4)\n\n\n\nbitesbyday.csv: analysis and overdispersion\n\n# Model 5: Try to replicate model from paper, using daily data I transcribed \n#          from Figure 1 and matched to period totals\nbites.day &lt;- bites.day %&gt;%\n  mutate(period = factor(period, levels = c(5,1:4,6:10)),\n         period_no4 = factor(period_no4, levels = c(5, 1:3, 6:10))\n)\n\nfit5 &lt;- glm(bites ~ period, family=poisson, data=bites.day)\nsummary(fit5)\nexp(fit5$coef)\nexp(confint(fit5))\ngof &lt;- 1-pchisq(fit5$deviance, fit5$df.residual)\ngof \n\nfit5reduced &lt;- glm(bites ~ period_no4, family = poisson, data = bites.day)\nsummary(fit5reduced)\nanova(fit5reduced, fit5, test = \"Chisq\")\n\n# Alternative (Wald) confidence intervals\nfit5coef &lt;- summary(fit5)$coefficients[,1]\nfit5se &lt;- summary(fit5)$coefficients[,2]\nlb &lt;- fit5coef - qnorm(.975)*fit5se\nub &lt;- fit5coef + qnorm(.975)*fit5se\ncbind(exp(lb),exp(ub))\n\n\n# Might overdispersion be a factor in lack of fit?\nbites.day %&gt;%\n  group_by(period) %&gt;%\n  summarise(count = n(),\n            mean_bites = mean(bites),\n            var_bites = var(bites))\n\n\n# Adjust fit1 for overdispersion\nfit5a &lt;- glm(bites ~ period, family=quasipoisson, data=bites.day)\nsummary(fit5a)\nexp(confint(fit5a))\n\nfit5areduced &lt;- glm(bites ~ period_no4, family = quasipoisson, data = bites.day)\nsummary(fit5areduced)\nanova(fit5areduced, fit5a, test = \"F\")\n\nphi &lt;- sum(resid(fit5, type='pearson')^2) / fit5$df.residual\nphi\ndrop.in.dev &lt;- fit5reduced$deviance - fit5$deviance\ndiff.in.df &lt;- fit5reduced$df.residual - fit5$df.residual\nFstat &lt;- drop.in.dev / summary(fit5a)$dispersion\nFstat\n1-pf(Fstat, diff.in.df, fit5$df.residual)\n\n# Alternative (Wald) confidence intervals with QL\nfit5acoef &lt;- summary(fit5a)$coefficients[,1]\nfit5ase &lt;- summary(fit5a)$coefficients[,2]\nlb &lt;- fit5acoef - qt(.975, fit5a$df.residual)*fit5ase\nub &lt;- fit5acoef + qt(.975, fit5a$df.residual)*fit5ase\ncbind(exp(lb),exp(ub))\n\n\n# Model fit1 using negative binomial\nfit5b &lt;- glm.nb(bites ~ period, data=bites.day)\nsummary(fit5b)\nexp(confint(fit5b))\n\nfit5breduced &lt;- glm.nb(bites ~ period_no4, data = bites.day)\nsummary(fit5breduced)\nanova(fit5breduced, fit5b, test = \"Chisq\")\n\n# Alternative (Wald) confidence intervals with NB\nfit5bcoef &lt;- summary(fit5b)$coefficients[,1]\nfit5bse &lt;- summary(fit5b)$coefficients[,2]\nlb &lt;- fit5bcoef - qnorm(.975)*fit5bse\nub &lt;- fit5bcoef + qnorm(.975)*fit5bse\ncbind(exp(lb),exp(ub))"
  },
  {
    "objectID": "labs/04_logistic/04_moths.html",
    "href": "labs/04_logistic/04_moths.html",
    "title": "Chapter 6 - Binomial Regression",
    "section": "",
    "text": "Copy the project lab folder located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file qmd file included."
  },
  {
    "objectID": "labs/04_logistic/04_moths.html#lab-setup",
    "href": "labs/04_logistic/04_moths.html#lab-setup",
    "title": "Chapter 6 - Binomial Regression",
    "section": "",
    "text": "Copy the project lab folder located at Home -&gt; STA363_inst_files-&gt; labs. If you check the box next to the folder name, then click the small gear icon you can ‚Äúcopy to‚Äù and put a copy of the folder in your newly created folder.\nNow, click File-&gt; Open Project and navigate to the project file in the folder you just copied.\nYou can place your responses in the file qmd file included."
  },
  {
    "objectID": "labs/04_logistic/04_moths.html#introduction",
    "href": "labs/04_logistic/04_moths.html#introduction",
    "title": "Chapter 6 - Binomial Regression",
    "section": "Introduction",
    "text": "Introduction\nAn article in the Journal of Animal Ecology by Bishop (1972) investigated whether moths provide evidence of ‚Äúsurvival of the fittest‚Äù with their camouflage traits. Researchers glued equal numbers of light and dark morph moths in lifelike positions on tree trunks at 7 locations from 0 to 51.2 km from Liverpool. They then recorded the numbers of moths removed after 24 hours, presumably by predators. The hypothesis was that, since tree trunks near Liverpool were blackened by pollution, light morph moths would be more likely to be removed near Liverpool. The data is found in moth.csv, and relevant R code can be found under Moths.Rmd. Variables include:\n\nMOPRH = light or dark\nDISTANCE = kilometers from Liverpool\nPLACED = number of moths of a specific morph glued to trees at that location\nREMOVED = number of moths of a specific morph removed after 24 hours"
  },
  {
    "objectID": "labs/04_logistic/04_moths.html#questions",
    "href": "labs/04_logistic/04_moths.html#questions",
    "title": "Chapter 6 - Binomial Regression",
    "section": "Questions",
    "text": "Questions\n\nWhat do you think of the study design? Any suggestions for improvement?\nWhat are logits, and why would we want to plot logits vs.¬†distance (rather than, say, proportion removed vs.¬†distance)?\nWhat can we conclude from the empirical logit plots?\nInterpret the 3 coefficient estimates from model ‚Äúbreg2‚Äù. Note that breg2 and breg2a provide two alternative ways to express the same model‚Ä¶\nWhat are the implications to using MORPH rather than ‚Äúdark‚Äù in breg2b?\nHow do the predicted logits from breg2 fit the actual data? Note that the predict() function with type=‚Äùlink‚Äù returns predicted logits, while type=‚Äùresponse‚Äù returns predicted probabilities‚Ä¶\nInterpret the 4 coefficients estimates from model breg3.\nTest the significance of the interaction term in breg3 in two ways. Do both methods agree?\nTest the goodness of fit for model breg3. What can we conclude about this model?\nIs there evidence of extra-binomial variation (overdispersion) in breg3?\nRegardless of your answer to (9), repeat (7) after adjusting for overdispersion.\nCompare confidence intervals for the interaction term in breg3 with and without adjusting for overdispersion, and with and without using profile likelihoods.\nWhat are the implications in breg5 of including DISTANCE as a factor variable? How does this change model interpretations? Does it lead to an improved model?\nWhat happens if we expand the data set to contain one row per moth (968 rows)? Now we can run a logistic regression model. How does the logistic regression model ‚Äúlreg1‚Äù compare to the binomial regression model breg3? What are similarities and differences? Would there be any reason to run a binomial regression rather than a logistic regression in a case like this?"
  },
  {
    "objectID": "mini_project/02_project_GLM.html",
    "href": "mini_project/02_project_GLM.html",
    "title": "Mini Project 2",
    "section": "",
    "text": "Pick a partner.\nFind an appropriate data set.\n\nGLM‚Äôs are broadly applicable and there are no requirements on the type of data the response needs to follow.\nThe data you choose should have a few predictors that may be useful when modeling (ideally at least 1 quantitative and 1 categorical).\n\n\nData Options. Check out Data Links on the Useful Links part of the course website. TidyTuesday has quickly accessible data.\n\nWrite out the anticipated cleaning and/or feature engineering steps you will need to take. Some examples:\n\nCreating simplified categorical variables or transforming a continuous variable into categorical.\nAggregating data\nConverting date columns\netc.\n\nSetup your R Project(s) on the server.\nRead your data into R. This likely will require you to download the data to your computer and upload the data the server."
  },
  {
    "objectID": "mini_project/02_project_GLM.html#timing",
    "href": "mini_project/02_project_GLM.html#timing",
    "title": "Mini Project 2",
    "section": "Timing",
    "text": "Timing\nThis project will be in a workshop style. The intention is for you to start and finish by the end of class time. We will follow a timeline:\n\n\n\n\n\n\n\nTask\nTiming\n\n\n\n\nFind Appropriate Data\n9:00 am - 9:20 am\n\n\nClean Data\n9:20 am - 9:50 am\n\n\nPerform EDA\n10:00 am - 10:30 am\n\n\nFit, Assess, and Compare Regression Models\n10:30 am - 11:00 am, 1:00 pm - 2:00 pm\n\n\nPrepare presentation\n2:00 pm - 2:20 pm\n\n\nPresent your findings\n2:20 pm - 2:40 pm\n\n\nSubmit your Final Report\nSubmit HTML Sunday 9/8 at 11:59 pm\n\n\n\n\nGrading\nEach Mini Project is worth 50 points (Labs are 10 points each).\n\n\n\n\n\n\n\nCategory\nPoints\n\n\n\n\nThe data chosen is appropriate, and the cleaning steps are correct and explained.\n5\n\n\nEDA is thorough. All included graphs and tables are paired with a discussion. EDA supports the choice of modeling technique.\n15\n\n\nThe model fitting process has a logical flow. Multiple models are considered and compared using statistical tests and multiple metrics. Any model that is interpreted has been assessed using residual plots and appropriate statistical tests.\n15\n\n\nThe code follows a sensible order and has been appropriately commented on.\n5\n\n\nThe presentation is concise, describes the data, highlights key parts of the EDA, describes minimally the final model, gives at least 1 interpretation in the context of a coefficient, and discusses limitations and potential future work.\n5\n\n\nThe report is well written, with correct spelling and grammar. The used code is included either inline or in an appendix at the end.\n5\n\n\n\n\n\nSubmission\nAdd format part of your final report document and then re-render:\n```{r}\n#| label: yaml_example\n#| eval: false\n---\ntitle: \"Document title\"\nauthor: \"my name\"\nformat:\n  html:\n    embed-resources: true\n---\n```\nWhen you are finished with your homework, be sure to Render the final document. Once rendered, you can download your file by:\n\nFinding the .html file in your File pane (on the bottom right of the screen)\nClick the check box next to the file\nClick the blue gear above and then click ‚ÄúExport‚Äù to download\nSubmit your final html document to the respective assignment on Moodle"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html",
    "href": "slides/01-welcome_ch1_o.html",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Dr.¬†Tyler George: tgeorge@cornellcollege.edu\n\n\n\n\n\nCourse Dates: August 26th to September 18th\nCourse sessions: M-F,9am-11am and 1pm-3pm\nExam Dates: September 6th and 18th\n\n\n\n\nIn statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n\n\nWikipedia\n. . .\nLogistic regression\n\\[\\begin{aligned}\\pi = P(y = 1 | x) \\hspace{2mm} &\\Rightarrow \\hspace{2mm} \\text{Link function: } \\log\\big(\\frac{\\pi}{1-\\pi}\\big) \\\\\n&\\Rightarrow \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~x\\end{aligned}\\]\n\n\n\nGeneralized Linear Models (Ch 1 - 6)\n\nIntroduce models for non-normal response variables\nEstimation, interpretation, and inference\nMathematical details showing how GLMs are connected\n\n\n\n\nModeling correlated data (Ch 7 - 9)\n\nIntroduce multilevel models for correlated and longitudinal data\nEstimation, interpretation, and inference\nMathematical details, particularly diving into covariance structures\n\n\n\n\nMore Regression Models (ITSL Chapter 7) - Polynomial Regression - Regression Splines - Smoothing Splines - Generalized Additive Models (GAMS)\n\n\n\n\nCreate larger groups\nQuick introductions - Name, year, and major\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to December 1st.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Cornell Student\nNot clothes (we‚Äôre all wearing socks)\nNot body parts (we all have a nose)\n\n\n. . .\nReporter will share list with the class\n\n\n\n. . .\nPre-reqs\n\nSTA 201, 202 and DSC 223\n\n. . .\nBackground knowledge\n\n\n\nStatistical content\n\nLinear and logistic regression\nStatistical inference\nBasic understanding of random variables\n\n\n\n\nComputing\n\nUsing R for data analysis\nWriting reports using R Markdown or Quarto\n\n\n\n\n\n\n\n\nWebsite\n\nhttps://stats-tgeorge.github.io/STA363_AdvReg/\nCentral hub for the course\nNotes\nLabs\nDatasets\n\n\n\n\n\n\nMoodle:\n\nhttps://moodle.cornellcollege.edu/course/view.php?id=7908\nSubmissions\nGradebook\nAnnouncements\n\n\n\n\n\nLectures\n\nSome traditional lecture\nIndividual and group labs\nBring fully-charged laptop\nMini-projects\nExams\n\n. . .\nAttendance is expected (if you are healthy!)\n\n\n\n\n\n\n\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler\n\nAvailable online\nHard copies available for purchase\n\n\n\n\n\n\nThe secondary text is: An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani ‚Äì it is freely available online. Chapter 7.\n\nHard copies available for purchase\n\n\n\n\n\nRStudio Server is installed and should be used\nhttp://turing.cornellcollege.edu:8787/\n\n\n\n\nReadings\n\nPrimarily from Beyond Multiple Linear Regression\nRecommend reading assigned text before lecture\n\n. . .\nHomework - Primarily from Beyond Multiple Linear Regression - Individual assignments - Work together but must complete your own work. Discuss but don‚Äôt copy.\n\n\n\nMini-projects\nExamples:\n\nMini-project 01: Focused on models for non-normal response variables, such as count data\nMini-project 02: Focused on models for correlated data\n\n. . .\n\nShort write up and short presentation\nTeam-based\n\n\n\n\n\nTwo exams this block, September 6th and 18th.\nEach will have two components\n\nComponent 1 will be on these dates and you will get a choice of oral or written format.\nComponent 2 will be a take-home, open-book, open-note, exam.\nYou will have 12 hours or more to complete this component.\n\n\n\n\n\nFinal grades will be calculated as follows\n\n\n\nCategory\nPoints\n\n\n\n\nHomework\n200\n\n\nParticipation\n100\n\n\nLabs and Mini Projects\n300\n\n\nExams\n400\n\n\nTotal\n1000\n\n\n\nSee Syllabus on website for letter grade thresholds.\n\n\n\n\nOffice hours to meet with your instructor in West 311\n\nTypically MWTh 3:05pm-4:05pm and by appt.\nDouble check course calendar\nMake appointments by going to https://calendar.app.google/Li1dftFBXqzRnaX69\n\nEmail Tyler George for private questions regarding personal matters or grades.\n\nPlease put STA 363 in the subject line since I am also teaching capstone this semester\n\nCollege support at https://stats-tgeorge.github.io/personal_website/course-support.html."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#instructor",
    "href": "slides/01-welcome_ch1_o.html#instructor",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Dr.¬†Tyler George: tgeorge@cornellcollege.edu"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#course-logistics",
    "href": "slides/01-welcome_ch1_o.html#course-logistics",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Course Dates: August 26th to September 18th\nCourse sessions: M-F,9am-11am and 1pm-3pm\nExam Dates: September 6th and 18th"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#generalized-linear-models",
    "href": "slides/01-welcome_ch1_o.html#generalized-linear-models",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "In statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n\n\nWikipedia\n. . .\nLogistic regression\n\\[\\begin{aligned}\\pi = P(y = 1 | x) \\hspace{2mm} &\\Rightarrow \\hspace{2mm} \\text{Link function: } \\log\\big(\\frac{\\pi}{1-\\pi}\\big) \\\\\n&\\Rightarrow \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~x\\end{aligned}\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester13",
    "href": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester13",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Generalized Linear Models (Ch 1 - 6)\n\nIntroduce models for non-normal response variables\nEstimation, interpretation, and inference\nMathematical details showing how GLMs are connected"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester23",
    "href": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester23",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Modeling correlated data (Ch 7 - 9)\n\nIntroduce multilevel models for correlated and longitudinal data\nEstimation, interpretation, and inference\nMathematical details, particularly diving into covariance structures"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester33",
    "href": "slides/01-welcome_ch1_o.html#what-were-covering-this-semester33",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "More Regression Models (ITSL Chapter 7) - Polynomial Regression - Regression Splines - Smoothing Splines - Generalized Additive Models (GAMS)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#meet-your-classmates",
    "href": "slides/01-welcome_ch1_o.html#meet-your-classmates",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Create larger groups\nQuick introductions - Name, year, and major\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to December 1st.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Cornell Student\nNot clothes (we‚Äôre all wearing socks)\nNot body parts (we all have a nose)\n\n\n. . .\nReporter will share list with the class"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-background-is-assumed-for-the-course",
    "href": "slides/01-welcome_ch1_o.html#what-background-is-assumed-for-the-course",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": ". . .\nPre-reqs\n\nSTA 201, 202 and DSC 223\n\n. . .\nBackground knowledge\n\n\n\nStatistical content\n\nLinear and logistic regression\nStatistical inference\nBasic understanding of random variables\n\n\n\n\nComputing\n\nUsing R for data analysis\nWriting reports using R Markdown or Quarto"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#course-toolkit-12",
    "href": "slides/01-welcome_ch1_o.html#course-toolkit-12",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Website\n\nhttps://stats-tgeorge.github.io/STA363_AdvReg/\nCentral hub for the course\nNotes\nLabs\nDatasets"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#course-toolkit-12-1",
    "href": "slides/01-welcome_ch1_o.html#course-toolkit-12-1",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Moodle:\n\nhttps://moodle.cornellcollege.edu/course/view.php?id=7908\nSubmissions\nGradebook\nAnnouncements"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#class-meetings",
    "href": "slides/01-welcome_ch1_o.html#class-meetings",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Lectures\n\nSome traditional lecture\nIndividual and group labs\nBring fully-charged laptop\nMini-projects\nExams\n\n. . .\nAttendance is expected (if you are healthy!)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#textbook",
    "href": "slides/01-welcome_ch1_o.html#textbook",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Beyond Multiple Linear Regression by Paul Roback and Julie Legler\n\nAvailable online\nHard copies available for purchase"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#textbook-2",
    "href": "slides/01-welcome_ch1_o.html#textbook-2",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "The secondary text is: An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani ‚Äì it is freely available online. Chapter 7.\n\nHard copies available for purchase"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#using-r-rstudio",
    "href": "slides/01-welcome_ch1_o.html#using-r-rstudio",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "RStudio Server is installed and should be used\nhttp://turing.cornellcollege.edu:8787/"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#activities-assessments",
    "href": "slides/01-welcome_ch1_o.html#activities-assessments",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Readings\n\nPrimarily from Beyond Multiple Linear Regression\nRecommend reading assigned text before lecture\n\n. . .\nHomework - Primarily from Beyond Multiple Linear Regression - Individual assignments - Work together but must complete your own work. Discuss but don‚Äôt copy."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#activities-assessments-1",
    "href": "slides/01-welcome_ch1_o.html#activities-assessments-1",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Mini-projects\nExamples:\n\nMini-project 01: Focused on models for non-normal response variables, such as count data\nMini-project 02: Focused on models for correlated data\n\n. . .\n\nShort write up and short presentation\nTeam-based"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#exams",
    "href": "slides/01-welcome_ch1_o.html#exams",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Two exams this block, September 6th and 18th.\nEach will have two components\n\nComponent 1 will be on these dates and you will get a choice of oral or written format.\nComponent 2 will be a take-home, open-book, open-note, exam.\nYou will have 12 hours or more to complete this component."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#grading",
    "href": "slides/01-welcome_ch1_o.html#grading",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Final grades will be calculated as follows\n\n\n\nCategory\nPoints\n\n\n\n\nHomework\n200\n\n\nParticipation\n100\n\n\nLabs and Mini Projects\n300\n\n\nExams\n400\n\n\nTotal\n1000\n\n\n\nSee Syllabus on website for letter grade thresholds."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#resources",
    "href": "slides/01-welcome_ch1_o.html#resources",
    "title": "Welcome and Chapter 1",
    "section": "",
    "text": "Office hours to meet with your instructor in West 311\n\nTypically MWTh 3:05pm-4:05pm and by appt.\nDouble check course calendar\nMake appointments by going to https://calendar.app.google/Li1dftFBXqzRnaX69\n\nEmail Tyler George for private questions regarding personal matters or grades.\n\nPlease put STA 363 in the subject line since I am also teaching capstone this semester\n\nCollege support at https://stats-tgeorge.github.io/personal_website/course-support.html."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#setup---r-packages",
    "href": "slides/01-welcome_ch1_o.html#setup---r-packages",
    "title": "Welcome and Chapter 1",
    "section": "Setup - R Packages",
    "text": "Setup - R Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#assumptions-for-linear-regression",
    "href": "slides/01-welcome_ch1_o.html#assumptions-for-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\nWhat are the assumptions for linear regression? . . .\nLinearity: Linear relationship between mean response and predictor variable(s)\n. . .\nIndependence: Residuals are independent. There is no connection between how far any two points lie above or below regression line.\n. . .\nNormality: Response follows a normal distribution at each level of the predictor (or combination of predictors)\n. . .\nEqual variance: Variability (variance or standard deviation) of the response is equal for all levels of the predictor (or combination of predictors)\n. . .\nUse residual plots to check that the conditions hold before using the model for statistical inference."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#assumptions-for-linear-regression-1",
    "href": "slides/01-welcome_ch1_o.html#assumptions-for-linear-regression-1",
    "title": "Welcome and Chapter 1",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\nModified from Figure 1.1. in BMLR]\n\n\nLinearity: Linear relationship between mean of the response \\(Y\\) and the predictor \\(X\\)\nIndependence: No connection between how any two points lie above or below the regression line\nNormality: Response, \\(Y\\), follows a normal distribution at each level of the predictor, \\(X\\) (indicated by red curves)\nEqual variance: Variance (or standard deviation) of the response, \\(Y\\), is equal for all levels of the predictor, \\(X\\)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#questions",
    "href": "slides/01-welcome_ch1_o.html#questions",
    "title": "Welcome and Chapter 1",
    "section": "Questions",
    "text": "Questions\nHow do we assess these conditions?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#beyond-linear-regression",
    "href": "slides/01-welcome_ch1_o.html#beyond-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Beyond linear regression",
    "text": "Beyond linear regression\n\nWhen we use linear least squares regression to draw conclusions, we do so under the assumption that L.I.N.E. are all met.\nGeneralized linear models require different assumptions and can accommodate violations in L.I.N.E.\n\nRelationship between response and predictor(s) can be nonlinear\nResponse variable can be non-normal\nVariance in response can differ at each level of predictor(s)\n\n\n. . .\nBut the independence assumption must hold!\n\nMultilevel models will be used for data with correlated observations"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#review-of-multiple-linear-regression",
    "href": "slides/01-welcome_ch1_o.html#review-of-multiple-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Review of multiple linear regression",
    "text": "Review of multiple linear regression"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#data-kentucky-derby-winners",
    "href": "slides/01-welcome_ch1_o.html#data-kentucky-derby-winners",
    "title": "Welcome and Chapter 1",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\nToday‚Äôs data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017.\n. . .\n\n\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)]\n\nAdditional variable\n\nwinner: Winning horse\n\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced]"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#data",
    "href": "slides/01-welcome_ch1_o.html#data",
    "title": "Welcome and Chapter 1",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")\n\n\nderby |&gt;\n  head(5) |&gt; kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n\n\n1898\nPlaudit\ngood\n51.16\n4\n\n\n1899\nManuel\nfast\n50.00\n5\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#data-analysis-life-cycle",
    "href": "slides/01-welcome_ch1_o.html#data-analysis-life-cycle",
    "title": "Welcome and Chapter 1",
    "section": "Data Analysis Life Cycle",
    "text": "Data Analysis Life Cycle"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#exploratory-data-analysis-eda",
    "href": "slides/01-welcome_ch1_o.html#exploratory-data-analysis-eda",
    "title": "Welcome and Chapter 1",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\n\nOnce you‚Äôre ready for the statistical analysis (explore), the first step should always be exploratory data analysis.\nThe EDA will help you\n\nbegin to understand the variables and observations\nidentify outliers or potential data entry errors\nbegin to see relationships between variables\nidentify the appropriate model and identify a strategy\n\nThe EDA is exploratory; formal modeling and statistical inference should be used to draw conclusions."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#plots-for-univariate-eda",
    "href": "slides/01-welcome_ch1_o.html#plots-for-univariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for univariate EDA",
    "text": "Plots for univariate EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = derby, aes(x = speed)) + \n  geom_histogram(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Winning speed (ft/s)\", y = \"Count\")\n\np2 &lt;- ggplot(data = derby, aes(x = starters)) + \n  geom_histogram(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Starters\", y = \"Count\")\n\np3 &lt;- ggplot(data = derby, aes(x = condition)) +\n   geom_bar(fill = \"forestgreen\", color = \"black\", aes(x = ))\n\np1 + (p2 / p3) + \n  plot_annotation(title = \"Univariate data analysis\")"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#plots-for-bivariate-eda",
    "href": "slides/01-welcome_ch1_o.html#plots-for-bivariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for bivariate EDA",
    "text": "Plots for bivariate EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np4 &lt;- ggplot(data = derby, aes(x = starters, y = speed)) + \n  geom_point() + \n  labs(x = \"Starters\", y = \"Speed (ft / s)\")\n\np5 &lt;- ggplot(data = derby, aes(x = year, y = speed)) + \n  geom_point() + \n  labs(x = \"Year\", y = \"Speed (ft / s)\")\n\np6 &lt;- ggplot(data = derby, aes(x = condition, y = speed)) + \n  geom_boxplot(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Conditions\", y = \"Speed (ft / s)\")\n\n(p4 + p5) + p6 +\n  plot_annotation(title = \"Bivariate data analysis\")"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#scatterplot-matrix",
    "href": "slides/01-welcome_ch1_o.html#scatterplot-matrix",
    "title": "Welcome and Chapter 1",
    "section": "Scatterplot matrix",
    "text": "Scatterplot matrix\nA scatterplot matrix helps quickly visualize relationships between many variable pairs. They are particularly useful to identify potentially correlated predictors.\n. . .\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#library(GGally)\nggpairs(data = derby, \n        columns = c(\"condition\", \"year\", \"starters\", \"speed\"))"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#plots-for-multivariate-eda",
    "href": "slides/01-welcome_ch1_o.html#plots-for-multivariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for multivariate EDA",
    "text": "Plots for multivariate EDA\nPlot the relationship between the response and a predictor based on levels of another predictor to assess potential interactions.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#library(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-1-main-effects-model",
    "href": "slides/01-welcome_ch1_o.html#model-1-main-effects-model",
    "title": "Welcome and Chapter 1",
    "section": "Model 1: Main effects model",
    "text": "Model 1: Main effects model\n\nOutputCode\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\n\n# Fit and display model\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\ntidy(model1) |&gt; \n  kable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#interpretation",
    "href": "slides/01-welcome_ch1_o.html#interpretation",
    "title": "Welcome and Chapter 1",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\\widehat{speed} = 8.197 - 0.005 ~ starters + 0.023 ~ year - 0.443 ~ good - 1.543 ~ slow\\]\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n. . .\n\nWrite out the interpretations for starters and conditiongood.\nDoes the intercept have a meaningful interpretation?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#centering",
    "href": "slides/01-welcome_ch1_o.html#centering",
    "title": "Welcome and Chapter 1",
    "section": "Centering",
    "text": "Centering\nCentering: Subtract a constant from each observation of a given variable\n\nDo this to make interpretation of model parameters more meaningful (particularly intercept)\nIn STA 202, we used mean-centering where we subtracted the mean from each observation of given variable\nHow does centering change the model?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#centering-year",
    "href": "slides/01-welcome_ch1_o.html#centering-year",
    "title": "Welcome and Chapter 1",
    "section": "Centering year",
    "text": "Centering year\n\nderby &lt;- derby |&gt;\n  mutate(yearnew = year - 1896) #1896 = starting year\n\n. . .\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.175\n0.194\n269.079\n0.000\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyearnew\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n. . .\n\\[\\widehat{speed} = 52.175 - 0.005 ~ starters + 0.023 ~ yearnew - 0.443 ~ good - 1.543 ~ slow\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-1-check-model-assumptions",
    "href": "slides/01-welcome_ch1_o.html#model-1-check-model-assumptions",
    "title": "Welcome and Chapter 1",
    "section": "Model 1: Check model assumptions",
    "text": "Model 1: Check model assumptions\n\nPlotsQuestions\n\n\n\n#library(ggfortify)\nautoplot(model1Cent)\n\n\n\n\n\n\n\n\n\n\nWhich of the model assumptions (LINE) does this pass and/or fail?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-2-add-quadratic-effect-for-year",
    "href": "slides/01-welcome_ch1_o.html#model-2-add-quadratic-effect-for-year",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Add quadratic effect for year?",
    "text": "Model 2: Add quadratic effect for year?\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = derby, aes(x = yearnew, y = speed)) + \n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") + \n  geom_smooth(se = FALSE, color = \"red\", linetype = 2) + \n  labs(x = \"Years since 1896\", y = \"Speed (ft/s)\", \n       title = \"Speed vs. Years since 1896\")"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-2-add-yearnew2",
    "href": "slides/01-welcome_ch1_o.html#model-2-add-yearnew2",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Add \\(yearnew^2\\)",
    "text": "Model 2: Add \\(yearnew^2\\)\n\nPlotCode\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n51.4130\n0.1826\n281.5645\n0.0000\n\n\nstarters\n-0.0253\n0.0136\n-1.8588\n0.0656\n\n\nyearnew\n0.0700\n0.0061\n11.4239\n0.0000\n\n\nI(yearnew^2)\n-0.0004\n0.0000\n-8.0411\n0.0000\n\n\nconditiongood\n-0.4770\n0.1857\n-2.5689\n0.0115\n\n\nconditionslow\n-1.3927\n0.1305\n-10.6701\n0.0000\n\n\n\n\n\n\n\n\nmodel2 &lt;- lm(speed ~ starters + yearnew + I(yearnew^2) + condition, \n             data = derby)\ntidy(model2) |&gt; kable(digits = 4)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#interpreting-quadratic-effects",
    "href": "slides/01-welcome_ch1_o.html#interpreting-quadratic-effects",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting quadratic effects",
    "text": "Interpreting quadratic effects\n\\[\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x_1  + \\hat{\\beta}_2 ~ x_2 + \\hat{\\beta}_3 ~ x_2^2\\]\nGeneral interpretation: When \\(x_2\\) increases from a to b, \\(y\\) is expected to change by \\(\\hat{\\beta}_2(b - a) + \\hat{\\beta}_3(b^2 - a^2)\\), holding \\(x_1\\) constant.\n. . ."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#interpreting-quadratic-effects-1",
    "href": "slides/01-welcome_ch1_o.html#interpreting-quadratic-effects-1",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting quadratic effects",
    "text": "Interpreting quadratic effects\n\\[\\begin{aligned}\\widehat{speed} = &51.413 - 0.025 ~ starters + 0.070 ~ yearnew \\\\\n& - 0.0004 ~ yearnew^2 - 0.477 ~ good - 1.393 ~ slow\\end{aligned}\\]\n. . .\nQuestions:\nInterpret the effect of year for the 5 most recent years (2013 - 2017)."
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-2-check-model-assumptions",
    "href": "slides/01-welcome_ch1_o.html#model-2-check-model-assumptions",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Check model assumptions",
    "text": "Model 2: Check model assumptions"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-3-include-interaction-term",
    "href": "slides/01-welcome_ch1_o.html#model-3-include-interaction-term",
    "title": "Welcome and Chapter 1",
    "section": "Model 3: Include interaction term?",
    "text": "Model 3: Include interaction term?\nRecall from the EDA‚Ä¶\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#model-3-add-interaction-term",
    "href": "slides/01-welcome_ch1_o.html#model-3-add-interaction-term",
    "title": "Welcome and Chapter 1",
    "section": "Model 3: Add interaction term",
    "text": "Model 3: Add interaction term\n\\[\\begin{aligned}\\widehat{speed} = & 52.387 - 0.003 ~ starters + 0.020 ~ yearnew - 1.070 ~ good - 2.183 ~ slow \\\\ &+0.012 ~ yearnew \\times good + 0.012 ~ yearnew \\times slow \\end{aligned}\\]\n\nOutputCodeAssumptions\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n\n\n\nmodel3 &lt;- lm(speed ~ starters + yearnew + condition +\n               yearnew * condition, \n             data = derby)\ntidy(model3) |&gt; kable(digits = 4)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#interpreting-interaction-effects",
    "href": "slides/01-welcome_ch1_o.html#interpreting-interaction-effects",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting interaction effects",
    "text": "Interpreting interaction effects\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n\nWrite out the interpretation of‚Ä¶"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#which-model-would-you-choose",
    "href": "slides/01-welcome_ch1_o.html#which-model-would-you-choose",
    "title": "Welcome and Chapter 1",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\n\nModel 1: Main effectsModel 2: Main effects + \\(year^2\\)Model 3: Main effects + interactionCode\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.73\n0.721\n259.478\n276.302\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.827\n0.819\n207.429\n227.057\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\n\n# Model 1\nglance(model1Cent) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)\n\n# Model2\nglance(model2) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)\n\n# Model 3\nglance(model3) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#what-are-these-model-quality-metrics",
    "href": "slides/01-welcome_ch1_o.html#what-are-these-model-quality-metrics",
    "title": "Welcome and Chapter 1",
    "section": "What are these model quality metrics?",
    "text": "What are these model quality metrics?\n\nHow do we define RSquared?\nWhat is adj.r.squared?"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#measures-of-model-performance",
    "href": "slides/01-welcome_ch1_o.html#measures-of-model-performance",
    "title": "Welcome and Chapter 1",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(\\color{#4187aa}{R^2}\\): Proportion of variability in the response explained by the model.\n\nWill always increase as predictors are added, so it shouldn‚Äôt be used to compare models\n\n\\(\\color{#4187aa}{Adj. R^2}\\): Similar to \\(R^2\\) with a penalty for extra terms\n\n. . .\n\n\\(\\color{#4187aa}{AIC}\\): Likelihood-based approach balancing model performance and complexity\n\\(\\color{#4187aa}{BIC}\\): Similar to AIC with stronger penalty for extra terms\n\n. . .\n\nNested F Test (extra sum of squares F test): Generalization of t-test for individual coefficients to perform significance tests on nested models"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#which-model-would-you-choose-1",
    "href": "slides/01-welcome_ch1_o.html#which-model-would-you-choose-1",
    "title": "Welcome and Chapter 1",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\nUse the glance function to get model statistics.\n\nOutputCode\n\n\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\n\nmodel1_glance &lt;- glance(model1Cent) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\nmodel2_glance &lt;- glance(model2) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\nmodel3_glance &lt;- glance(model3) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\n\nmodel1_glance |&gt;\n  bind_rows(model2_glance) |&gt;\n  bind_rows(model3_glance) |&gt;\n  bind_cols(model = c(\"Model1\", \"Model2\", \"Model3\")) |&gt;\n  select(model, everything()) |&gt;\nkable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#characteristics-of-a-good-final-model",
    "href": "slides/01-welcome_ch1_o.html#characteristics-of-a-good-final-model",
    "title": "Welcome and Chapter 1",
    "section": "Characteristics of a ‚Äúgood‚Äù final model",
    "text": "Characteristics of a ‚Äúgood‚Äù final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nunnecessary terms are removed\nAssumptions are met and influential points have been addressed\nmodel tells a ‚Äúpersuasive story parsimoniously‚Äù\n\n\n\nList from Section 1.6.7 of BMLR"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#inference-for-multiple-linear-regression",
    "href": "slides/01-welcome_ch1_o.html#inference-for-multiple-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Inference for multiple linear regression",
    "text": "Inference for multiple linear regression\nUse statistical inference to\n\nDetermine if predictors are statistically significant (not necessarily practically significant!)\nQuantify uncertainty in coefficient estimates\nQuantify uncertainty in model predictions\n\n. . .\nIf L.I.N.E. assumptions are met, we can conduct inference using the \\(t\\) distribution and estimated standard errors"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#inference-for-regression",
    "href": "slides/01-welcome_ch1_o.html#inference-for-regression",
    "title": "Welcome and Chapter 1",
    "section": "Inference for regression",
    "text": "Inference for regression\n\nWhen L.I.N.E. conditions are metWe can\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse least squares regression to get the estimates \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), and \\(\\hat{\\sigma}^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\n. . .\n\\[\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1_o.html#acknowledgements",
    "href": "slides/01-welcome_ch1_o.html#acknowledgements",
    "title": "Welcome and Chapter 1",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#instructor",
    "href": "slides/01-welcome_ch1.html#instructor",
    "title": "Welcome and Chapter 1",
    "section": "Instructor",
    "text": "Instructor\n\nDr.¬†Tyler George: tgeorge@cornellcollege.edu"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#course-logistics",
    "href": "slides/01-welcome_ch1.html#course-logistics",
    "title": "Welcome and Chapter 1",
    "section": "Course logistics",
    "text": "Course logistics\n\nCourse Dates: August 26th to September 18th\nCourse sessions: M-F,9am-11am and 1pm-3pm\nExam Dates: September 6th and 18th"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#generalized-linear-models",
    "href": "slides/01-welcome_ch1.html#generalized-linear-models",
    "title": "Welcome and Chapter 1",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\nIn statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n\n\nLogistic regression\n\\[\\begin{aligned}\\pi = P(y = 1 | x) \\hspace{2mm} &\\Rightarrow \\hspace{2mm} \\text{Link function: } \\log\\big(\\frac{\\pi}{1-\\pi}\\big) \\\\\n&\\Rightarrow \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~x\\end{aligned}\\]\n\n\nWikipedia"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-were-covering-this-semester13",
    "href": "slides/01-welcome_ch1.html#what-were-covering-this-semester13",
    "title": "Welcome and Chapter 1",
    "section": "What we‚Äôre covering this semester(1/3)",
    "text": "What we‚Äôre covering this semester(1/3)\nGeneralized Linear Models (Ch 1 - 6)\n\nIntroduce models for non-normal response variables\nEstimation, interpretation, and inference\nMathematical details showing how GLMs are connected"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-were-covering-this-semester23",
    "href": "slides/01-welcome_ch1.html#what-were-covering-this-semester23",
    "title": "Welcome and Chapter 1",
    "section": "What we‚Äôre covering this semester(2/3)",
    "text": "What we‚Äôre covering this semester(2/3)\nModeling correlated data (Ch 7 - 9)\n\nIntroduce multilevel models for correlated and longitudinal data\nEstimation, interpretation, and inference\nMathematical details, particularly diving into covariance structures"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-were-covering-this-semester33",
    "href": "slides/01-welcome_ch1.html#what-were-covering-this-semester33",
    "title": "Welcome and Chapter 1",
    "section": "What we‚Äôre covering this semester(3/3)",
    "text": "What we‚Äôre covering this semester(3/3)\nMore Regression Models (ITSL Chapter 7) - Polynomial Regression - Regression Splines - Smoothing Splines - Generalized Additive Models (GAMS)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#meet-your-classmates",
    "href": "slides/01-welcome_ch1.html#meet-your-classmates",
    "title": "Welcome and Chapter 1",
    "section": "Meet your classmates!",
    "text": "Meet your classmates!\n\nCreate larger groups\nQuick introductions - Name, year, and major\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to December 1st.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Cornell Student\nNot clothes (we‚Äôre all wearing socks)\nNot body parts (we all have a nose)\n\n\n\nReporter will share list with the class"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-background-is-assumed-for-the-course",
    "href": "slides/01-welcome_ch1.html#what-background-is-assumed-for-the-course",
    "title": "Welcome and Chapter 1",
    "section": "What background is assumed for the course?",
    "text": "What background is assumed for the course?\n\nPre-reqs\n\nSTA 201, 202 and DSC 223\n\n\n\nBackground knowledge\n\n\n\nStatistical content\n\nLinear and logistic regression\nStatistical inference\nBasic understanding of random variables\n\n\n\n\nComputing\n\nUsing R for data analysis\nWriting reports using R Markdown or Quarto"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#course-toolkit-12",
    "href": "slides/01-welcome_ch1.html#course-toolkit-12",
    "title": "Welcome and Chapter 1",
    "section": "Course Toolkit (1/2)",
    "text": "Course Toolkit (1/2)\n\nWebsite\n\nhttps://stats-tgeorge.github.io/STA363_AdvReg/\nCentral hub for the course\nNotes\nLabs\nDatasets"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#course-toolkit-12-1",
    "href": "slides/01-welcome_ch1.html#course-toolkit-12-1",
    "title": "Welcome and Chapter 1",
    "section": "Course Toolkit (1/2)",
    "text": "Course Toolkit (1/2)\n\nMoodle:\n\nhttps://moodle.cornellcollege.edu/course/view.php?id=7908\nSubmissions\nGradebook\nAnnouncements"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#class-meetings",
    "href": "slides/01-welcome_ch1.html#class-meetings",
    "title": "Welcome and Chapter 1",
    "section": "Class Meetings",
    "text": "Class Meetings\nLectures\n\nSome traditional lecture\nIndividual and group labs\nBring fully-charged laptop\nMini-projects\nExams\n\n\nAttendance is expected (if you are healthy!)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#textbook",
    "href": "slides/01-welcome_ch1.html#textbook",
    "title": "Welcome and Chapter 1",
    "section": "Textbook",
    "text": "Textbook\n\n\n\n\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler\n\nAvailable online\nHard copies available for purchase"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#textbook-2",
    "href": "slides/01-welcome_ch1.html#textbook-2",
    "title": "Welcome and Chapter 1",
    "section": "Textbook 2",
    "text": "Textbook 2\nThe secondary text is: An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani ‚Äì it is freely available online. Chapter 7.\n\nHard copies available for purchase"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#using-r-rstudio",
    "href": "slides/01-welcome_ch1.html#using-r-rstudio",
    "title": "Welcome and Chapter 1",
    "section": "Using R / RStudio",
    "text": "Using R / RStudio\n\nRStudio Server is installed and should be used\nhttp://turing.cornellcollege.edu:8787/"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#activities-assessments",
    "href": "slides/01-welcome_ch1.html#activities-assessments",
    "title": "Welcome and Chapter 1",
    "section": "Activities & Assessments",
    "text": "Activities & Assessments\nReadings\n\nPrimarily from Beyond Multiple Linear Regression\nRecommend reading assigned text before lecture\n\n\nHomework - Primarily from Beyond Multiple Linear Regression - Individual assignments - Work together but must complete your own work. Discuss but don‚Äôt copy."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#activities-assessments-1",
    "href": "slides/01-welcome_ch1.html#activities-assessments-1",
    "title": "Welcome and Chapter 1",
    "section": "Activities & Assessments",
    "text": "Activities & Assessments\nMini-projects\nExamples:\n\nMini-project 01: Focused on models for non-normal response variables, such as count data\nMini-project 02: Focused on models for correlated data\n\n\n\nShort write up and short presentation\nTeam-based"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#exams",
    "href": "slides/01-welcome_ch1.html#exams",
    "title": "Welcome and Chapter 1",
    "section": "Exams",
    "text": "Exams\n\nTwo exams this block, September 6th and 18th.\nEach will have two components\n\nComponent 1 will be on these dates and you will get a choice of oral or written format.\nComponent 2 will be a take-home, open-book, open-note, exam.\nYou will have 12 hours or more to complete this component."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#grading",
    "href": "slides/01-welcome_ch1.html#grading",
    "title": "Welcome and Chapter 1",
    "section": "Grading",
    "text": "Grading\nFinal grades will be calculated as follows\n\n\n\nCategory\nPoints\n\n\n\n\nHomework\n200\n\n\nParticipation\n100\n\n\nLabs and Mini Projects\n300\n\n\nExams\n400\n\n\nTotal\n1000\n\n\n\nSee Syllabus on website for letter grade thresholds."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#resources",
    "href": "slides/01-welcome_ch1.html#resources",
    "title": "Welcome and Chapter 1",
    "section": "Resources",
    "text": "Resources\n\nOffice hours to meet with your instructor in West 311\n\nTypically MWTh 3:05pm-4:05pm and by appt.\nDouble check course calendar\nMake appointments by going to https://calendar.app.google/Li1dftFBXqzRnaX69\n\nEmail Tyler George for private questions regarding personal matters or grades.\n\nPlease put STA 363 in the subject line since I am also teaching capstone this semester\n\nCollege support at https://stats-tgeorge.github.io/personal_website/course-support.html."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#setup---r-packages",
    "href": "slides/01-welcome_ch1.html#setup---r-packages",
    "title": "Welcome and Chapter 1",
    "section": "Setup - R Packages",
    "text": "Setup - R Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#assumptions-for-linear-regression",
    "href": "slides/01-welcome_ch1.html#assumptions-for-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\nWhat are the assumptions for linear regression? . . .\nLinearity: Linear relationship between mean response and predictor variable(s)\n\nIndependence: Residuals are independent. There is no connection between how far any two points lie above or below regression line.\n\n\nNormality: Response follows a normal distribution at each level of the predictor (or combination of predictors)\n\n\nEqual variance: Variability (variance or standard deviation) of the response is equal for all levels of the predictor (or combination of predictors)\n\n\nUse residual plots to check that the conditions hold before using the model for statistical inference."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#assumptions-for-linear-regression-1",
    "href": "slides/01-welcome_ch1.html#assumptions-for-linear-regression-1",
    "title": "Welcome and Chapter 1",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinearity: Linear relationship between mean of the response \\(Y\\) and the predictor \\(X\\)\nIndependence: No connection between how any two points lie above or below the regression line\nNormality: Response, \\(Y\\), follows a normal distribution at each level of the predictor, \\(X\\) (indicated by red curves)\nEqual variance: Variance (or standard deviation) of the response, \\(Y\\), is equal for all levels of the predictor, \\(X\\)\n\n\n\n\nModified from Figure 1.1. in BMLR]"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#questions",
    "href": "slides/01-welcome_ch1.html#questions",
    "title": "Welcome and Chapter 1",
    "section": "Questions",
    "text": "Questions\nHow do we assess these conditions?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#beyond-linear-regression",
    "href": "slides/01-welcome_ch1.html#beyond-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Beyond linear regression",
    "text": "Beyond linear regression\n\nWhen we use linear least squares regression to draw conclusions, we do so under the assumption that L.I.N.E. are all met.\nGeneralized linear models require different assumptions and can accommodate violations in L.I.N.E.\n\nRelationship between response and predictor(s) can be nonlinear\nResponse variable can be non-normal\nVariance in response can differ at each level of predictor(s)\n\n\n\nBut the independence assumption must hold!\n\nMultilevel models will be used for data with correlated observations"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#review-of-multiple-linear-regression",
    "href": "slides/01-welcome_ch1.html#review-of-multiple-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Review of multiple linear regression",
    "text": "Review of multiple linear regression"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#data-kentucky-derby-winners",
    "href": "slides/01-welcome_ch1.html#data-kentucky-derby-winners",
    "title": "Welcome and Chapter 1",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\nToday‚Äôs data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017.\n\n\n\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)]\n\nAdditional variable\n\nwinner: Winning horse\n\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced]"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#data",
    "href": "slides/01-welcome_ch1.html#data",
    "title": "Welcome and Chapter 1",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")\n\n\nderby |&gt;\n  head(5) |&gt; kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n\n\n1898\nPlaudit\ngood\n51.16\n4\n\n\n1899\nManuel\nfast\n50.00\n5\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#data-analysis-life-cycle",
    "href": "slides/01-welcome_ch1.html#data-analysis-life-cycle",
    "title": "Welcome and Chapter 1",
    "section": "Data Analysis Life Cycle",
    "text": "Data Analysis Life Cycle"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#exploratory-data-analysis-eda",
    "href": "slides/01-welcome_ch1.html#exploratory-data-analysis-eda",
    "title": "Welcome and Chapter 1",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\n\nOnce you‚Äôre ready for the statistical analysis (explore), the first step should always be exploratory data analysis.\nThe EDA will help you\n\nbegin to understand the variables and observations\nidentify outliers or potential data entry errors\nbegin to see relationships between variables\nidentify the appropriate model and identify a strategy\n\nThe EDA is exploratory; formal modeling and statistical inference should be used to draw conclusions."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#plots-for-univariate-eda",
    "href": "slides/01-welcome_ch1.html#plots-for-univariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for univariate EDA",
    "text": "Plots for univariate EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = derby, aes(x = speed)) + \n  geom_histogram(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Winning speed (ft/s)\", y = \"Count\")\n\np2 &lt;- ggplot(data = derby, aes(x = starters)) + \n  geom_histogram(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Starters\", y = \"Count\")\n\np3 &lt;- ggplot(data = derby, aes(x = condition)) +\n   geom_bar(fill = \"forestgreen\", color = \"black\", aes(x = ))\n\np1 + (p2 / p3) + \n  plot_annotation(title = \"Univariate data analysis\")"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#plots-for-bivariate-eda",
    "href": "slides/01-welcome_ch1.html#plots-for-bivariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for bivariate EDA",
    "text": "Plots for bivariate EDA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np4 &lt;- ggplot(data = derby, aes(x = starters, y = speed)) + \n  geom_point() + \n  labs(x = \"Starters\", y = \"Speed (ft / s)\")\n\np5 &lt;- ggplot(data = derby, aes(x = year, y = speed)) + \n  geom_point() + \n  labs(x = \"Year\", y = \"Speed (ft / s)\")\n\np6 &lt;- ggplot(data = derby, aes(x = condition, y = speed)) + \n  geom_boxplot(fill = \"forestgreen\", color = \"black\") + \n  labs(x = \"Conditions\", y = \"Speed (ft / s)\")\n\n(p4 + p5) + p6 +\n  plot_annotation(title = \"Bivariate data analysis\")"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#scatterplot-matrix",
    "href": "slides/01-welcome_ch1.html#scatterplot-matrix",
    "title": "Welcome and Chapter 1",
    "section": "Scatterplot matrix",
    "text": "Scatterplot matrix\nA scatterplot matrix helps quickly visualize relationships between many variable pairs. They are particularly useful to identify potentially correlated predictors.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#library(GGally)\nggpairs(data = derby, \n        columns = c(\"condition\", \"year\", \"starters\", \"speed\"))"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#plots-for-multivariate-eda",
    "href": "slides/01-welcome_ch1.html#plots-for-multivariate-eda",
    "title": "Welcome and Chapter 1",
    "section": "Plots for multivariate EDA",
    "text": "Plots for multivariate EDA\nPlot the relationship between the response and a predictor based on levels of another predictor to assess potential interactions.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#library(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-1-main-effects-model",
    "href": "slides/01-welcome_ch1.html#model-1-main-effects-model",
    "title": "Welcome and Chapter 1",
    "section": "Model 1: Main effects model",
    "text": "Model 1: Main effects model\n\nOutputCode\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\n\n# Fit and display model\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\ntidy(model1) |&gt; \n  kable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#interpretation",
    "href": "slides/01-welcome_ch1.html#interpretation",
    "title": "Welcome and Chapter 1",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\\widehat{speed} = 8.197 - 0.005 ~ starters + 0.023 ~ year - 0.443 ~ good - 1.543 ~ slow\\]\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\nWrite out the interpretations for starters and conditiongood.\nDoes the intercept have a meaningful interpretation?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#centering",
    "href": "slides/01-welcome_ch1.html#centering",
    "title": "Welcome and Chapter 1",
    "section": "Centering",
    "text": "Centering\nCentering: Subtract a constant from each observation of a given variable\n\nDo this to make interpretation of model parameters more meaningful (particularly intercept)\nIn STA 202, we used mean-centering where we subtracted the mean from each observation of given variable\nHow does centering change the model?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#centering-year",
    "href": "slides/01-welcome_ch1.html#centering-year",
    "title": "Welcome and Chapter 1",
    "section": "Centering year",
    "text": "Centering year\n\nderby &lt;- derby |&gt;\n  mutate(yearnew = year - 1896) #1896 = starting year\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.175\n0.194\n269.079\n0.000\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyearnew\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\n\\[\\widehat{speed} = 52.175 - 0.005 ~ starters + 0.023 ~ yearnew - 0.443 ~ good - 1.543 ~ slow\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-1-check-model-assumptions",
    "href": "slides/01-welcome_ch1.html#model-1-check-model-assumptions",
    "title": "Welcome and Chapter 1",
    "section": "Model 1: Check model assumptions",
    "text": "Model 1: Check model assumptions\n\nPlotsQuestions\n\n\n\n#library(ggfortify)\nautoplot(model1Cent)\n\n\n\n\n\n\n\n\n\n\nWhich of the model assumptions (LINE) does this pass and/or fail?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-2-add-quadratic-effect-for-year",
    "href": "slides/01-welcome_ch1.html#model-2-add-quadratic-effect-for-year",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Add quadratic effect for year?",
    "text": "Model 2: Add quadratic effect for year?\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = derby, aes(x = yearnew, y = speed)) + \n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") + \n  geom_smooth(se = FALSE, color = \"red\", linetype = 2) + \n  labs(x = \"Years since 1896\", y = \"Speed (ft/s)\", \n       title = \"Speed vs. Years since 1896\")"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-2-add-yearnew2",
    "href": "slides/01-welcome_ch1.html#model-2-add-yearnew2",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Add \\(yearnew^2\\)",
    "text": "Model 2: Add \\(yearnew^2\\)\n\nPlotCode\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n51.4130\n0.1826\n281.5645\n0.0000\n\n\nstarters\n-0.0253\n0.0136\n-1.8588\n0.0656\n\n\nyearnew\n0.0700\n0.0061\n11.4239\n0.0000\n\n\nI(yearnew^2)\n-0.0004\n0.0000\n-8.0411\n0.0000\n\n\nconditiongood\n-0.4770\n0.1857\n-2.5689\n0.0115\n\n\nconditionslow\n-1.3927\n0.1305\n-10.6701\n0.0000\n\n\n\n\n\n\n\n\nmodel2 &lt;- lm(speed ~ starters + yearnew + I(yearnew^2) + condition, \n             data = derby)\ntidy(model2) |&gt; kable(digits = 4)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#interpreting-quadratic-effects",
    "href": "slides/01-welcome_ch1.html#interpreting-quadratic-effects",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting quadratic effects",
    "text": "Interpreting quadratic effects\n\\[\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x_1  + \\hat{\\beta}_2 ~ x_2 + \\hat{\\beta}_3 ~ x_2^2\\]\nGeneral interpretation: When \\(x_2\\) increases from a to b, \\(y\\) is expected to change by \\(\\hat{\\beta}_2(b - a) + \\hat{\\beta}_3(b^2 - a^2)\\), holding \\(x_1\\) constant."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#interpreting-quadratic-effects-1",
    "href": "slides/01-welcome_ch1.html#interpreting-quadratic-effects-1",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting quadratic effects",
    "text": "Interpreting quadratic effects\n\\[\\begin{aligned}\\widehat{speed} = &51.413 - 0.025 ~ starters + 0.070 ~ yearnew \\\\\n& - 0.0004 ~ yearnew^2 - 0.477 ~ good - 1.393 ~ slow\\end{aligned}\\]\n\nQuestions:\nInterpret the effect of year for the 5 most recent years (2013 - 2017)."
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-2-check-model-assumptions",
    "href": "slides/01-welcome_ch1.html#model-2-check-model-assumptions",
    "title": "Welcome and Chapter 1",
    "section": "Model 2: Check model assumptions",
    "text": "Model 2: Check model assumptions"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-3-include-interaction-term",
    "href": "slides/01-welcome_ch1.html#model-3-include-interaction-term",
    "title": "Welcome and Chapter 1",
    "section": "Model 3: Include interaction term?",
    "text": "Model 3: Include interaction term?\nRecall from the EDA‚Ä¶\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#model-3-add-interaction-term",
    "href": "slides/01-welcome_ch1.html#model-3-add-interaction-term",
    "title": "Welcome and Chapter 1",
    "section": "Model 3: Add interaction term",
    "text": "Model 3: Add interaction term\n\\[\\begin{aligned}\\widehat{speed} = & 52.387 - 0.003 ~ starters + 0.020 ~ yearnew - 1.070 ~ good - 2.183 ~ slow \\\\ &+0.012 ~ yearnew \\times good + 0.012 ~ yearnew \\times slow \\end{aligned}\\]\n\nOutputCodeAssumptions\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n\n\n\nmodel3 &lt;- lm(speed ~ starters + yearnew + condition +\n               yearnew * condition, \n             data = derby)\ntidy(model3) |&gt; kable(digits = 4)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#interpreting-interaction-effects",
    "href": "slides/01-welcome_ch1.html#interpreting-interaction-effects",
    "title": "Welcome and Chapter 1",
    "section": "Interpreting interaction effects",
    "text": "Interpreting interaction effects\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n\nWrite out the interpretation of‚Ä¶"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#which-model-would-you-choose",
    "href": "slides/01-welcome_ch1.html#which-model-would-you-choose",
    "title": "Welcome and Chapter 1",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\n\nModel 1: Main effectsModel 2: Main effects + \\(year^2\\)Model 3: Main effects + interactionCode\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.73\n0.721\n259.478\n276.302\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.827\n0.819\n207.429\n227.057\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\n\n# Model 1\nglance(model1Cent) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)\n\n# Model2\nglance(model2) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)\n\n# Model 3\nglance(model3) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC) |&gt;\n  kable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#what-are-these-model-quality-metrics",
    "href": "slides/01-welcome_ch1.html#what-are-these-model-quality-metrics",
    "title": "Welcome and Chapter 1",
    "section": "What are these model quality metrics?",
    "text": "What are these model quality metrics?\n\nHow do we define RSquared?\nWhat is adj.r.squared?"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#measures-of-model-performance",
    "href": "slides/01-welcome_ch1.html#measures-of-model-performance",
    "title": "Welcome and Chapter 1",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(\\color{#4187aa}{R^2}\\): Proportion of variability in the response explained by the model.\n\nWill always increase as predictors are added, so it shouldn‚Äôt be used to compare models\n\n\\(\\color{#4187aa}{Adj. R^2}\\): Similar to \\(R^2\\) with a penalty for extra terms\n\n\n\n\\(\\color{#4187aa}{AIC}\\): Likelihood-based approach balancing model performance and complexity\n\\(\\color{#4187aa}{BIC}\\): Similar to AIC with stronger penalty for extra terms\n\n\n\n\nNested F Test (extra sum of squares F test): Generalization of t-test for individual coefficients to perform significance tests on nested models"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#which-model-would-you-choose-1",
    "href": "slides/01-welcome_ch1.html#which-model-would-you-choose-1",
    "title": "Welcome and Chapter 1",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\nUse the glance function to get model statistics.\n\nOutputCode\n\n\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\n\nmodel1_glance &lt;- glance(model1Cent) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\nmodel2_glance &lt;- glance(model2) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\nmodel3_glance &lt;- glance(model3) |&gt;\n  select(r.squared, adj.r.squared, AIC, BIC)\n\nmodel1_glance |&gt;\n  bind_rows(model2_glance) |&gt;\n  bind_rows(model3_glance) |&gt;\n  bind_cols(model = c(\"Model1\", \"Model2\", \"Model3\")) |&gt;\n  select(model, everything()) |&gt;\nkable(digits = 3)"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#characteristics-of-a-good-final-model",
    "href": "slides/01-welcome_ch1.html#characteristics-of-a-good-final-model",
    "title": "Welcome and Chapter 1",
    "section": "Characteristics of a ‚Äúgood‚Äù final model",
    "text": "Characteristics of a ‚Äúgood‚Äù final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nunnecessary terms are removed\nAssumptions are met and influential points have been addressed\nmodel tells a ‚Äúpersuasive story parsimoniously‚Äù\n\n\n\nList from Section 1.6.7 of BMLR"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#inference-for-multiple-linear-regression",
    "href": "slides/01-welcome_ch1.html#inference-for-multiple-linear-regression",
    "title": "Welcome and Chapter 1",
    "section": "Inference for multiple linear regression",
    "text": "Inference for multiple linear regression\nUse statistical inference to\n\nDetermine if predictors are statistically significant (not necessarily practically significant!)\nQuantify uncertainty in coefficient estimates\nQuantify uncertainty in model predictions\n\n\nIf L.I.N.E. assumptions are met, we can conduct inference using the \\(t\\) distribution and estimated standard errors"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#inference-for-regression",
    "href": "slides/01-welcome_ch1.html#inference-for-regression",
    "title": "Welcome and Chapter 1",
    "section": "Inference for regression",
    "text": "Inference for regression\n\nWhen L.I.N.E. conditions are metWe can\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse least squares regression to get the estimates \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), and \\(\\hat{\\sigma}^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\n. . .\n\\[\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\\]"
  },
  {
    "objectID": "slides/01-welcome_ch1.html#acknowledgements",
    "href": "slides/01-welcome_ch1.html#acknowledgements",
    "title": "Welcome and Chapter 1",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html",
    "href": "slides/03_distribution_ch3_o.html",
    "title": "Distribution Theory",
    "section": "",
    "text": "Write definitions of non-normal random variables in the context of an application.\nIdentify possible values for each random variable.\nIdentify how changing values for a parameter affects the characteristics of the distribution.\nRecognize a form of the probability density function for each distribution.\nIdentify the mean and variance for each distribution.\nMatch the response for a study to a plausible random variable and provide reasons for ruling out other random variables.\nMatch a histogram of sample data to plausible distributions.\nCreate a mixture of distributions and evaluate the shape, mean, and variance."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#learning-objectives",
    "href": "slides/03_distribution_ch3_o.html#learning-objectives",
    "title": "Distribution Theory",
    "section": "",
    "text": "Write definitions of non-normal random variables in the context of an application.\nIdentify possible values for each random variable.\nIdentify how changing values for a parameter affects the characteristics of the distribution.\nRecognize a form of the probability density function for each distribution.\nIdentify the mean and variance for each distribution.\nMatch the response for a study to a plausible random variable and provide reasons for ruling out other random variables.\nMatch a histogram of sample data to plausible distributions.\nCreate a mixture of distributions and evaluate the shape, mean, and variance."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#libraries-needed-none-new",
    "href": "slides/03_distribution_ch3_o.html#libraries-needed-none-new",
    "title": "Distribution Theory",
    "section": "Libraries Needed (none new?)",
    "text": "Libraries Needed (none new?)\n\n# Packages required for Chapter 3\nlibrary(gridExtra)  \nlibrary(knitr) \nlibrary(kableExtra)\nlibrary(tidyverse)"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#introduction",
    "href": "slides/03_distribution_ch3_o.html#introduction",
    "title": "Distribution Theory",
    "section": "Introduction",
    "text": "Introduction\n\nWhat if it is not plausible that a response is normally distributed?\nYou may want to construct a model to predict whether a prospective student will enroll at a school or model the lifetimes of patients following a particular surgery.\n\nIn the first case you have a binary response (enrolls (1) or does not enroll (0)), and in the second case you are likely to have very skewed data with many similar values and a few hardy souls with extremely long survival.\nThese responses are not expected to be normally distributed; other distributions will be needed to describe and model binary or lifetime data.\nNon-normal responses are encountered in a large number of situations. Luckily, there are quite a few possibilities for models."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#discrete-random-variables-1",
    "href": "slides/03_distribution_ch3_o.html#discrete-random-variables-1",
    "title": "Distribution Theory",
    "section": "Discrete Random Variables",
    "text": "Discrete Random Variables\n\nA discrete random variable has a countable number of possible values\n\nEx: we may want to measure the number of people in a household\nEx: model the number of crimes committed on a college campus.\n\nWith discrete random variables, the associated probabilities can be calculated for each possible value using a probability mass function (pmf). \nA pmf is a function that calculates \\(P(Y=y)\\), given each variable‚Äôs parameters."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#binary-random-variable",
    "href": "slides/03_distribution_ch3_o.html#binary-random-variable",
    "title": "Distribution Theory",
    "section": "Binary Random Variable",
    "text": "Binary Random Variable\n\nConsider the event of flipping a (possibly unfair) coin.\nIf the coin lands heads, let‚Äôs consider this a success and record \\(Y = 1\\).\nA series of these events is a Bernoulli process, independent trials that take on one of two values (e.g., 0 or 1).\nThese values are often referred to as a failure and a success\n\nthe probability of success is identical for each trial."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#binary-random-variable-1",
    "href": "slides/03_distribution_ch3_o.html#binary-random-variable-1",
    "title": "Distribution Theory",
    "section": "Binary Random Variable",
    "text": "Binary Random Variable\n\nSuppose we only flip the coin once, so we only have one parameter, the probability of flipping heads, \\(p\\).\nIf we know this value, we can express \\(P(Y=1) = p\\) and \\(P(Y=0) = 1-p\\).\nIn general, if we have a Bernoulli process with only one trial, we have a binary distribution (also called a Bernoulli distribution) where\n\n. . .\n\\[\\begin{equation*}\nP(Y = y) = p^y(1-p)^{1-y} \\quad \\textrm{for} \\quad y = 0, 1.\n\\end{equation*}\\]\n\nIf \\(Y \\sim \\textrm{Binary}(p)\\), then \\(Y\\) has mean \\(\\operatorname{E}(Y) = p\\) and standard deviation \\(\\operatorname{SD}(Y) = \\sqrt{p(1-p)}\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#example-1",
    "href": "slides/03_distribution_ch3_o.html#example-1",
    "title": "Distribution Theory",
    "section": "Example 1",
    "text": "Example 1\n\nYour playlist of 200 songs has 5 which you cannot stand. What is the probability that when you hit shuffle, a song you tolerate comes on?\nWe want to understand the example and be able to translate that into notation/model it with a distribution\nAssuming all songs have equal odds of playing, we can calculate \\(p = \\frac{200-5}{200} = 0.975\\)\n\nso there is a 97.5% chance of a song you tolerate playing, since \\(P(Y=1)=.975^1*(1-.975)^0\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#binomial-random-variable-12",
    "href": "slides/03_distribution_ch3_o.html#binomial-random-variable-12",
    "title": "Distribution Theory",
    "section": "Binomial Random Variable (1/2)",
    "text": "Binomial Random Variable (1/2)\n\nDoes anybody know how this relates to a Bernoulli random variable?\nWe can extend our knowledge of binary random variables.\nSuppose we flipped an unfair coin \\(n\\) times and recorded \\(Y\\), the number of heads after \\(n\\) flips.\nIf we consider a case where \\(p = 0.25\\) and \\(n = 4\\), then here \\(P(Y=0)\\) represents the probability of no successes in 4 trials\n\n4 consecutive failures.\nThe probability of 4 consecutive failures is \\(P(Y = 0) = P(TTTT) = (1-p)^4 = 0.75^4\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#binomial-random-variable-22",
    "href": "slides/03_distribution_ch3_o.html#binomial-random-variable-22",
    "title": "Distribution Theory",
    "section": "Binomial Random Variable (2/2)",
    "text": "Binomial Random Variable (2/2)\n\nNext we consider \\(P(Y = 1)\\), and are interested in the probability of exactly 1 success anywhere among the 4 trials.\nHow many different ways can we get exactly 1 success in the four trials?\nTo find the probability of this what else do we need to count?\nWhat is the probability?\nThere are \\(\\binom{4}{1} = 4\\) ways to have exactly 1 success in 4 trials, \\(P(Y = 1) = \\binom{4}{1}p^1(1-p)^{4-1} = (4)(0.25)(0.75)^3\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#binomial-distribution",
    "href": "slides/03_distribution_ch3_o.html#binomial-distribution",
    "title": "Distribution Theory",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nIn general, if we carry out a sequence of \\(n\\) Bernoulli trials (with probability of success \\(p\\)) and record \\(Y\\), the total number of successes, then \\(Y\\) follows a binomial distribution, where\n\n. . .\n\\[\\begin{equation}\nP(Y=y) = \\binom{n}{y} p^y (1-p)^{n-y} \\quad \\textrm{for} \\quad y = 0, 1, \\ldots, n.\n\\end{equation}\\]\n. . .\n\nIf \\(Y \\sim \\textrm{Binomial}(n,p)\\), then \\(\\operatorname{E}(Y) = np\\) and \\(\\operatorname{SD}(Y) = \\sqrt{np(1-p)}\\).\n\\(E(y)\\) is the expected value of \\(Y\\). If we repeated the experiment many times we would expect on average \\(n*p\\) successes."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#binomial-distribution-graphs",
    "href": "slides/03_distribution_ch3_o.html#binomial-distribution-graphs",
    "title": "Distribution Theory",
    "section": "Binomial Distribution Graphs",
    "text": "Binomial Distribution Graphs\n\nTypical shapes of a binomial distribution\nI will show you these in R"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#binomial-distribution-graphs-1",
    "href": "slides/03_distribution_ch3_o.html#binomial-distribution-graphs-1",
    "title": "Distribution Theory",
    "section": "Binomial Distribution Graphs",
    "text": "Binomial Distribution Graphs\n\nOn the left side \\(n\\) remains constant.\nWe see that as \\(p\\) increases, the center of the distribution (\\(\\operatorname{E}(Y) = np\\)) shifts right.\nOn the right, \\(p\\) is held constant.\nAs \\(n\\) increases, the distribution becomes less skewed."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#binomial-distribution-vs-bernoulli",
    "href": "slides/03_distribution_ch3_o.html#binomial-distribution-vs-bernoulli",
    "title": "Distribution Theory",
    "section": "Binomial Distribution vs Bernoulli",
    "text": "Binomial Distribution vs Bernoulli\n\nNote that if \\(n=1\\),\n\n. . .\n\\[\\begin{align*}\nP(Y=y) &= \\binom{1}{y} p^y(1-p)^{1-y} \\\\\n        &= p^y(1-p)^{1-y}\\quad \\textrm{for}\\quad y = 0, 1,\n\\end{align*}\\] a Bernoulli distribution! - In fact, Bernoulli random variables are a special case of binomial random variables where \\(n=1\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#graphingcalling-in-r",
    "href": "slides/03_distribution_ch3_o.html#graphingcalling-in-r",
    "title": "Distribution Theory",
    "section": "Graphing/calling in R",
    "text": "Graphing/calling in R\n\nIn R we can use the function dbinom(y, n, p), which outputs the probability of \\(y\\) successes given \\(n\\) trials with probability \\(p\\), i.e., \\(P(Y=y)\\) for \\(Y \\sim \\textrm{Binomial}(n,p)\\).\nLets try it"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#example-2-12",
    "href": "slides/03_distribution_ch3_o.html#example-2-12",
    "title": "Distribution Theory",
    "section": "Example 2 (1/2)",
    "text": "Example 2 (1/2)\n\nWhile taking a multiple choice test, a student encountered 10 problems where she ended up completely guessing, randomly selecting one of the four options.\nWhat is the chance that she got exactly 2 of the 10 correct?\nWhat assumption do we need to make about the questions?\nHow would we do this without using a distribution?"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#example-2-22",
    "href": "slides/03_distribution_ch3_o.html#example-2-22",
    "title": "Distribution Theory",
    "section": "Example 2 (2/2)",
    "text": "Example 2 (2/2)\n\nKnowing that the student randomly selected her answers, we assume she has a 25% chance of a correct response.\nn factorial is denoted \\(n!\\) and \\(n!=n\\cdot(n-1)\\cdot...\\cdot 3\\cdot 2\\cdot 1\\)\nHere we used a combination \\({n \\choose p}=\\frac{n!}{p!(n-p)!}\\) read n choose p\nThus, \\(P(Y=2) = {10 \\choose 2}(.25)^2(.75)^8 = 0.282\\).\n\n. . .\n\nWe can use R to verify this:\n\n. . .\n\ndbinom(2, size = 10, prob = .25)\n\n[1] 0.2815676\n\n\nTherefore, there is a 28% chance of exactly 2 correct answers out of 10."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#negative-binomial-random-variable",
    "href": "slides/03_distribution_ch3_o.html#negative-binomial-random-variable",
    "title": "Distribution Theory",
    "section": "Negative Binomial Random Variable",
    "text": "Negative Binomial Random Variable\n\nWhat if we were to carry out multiple independent and identical Bernoulli trails until the \\(r\\)th success occurs?\nIf we model \\(Y\\), the number of failures before the \\(r\\)th success, then \\(Y\\) follows a negative binomial distribution where\n\n. . .\n\\[\\begin{equation}\nP(Y=y) = \\binom{y + r - 1}{r-1} (1-p)^{y}(p)^r \\quad \\textrm{for}\\quad y = 0, 1, \\ldots, \\infty.\n\\end{equation}\\]"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#negative-binomial-rv",
    "href": "slides/03_distribution_ch3_o.html#negative-binomial-rv",
    "title": "Distribution Theory",
    "section": "Negative Binomial RV",
    "text": "Negative Binomial RV\n\nIf \\(Y \\sim \\textrm{Negative Binomial}(r, p)\\) then \\(\\operatorname{E}(Y) = \\frac{r(1-p)}{p}\\) and \\(\\operatorname{SD}(Y) = \\sqrt{\\frac{r(1-p)}{p^2}}\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#negative-binomial-rv-1",
    "href": "slides/03_distribution_ch3_o.html#negative-binomial-rv-1",
    "title": "Distribution Theory",
    "section": "Negative Binomial RV",
    "text": "Negative Binomial RV\n\nPlotCode\n\n\n\n\n\n\n\nNegative Binomial\n\n\n\n\n\nNotice how centers shift right as \\(r\\) increases, and left as \\(p\\) increases.\n\n\n\n\n#negativeBinomialPlots\nplotNBinom &lt;- function(p, r){\n  ynb &lt;- 0:10000\n  nbd &lt;- tibble(x = rnbinom(ynb, r, p))\n  #breaks &lt;- pretty(range(nbd$x), n = nclass.FD(nbd$x), min.n = 1)  # pretty binning\n  #bwidth &lt;- breaks[2] - breaks[1]\n  ggplot(nbd, aes(x = x)) +\n    geom_histogram(aes(y=..count../sum(..count..)), binwidth = .25) +\n    labs(title = paste(\"p = \", p, \", r = \", r),\n         x = \"number of failures\",\n         y = \"probability\") +\n    xlim(-1,30)\n}\n\nNBin1 &lt;- plotNBinom(0.35, 3)\nNBin2 &lt;- plotNBinom(0.35, 5)\nNBin3 &lt;- plotNBinom(0.70, 5)\ngrid.arrange(NBin1, NBin2, NBin3, ncol = 1)"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#negative-binomial-rv-2",
    "href": "slides/03_distribution_ch3_o.html#negative-binomial-rv-2",
    "title": "Distribution Theory",
    "section": "Negative Binomial RV",
    "text": "Negative Binomial RV\n\nNote that if we set \\(r=1\\), then\n\n. . .\n\\[\\begin{align*}\nP(Y=y) &= \\binom{y}{0} (1-p)^yp \\\\\n        &= (1-p)^yp \\quad \\textrm{for} \\quad y = 0, 1, \\ldots, \\infty,\n\\end{align*}\\] which is the probability mass function of a geometric random variable!\n\nThus, a geometric random variable is, in fact, a special case of a negative binomial random variable.\nWhile negative binomial random variables typically are expressed as above using binomial coefficients (expressions such as \\(\\binom{x}{y}\\)), we can generalize our definition to allow non-integer values of \\(r\\).\nR function dnbinom(y, r, p) for the probability of \\(y\\) failures before the \\(r\\)th success given probability \\(p\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#poisson-random-variable",
    "href": "slides/03_distribution_ch3_o.html#poisson-random-variable",
    "title": "Distribution Theory",
    "section": "Poisson Random Variable",
    "text": "Poisson Random Variable\n\nSometimes, random variables are based on a Poisson process. \nIn a Poisson process, we are counting the number of events per unit of time or space and the number of events depends only on the length or size of the interval.\nWe can then model \\(Y\\), the number of events in one of these sections with the Poisson distribution, where\n\n. . .\n\\[\\begin{equation}\nP(Y=y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\quad \\textrm{for} \\quad y = 0, 1, \\ldots, \\infty,\n\\end{equation}\\] where \\(\\lambda\\) is the mean or expected count in the unit of time or space of interest. - This probability mass function has \\(\\operatorname{E}(Y) = \\lambda\\) and \\(\\operatorname{SD}(Y) = \\sqrt{\\lambda}\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#poisson-distribution-graphs",
    "href": "slides/03_distribution_ch3_o.html#poisson-distribution-graphs",
    "title": "Distribution Theory",
    "section": "Poisson Distribution Graphs",
    "text": "Poisson Distribution Graphs\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\nNotice how distributions become more symmetric as \\(\\lambda\\) increases.\nIf we wish to use R, dpois(y, lambda) outputs the probability of \\(y\\) events given \\(\\lambda\\).\n\n\n\n\n#poissonPlots\nplotPois &lt;- function(lam){\nyp = 0:10000 # possible values\npd &lt;- data.frame(x=rpois(yp, lam))  # generate random deviates\nbreaks &lt;- pretty(range(pd$x), n = nclass.FD(pd$x), min.n = 1)  # pretty binning\n#bwidth &lt;- breaks[2] - breaks[1]\nggplot(pd, aes(x = x)) + geom_histogram(aes(y=..count../sum(..count..)), binwidth = .25) +\n  xlab(\"number of events\") + ylab(\"probability\") + \n  labs(title=paste(\"Poisson lambda = \", lam)) + xlim(-1,13)\n}\n\nPois1 &lt;- plotPois(0.5)\nPois2 &lt;- plotPois(1)\nPois3 &lt;- plotPois(5) + scale_y_continuous(breaks = c(0, 0.1))\ngrid.arrange(Pois1,Pois2,Pois3,ncol=1)"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#continuous-random-variables-1",
    "href": "slides/03_distribution_ch3_o.html#continuous-random-variables-1",
    "title": "Distribution Theory",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\n\nA continuous random variable can take on an uncountably infinite number of values.\nWith continuous random variables, we define probabilities using probability density functions (pdfs). \nProbabilities are calculated by computing the area under the density curve over the interval of interest. So, given a pdf, \\(f(y)\\), we can compute\n\n. . .\n\\[\\begin{align*}\nP(a \\le Y \\le b) = \\int_a^b f(y)dy.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#continuous-random-variables-2",
    "href": "slides/03_distribution_ch3_o.html#continuous-random-variables-2",
    "title": "Distribution Theory",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\nA few properties of continuous random variables:\n\nThe area under their density curve is 1. (\\(\\int_{-\\infty}^{\\infty} f(y)dy = 1\\)).\n\nFor any value \\(y\\), \\(P(Y = y) =  \\int_y^y f(y)dy = 0\\). Why?\nBecause of the above property, \\(P(y &lt; Y) = P(y \\le Y)\\). We will typically use the first notation rather than the second, but both are equally valid."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#exponential-random-variable",
    "href": "slides/03_distribution_ch3_o.html#exponential-random-variable",
    "title": "Distribution Theory",
    "section": "Exponential Random Variable",
    "text": "Exponential Random Variable\n\nSuppose we have a Poisson process with rate \\(\\lambda\\), and we wish to model the wait time \\(Y\\) until the first event.\nWe could model \\(Y\\) using an exponential distribution, where\n\n. . .\n\\[\\begin{equation}\nf(y) = \\lambda e^{-\\lambda y} \\quad \\textrm{for} \\quad y &gt; 0,\n\\end{equation}\\] - \\(\\operatorname{E}(Y) = 1/\\lambda\\) and \\(\\operatorname{SD}(Y) = 1/\\lambda\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#exponential-distribution",
    "href": "slides/03_distribution_ch3_o.html#exponential-distribution",
    "title": "Distribution Theory",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\nExponential distributions with \\(\\lambda = 0.5, 1,\\) and \\(5\\).\n\nPlotCode\n\n\n\n\n\n\n\n\n\nExponential Distribution\n\n\n\n\n\n\nAs \\(\\lambda\\) increases, \\(\\operatorname{E}(Y)\\) tends towards 0, and distributions ‚Äúdie off‚Äù quicker.\n\n\n\n\n\n\n#exponentialPlots\nx=seq(0,4,by=0.01)  # possible values\nprobex1 &lt;- dexp(x,.5)  # P(Y=y)\nprobex2 &lt;- dexp(x,1)\nprobex3 &lt;- dexp(x,5)\nExpdf &lt;- tibble(x,probex1, probex2, probex3) %&gt;%\n  rename(x = x,\n         `0.5` = probex1,\n         `1` = probex2,\n         `5` = probex3) %&gt;%\n  gather(2:4, key = \"Lambda\", value = \"value\") %&gt;%\n  mutate(Lambda = factor(Lambda, levels = c(\"0.5\", \"1\", \"5\")))\nggplot(data = Expdf, aes(x = x, y = value, color = Lambda)) +\n  geom_line(aes(linetype = Lambda)) +\n  xlab(\"values\") + ylab(\"density\") + \n  labs(title = \"Exponential Distributions\") + \n  xlim(0,4) + ylim(0,3)\n\n\n\n\n\n\n\n\n\nTo use R, pexp(y, lambda) outputs the probability \\(P(Y &lt; y)\\) given \\(\\lambda\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#gamma-random-variable",
    "href": "slides/03_distribution_ch3_o.html#gamma-random-variable",
    "title": "Distribution Theory",
    "section": "Gamma Random Variable",
    "text": "Gamma Random Variable\n\nOnce again consider a Poisson process.\nWhen discussing exponential random variables, we modeled the wait time before one event occurred.\nIf \\(Y\\) represents the wait time before \\(r\\) events occur in a Poisson process with rate \\(\\lambda\\), \\(Y\\) follows a gamma distribution where\n\n. . .\n\\[\\begin{equation}\nf(y) = \\frac{\\lambda^r}{\\Gamma(r)} y^{r-1} e^{-\\lambda y}\\quad \\textrm{for} \\quad y &gt;0.\n\\end{equation}\\]\n\nIf \\(Y \\sim \\textrm{Gamma}(r, \\lambda)\\) then \\(\\operatorname{E}(Y) = r/\\lambda\\) and \\(\\operatorname{SD}(Y) = \\sqrt{r/\\lambda^2}\\).\nNote: \\(\\Gamma(r)=(r-1)!\\) (There is more to it)"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#gamma-distribution",
    "href": "slides/03_distribution_ch3_o.html#gamma-distribution",
    "title": "Distribution Theory",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\nMeans increase as \\(r\\) increases, but decrease as \\(\\lambda\\) increases.\n\n\n\n\nx &lt;- seq(0, 7, by = 0.01)\n`r = 1, lambda = 1` &lt;- dgamma(x, 1, rate = 1)\n`r = 2, lambda = 1` &lt;- dgamma(x, 2, rate = 1) \n`r = 5, lambda = 5` &lt;- dgamma(x, 5, rate = 5)\n`r = 5, lambda = 7` &lt;- dgamma(x, 5, rate = 7)\n\ngammaDf &lt;- tibble(x, `r = 1, lambda = 1`, `r = 2, lambda = 1`, `r = 5, lambda = 5`, `r = 5, lambda = 7`) %&gt;%\n  gather(2:5, key = \"Distribution\", value = \"value\") %&gt;%\n  mutate(Distribution = factor(Distribution, \n                               levels = c(\"r = 2, lambda = 1\", \n                                          \"r = 1, lambda = 1\", \n                                          \"r = 5, lambda = 5\", \n                                          \"r = 5, lambda = 7\")))\n\nggplot(data = gammaDf, aes(x = x, y = value, \n                           color = Distribution)) +\n  geom_line(aes(linetype = Distribution)) +\n  xlab(\"values\") + ylab(\"density\") + \n  labs(title = \"Gamma Distributions\") +\n  theme(legend.title = element_blank())"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#gamma-vs-others",
    "href": "slides/03_distribution_ch3_o.html#gamma-vs-others",
    "title": "Distribution Theory",
    "section": "Gamma vs Others",
    "text": "Gamma vs Others\n\nNote that if we let \\(r = 1\\), we have the following pdf,\n\n. . .\n\\[\\begin{align*}\nf(y) &= \\frac{\\lambda}{\\Gamma(1)} y^{1-1} e^{-\\lambda y} \\\\\n      &= \\lambda e^{-\\lambda y} \\quad \\textrm{for} \\quad y &gt; 0,\n\\end{align*}\\] an exponential distribution. - Just as how the geometric distribution was a special case of the negative binomial, exponential distributions are in fact a special case of gamma distributions!\n\nJust like negative binomial, the pdf of a gamma distribution is defined for all real, non-negative \\(r\\).\nIn R, pgamma(y, r, lambda) outputs the probability \\(P(Y &lt; y)\\) given \\(r\\) and \\(\\lambda\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#distributions-used-in-testing",
    "href": "slides/03_distribution_ch3_o.html#distributions-used-in-testing",
    "title": "Distribution Theory",
    "section": "Distributions Used in Testing",
    "text": "Distributions Used in Testing\n\nWe have spent most of this chapter discussing probability distributions that may come in handy when modeling.\nThe following distributions, while rarely used in modeling, prove useful in hypothesis testing as certain commonly used test statistics follow these distributions.\n\\(\\chi^2\\) distribution (requires a degree of freedom)\nStudent \\(t\\) distribution\n\\(F\\) distribution (need 2 different degrees of freedom)\nSince we have used these In the past, we will leave their definitions to be referenced if needed"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#distribution-table",
    "href": "slides/03_distribution_ch3_o.html#distribution-table",
    "title": "Distribution Theory",
    "section": "Distribution Table!",
    "text": "Distribution Table!\n\nWould not fit on a slide\nClick HERE\nThe ‚Äúweb‚Äù of distributions: https://www.acsu.buffalo.edu/~adamcunn/probability/poisson.html"
  },
  {
    "objectID": "slides/03_distribution_ch3_o.html#acknowledgements",
    "href": "slides/03_distribution_ch3_o.html#acknowledgements",
    "title": "Distribution Theory",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#learning-objectives",
    "href": "slides/03_distribution_ch3.html#learning-objectives",
    "title": "Distribution Theory",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nWrite definitions of non-normal random variables in the context of an application.\nIdentify possible values for each random variable.\nIdentify how changing values for a parameter affects the characteristics of the distribution.\nRecognize a form of the probability density function for each distribution.\nIdentify the mean and variance for each distribution.\nMatch the response for a study to a plausible random variable and provide reasons for ruling out other random variables.\nMatch a histogram of sample data to plausible distributions.\nCreate a mixture of distributions and evaluate the shape, mean, and variance."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#libraries-needed-none-new",
    "href": "slides/03_distribution_ch3.html#libraries-needed-none-new",
    "title": "Distribution Theory",
    "section": "Libraries Needed (none new?)",
    "text": "Libraries Needed (none new?)\n\n# Packages required for Chapter 3\nlibrary(gridExtra)  \nlibrary(knitr) \nlibrary(kableExtra)\nlibrary(tidyverse)"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#introduction",
    "href": "slides/03_distribution_ch3.html#introduction",
    "title": "Distribution Theory",
    "section": "Introduction",
    "text": "Introduction\n\nWhat if it is not plausible that a response is normally distributed?\nYou may want to construct a model to predict whether a prospective student will enroll at a school or model the lifetimes of patients following a particular surgery.\n\nIn the first case you have a binary response (enrolls (1) or does not enroll (0)), and in the second case you are likely to have very skewed data with many similar values and a few hardy souls with extremely long survival.\nThese responses are not expected to be normally distributed; other distributions will be needed to describe and model binary or lifetime data.\nNon-normal responses are encountered in a large number of situations. Luckily, there are quite a few possibilities for models."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#discrete-random-variables-1",
    "href": "slides/03_distribution_ch3.html#discrete-random-variables-1",
    "title": "Distribution Theory",
    "section": "Discrete Random Variables",
    "text": "Discrete Random Variables\n\nA discrete random variable has a countable number of possible values\n\nEx: we may want to measure the number of people in a household\nEx: model the number of crimes committed on a college campus.\n\nWith discrete random variables, the associated probabilities can be calculated for each possible value using a probability mass function (pmf). \nA pmf is a function that calculates \\(P(Y=y)\\), given each variable‚Äôs parameters."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#binary-random-variable",
    "href": "slides/03_distribution_ch3.html#binary-random-variable",
    "title": "Distribution Theory",
    "section": "Binary Random Variable",
    "text": "Binary Random Variable\n\nConsider the event of flipping a (possibly unfair) coin.\nIf the coin lands heads, let‚Äôs consider this a success and record \\(Y = 1\\).\nA series of these events is a Bernoulli process, independent trials that take on one of two values (e.g., 0 or 1).\nThese values are often referred to as a failure and a success\n\nthe probability of success is identical for each trial."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#binary-random-variable-1",
    "href": "slides/03_distribution_ch3.html#binary-random-variable-1",
    "title": "Distribution Theory",
    "section": "Binary Random Variable",
    "text": "Binary Random Variable\n\nSuppose we only flip the coin once, so we only have one parameter, the probability of flipping heads, \\(p\\).\nIf we know this value, we can express \\(P(Y=1) = p\\) and \\(P(Y=0) = 1-p\\).\nIn general, if we have a Bernoulli process with only one trial, we have a binary distribution (also called a Bernoulli distribution) where\n\n\n\\[\\begin{equation*}\nP(Y = y) = p^y(1-p)^{1-y} \\quad \\textrm{for} \\quad y = 0, 1.\n\\end{equation*}\\]\n\nIf \\(Y \\sim \\textrm{Binary}(p)\\), then \\(Y\\) has mean \\(\\operatorname{E}(Y) = p\\) and standard deviation \\(\\operatorname{SD}(Y) = \\sqrt{p(1-p)}\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#example-1",
    "href": "slides/03_distribution_ch3.html#example-1",
    "title": "Distribution Theory",
    "section": "Example 1",
    "text": "Example 1\n\nYour playlist of 200 songs has 5 which you cannot stand. What is the probability that when you hit shuffle, a song you tolerate comes on?\nWe want to understand the example and be able to translate that into notation/model it with a distribution\nAssuming all songs have equal odds of playing, we can calculate \\(p = \\frac{200-5}{200} = 0.975\\)\n\nso there is a 97.5% chance of a song you tolerate playing, since \\(P(Y=1)=.975^1*(1-.975)^0\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#binomial-random-variable-12",
    "href": "slides/03_distribution_ch3.html#binomial-random-variable-12",
    "title": "Distribution Theory",
    "section": "Binomial Random Variable (1/2)",
    "text": "Binomial Random Variable (1/2)\n\nDoes anybody know how this relates to a Bernoulli random variable?\nWe can extend our knowledge of binary random variables.\nSuppose we flipped an unfair coin \\(n\\) times and recorded \\(Y\\), the number of heads after \\(n\\) flips.\nIf we consider a case where \\(p = 0.25\\) and \\(n = 4\\), then here \\(P(Y=0)\\) represents the probability of no successes in 4 trials\n\n4 consecutive failures.\nThe probability of 4 consecutive failures is \\(P(Y = 0) = P(TTTT) = (1-p)^4 = 0.75^4\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#binomial-random-variable-22",
    "href": "slides/03_distribution_ch3.html#binomial-random-variable-22",
    "title": "Distribution Theory",
    "section": "Binomial Random Variable (2/2)",
    "text": "Binomial Random Variable (2/2)\n\nNext we consider \\(P(Y = 1)\\), and are interested in the probability of exactly 1 success anywhere among the 4 trials.\nHow many different ways can we get exactly 1 success in the four trials?\nTo find the probability of this what else do we need to count?\nWhat is the probability?\nThere are \\(\\binom{4}{1} = 4\\) ways to have exactly 1 success in 4 trials, \\(P(Y = 1) = \\binom{4}{1}p^1(1-p)^{4-1} = (4)(0.25)(0.75)^3\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#binomial-distribution",
    "href": "slides/03_distribution_ch3.html#binomial-distribution",
    "title": "Distribution Theory",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nIn general, if we carry out a sequence of \\(n\\) Bernoulli trials (with probability of success \\(p\\)) and record \\(Y\\), the total number of successes, then \\(Y\\) follows a binomial distribution, where\n\n\n\\[\\begin{equation}\nP(Y=y) = \\binom{n}{y} p^y (1-p)^{n-y} \\quad \\textrm{for} \\quad y = 0, 1, \\ldots, n.\n\\end{equation}\\]\n\n\n\nIf \\(Y \\sim \\textrm{Binomial}(n,p)\\), then \\(\\operatorname{E}(Y) = np\\) and \\(\\operatorname{SD}(Y) = \\sqrt{np(1-p)}\\).\n\\(E(y)\\) is the expected value of \\(Y\\). If we repeated the experiment many times we would expect on average \\(n*p\\) successes."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#binomial-distribution-graphs",
    "href": "slides/03_distribution_ch3.html#binomial-distribution-graphs",
    "title": "Distribution Theory",
    "section": "Binomial Distribution Graphs",
    "text": "Binomial Distribution Graphs\n\nTypical shapes of a binomial distribution\nI will show you these in R"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#binomial-distribution-graphs-1",
    "href": "slides/03_distribution_ch3.html#binomial-distribution-graphs-1",
    "title": "Distribution Theory",
    "section": "Binomial Distribution Graphs",
    "text": "Binomial Distribution Graphs\n\nOn the left side \\(n\\) remains constant.\nWe see that as \\(p\\) increases, the center of the distribution (\\(\\operatorname{E}(Y) = np\\)) shifts right.\nOn the right, \\(p\\) is held constant.\nAs \\(n\\) increases, the distribution becomes less skewed."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#binomial-distribution-vs-bernoulli",
    "href": "slides/03_distribution_ch3.html#binomial-distribution-vs-bernoulli",
    "title": "Distribution Theory",
    "section": "Binomial Distribution vs Bernoulli",
    "text": "Binomial Distribution vs Bernoulli\n\nNote that if \\(n=1\\),\n\n\n\\[\\begin{align*}\nP(Y=y) &= \\binom{1}{y} p^y(1-p)^{1-y} \\\\\n        &= p^y(1-p)^{1-y}\\quad \\textrm{for}\\quad y = 0, 1,\n\\end{align*}\\] a Bernoulli distribution! - In fact, Bernoulli random variables are a special case of binomial random variables where \\(n=1\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#graphingcalling-in-r",
    "href": "slides/03_distribution_ch3.html#graphingcalling-in-r",
    "title": "Distribution Theory",
    "section": "Graphing/calling in R",
    "text": "Graphing/calling in R\n\nIn R we can use the function dbinom(y, n, p), which outputs the probability of \\(y\\) successes given \\(n\\) trials with probability \\(p\\), i.e., \\(P(Y=y)\\) for \\(Y \\sim \\textrm{Binomial}(n,p)\\).\nLets try it"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#example-2-12",
    "href": "slides/03_distribution_ch3.html#example-2-12",
    "title": "Distribution Theory",
    "section": "Example 2 (1/2)",
    "text": "Example 2 (1/2)\n\nWhile taking a multiple choice test, a student encountered 10 problems where she ended up completely guessing, randomly selecting one of the four options.\nWhat is the chance that she got exactly 2 of the 10 correct?\nWhat assumption do we need to make about the questions?\nHow would we do this without using a distribution?"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#example-2-22",
    "href": "slides/03_distribution_ch3.html#example-2-22",
    "title": "Distribution Theory",
    "section": "Example 2 (2/2)",
    "text": "Example 2 (2/2)\n\nKnowing that the student randomly selected her answers, we assume she has a 25% chance of a correct response.\nn factorial is denoted \\(n!\\) and \\(n!=n\\cdot(n-1)\\cdot...\\cdot 3\\cdot 2\\cdot 1\\)\nHere we used a combination \\({n \\choose p}=\\frac{n!}{p!(n-p)!}\\) read n choose p\nThus, \\(P(Y=2) = {10 \\choose 2}(.25)^2(.75)^8 = 0.282\\).\n\n\n\nWe can use R to verify this:\n\n\n\n\ndbinom(2, size = 10, prob = .25)\n\n[1] 0.2815676\n\n\nTherefore, there is a 28% chance of exactly 2 correct answers out of 10."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#negative-binomial-random-variable",
    "href": "slides/03_distribution_ch3.html#negative-binomial-random-variable",
    "title": "Distribution Theory",
    "section": "Negative Binomial Random Variable",
    "text": "Negative Binomial Random Variable\n\nWhat if we were to carry out multiple independent and identical Bernoulli trails until the \\(r\\)th success occurs?\nIf we model \\(Y\\), the number of failures before the \\(r\\)th success, then \\(Y\\) follows a negative binomial distribution where\n\n\n\\[\\begin{equation}\nP(Y=y) = \\binom{y + r - 1}{r-1} (1-p)^{y}(p)^r \\quad \\textrm{for}\\quad y = 0, 1, \\ldots, \\infty.\n\\end{equation}\\]"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#negative-binomial-rv",
    "href": "slides/03_distribution_ch3.html#negative-binomial-rv",
    "title": "Distribution Theory",
    "section": "Negative Binomial RV",
    "text": "Negative Binomial RV\n\nIf \\(Y \\sim \\textrm{Negative Binomial}(r, p)\\) then \\(\\operatorname{E}(Y) = \\frac{r(1-p)}{p}\\) and \\(\\operatorname{SD}(Y) = \\sqrt{\\frac{r(1-p)}{p^2}}\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#negative-binomial-rv-1",
    "href": "slides/03_distribution_ch3.html#negative-binomial-rv-1",
    "title": "Distribution Theory",
    "section": "Negative Binomial RV",
    "text": "Negative Binomial RV\n\nPlotCode\n\n\n\n\n\n\n\nNegative Binomial\n\n\n\n\n\nNotice how centers shift right as \\(r\\) increases, and left as \\(p\\) increases.\n\n\n\n\n#negativeBinomialPlots\nplotNBinom &lt;- function(p, r){\n  ynb &lt;- 0:10000\n  nbd &lt;- tibble(x = rnbinom(ynb, r, p))\n  #breaks &lt;- pretty(range(nbd$x), n = nclass.FD(nbd$x), min.n = 1)  # pretty binning\n  #bwidth &lt;- breaks[2] - breaks[1]\n  ggplot(nbd, aes(x = x)) +\n    geom_histogram(aes(y=..count../sum(..count..)), binwidth = .25) +\n    labs(title = paste(\"p = \", p, \", r = \", r),\n         x = \"number of failures\",\n         y = \"probability\") +\n    xlim(-1,30)\n}\n\nNBin1 &lt;- plotNBinom(0.35, 3)\nNBin2 &lt;- plotNBinom(0.35, 5)\nNBin3 &lt;- plotNBinom(0.70, 5)\ngrid.arrange(NBin1, NBin2, NBin3, ncol = 1)"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#negative-binomial-rv-2",
    "href": "slides/03_distribution_ch3.html#negative-binomial-rv-2",
    "title": "Distribution Theory",
    "section": "Negative Binomial RV",
    "text": "Negative Binomial RV\n\nNote that if we set \\(r=1\\), then\n\n\n\\[\\begin{align*}\nP(Y=y) &= \\binom{y}{0} (1-p)^yp \\\\\n        &= (1-p)^yp \\quad \\textrm{for} \\quad y = 0, 1, \\ldots, \\infty,\n\\end{align*}\\] which is the probability mass function of a geometric random variable!\n\nThus, a geometric random variable is, in fact, a special case of a negative binomial random variable.\nWhile negative binomial random variables typically are expressed as above using binomial coefficients (expressions such as \\(\\binom{x}{y}\\)), we can generalize our definition to allow non-integer values of \\(r\\).\nR function dnbinom(y, r, p) for the probability of \\(y\\) failures before the \\(r\\)th success given probability \\(p\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#poisson-random-variable",
    "href": "slides/03_distribution_ch3.html#poisson-random-variable",
    "title": "Distribution Theory",
    "section": "Poisson Random Variable",
    "text": "Poisson Random Variable\n\nSometimes, random variables are based on a Poisson process. \nIn a Poisson process, we are counting the number of events per unit of time or space and the number of events depends only on the length or size of the interval.\nWe can then model \\(Y\\), the number of events in one of these sections with the Poisson distribution, where\n\n\n\\[\\begin{equation}\nP(Y=y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\quad \\textrm{for} \\quad y = 0, 1, \\ldots, \\infty,\n\\end{equation}\\] where \\(\\lambda\\) is the mean or expected count in the unit of time or space of interest. - This probability mass function has \\(\\operatorname{E}(Y) = \\lambda\\) and \\(\\operatorname{SD}(Y) = \\sqrt{\\lambda}\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#poisson-distribution-graphs",
    "href": "slides/03_distribution_ch3.html#poisson-distribution-graphs",
    "title": "Distribution Theory",
    "section": "Poisson Distribution Graphs",
    "text": "Poisson Distribution Graphs\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\nNotice how distributions become more symmetric as \\(\\lambda\\) increases.\nIf we wish to use R, dpois(y, lambda) outputs the probability of \\(y\\) events given \\(\\lambda\\).\n\n\n\n\n#poissonPlots\nplotPois &lt;- function(lam){\nyp = 0:10000 # possible values\npd &lt;- data.frame(x=rpois(yp, lam))  # generate random deviates\nbreaks &lt;- pretty(range(pd$x), n = nclass.FD(pd$x), min.n = 1)  # pretty binning\n#bwidth &lt;- breaks[2] - breaks[1]\nggplot(pd, aes(x = x)) + geom_histogram(aes(y=..count../sum(..count..)), binwidth = .25) +\n  xlab(\"number of events\") + ylab(\"probability\") + \n  labs(title=paste(\"Poisson lambda = \", lam)) + xlim(-1,13)\n}\n\nPois1 &lt;- plotPois(0.5)\nPois2 &lt;- plotPois(1)\nPois3 &lt;- plotPois(5) + scale_y_continuous(breaks = c(0, 0.1))\ngrid.arrange(Pois1,Pois2,Pois3,ncol=1)"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#continuous-random-variables-1",
    "href": "slides/03_distribution_ch3.html#continuous-random-variables-1",
    "title": "Distribution Theory",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\n\nA continuous random variable can take on an uncountably infinite number of values.\nWith continuous random variables, we define probabilities using probability density functions (pdfs). \nProbabilities are calculated by computing the area under the density curve over the interval of interest. So, given a pdf, \\(f(y)\\), we can compute\n\n\n\\[\\begin{align*}\nP(a \\le Y \\le b) = \\int_a^b f(y)dy.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#continuous-random-variables-2",
    "href": "slides/03_distribution_ch3.html#continuous-random-variables-2",
    "title": "Distribution Theory",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\nA few properties of continuous random variables:\n\nThe area under their density curve is 1. (\\(\\int_{-\\infty}^{\\infty} f(y)dy = 1\\)).\n\nFor any value \\(y\\), \\(P(Y = y) =  \\int_y^y f(y)dy = 0\\). Why?\nBecause of the above property, \\(P(y &lt; Y) = P(y \\le Y)\\). We will typically use the first notation rather than the second, but both are equally valid."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#exponential-random-variable",
    "href": "slides/03_distribution_ch3.html#exponential-random-variable",
    "title": "Distribution Theory",
    "section": "Exponential Random Variable",
    "text": "Exponential Random Variable\n\nSuppose we have a Poisson process with rate \\(\\lambda\\), and we wish to model the wait time \\(Y\\) until the first event.\nWe could model \\(Y\\) using an exponential distribution, where\n\n\n\\[\\begin{equation}\nf(y) = \\lambda e^{-\\lambda y} \\quad \\textrm{for} \\quad y &gt; 0,\n\\end{equation}\\] - \\(\\operatorname{E}(Y) = 1/\\lambda\\) and \\(\\operatorname{SD}(Y) = 1/\\lambda\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#exponential-distribution",
    "href": "slides/03_distribution_ch3.html#exponential-distribution",
    "title": "Distribution Theory",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\nExponential distributions with \\(\\lambda = 0.5, 1,\\) and \\(5\\).\n\nPlotCode\n\n\n\n\n\n\n\n\n\nExponential Distribution\n\n\n\n\n\n\nAs \\(\\lambda\\) increases, \\(\\operatorname{E}(Y)\\) tends towards 0, and distributions ‚Äúdie off‚Äù quicker.\n\n\n\n\n\n\n#exponentialPlots\nx=seq(0,4,by=0.01)  # possible values\nprobex1 &lt;- dexp(x,.5)  # P(Y=y)\nprobex2 &lt;- dexp(x,1)\nprobex3 &lt;- dexp(x,5)\nExpdf &lt;- tibble(x,probex1, probex2, probex3) %&gt;%\n  rename(x = x,\n         `0.5` = probex1,\n         `1` = probex2,\n         `5` = probex3) %&gt;%\n  gather(2:4, key = \"Lambda\", value = \"value\") %&gt;%\n  mutate(Lambda = factor(Lambda, levels = c(\"0.5\", \"1\", \"5\")))\nggplot(data = Expdf, aes(x = x, y = value, color = Lambda)) +\n  geom_line(aes(linetype = Lambda)) +\n  xlab(\"values\") + ylab(\"density\") + \n  labs(title = \"Exponential Distributions\") + \n  xlim(0,4) + ylim(0,3)\n\n\n\n\n\n\n\n\n\nTo use R, pexp(y, lambda) outputs the probability \\(P(Y &lt; y)\\) given \\(\\lambda\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#gamma-random-variable",
    "href": "slides/03_distribution_ch3.html#gamma-random-variable",
    "title": "Distribution Theory",
    "section": "Gamma Random Variable",
    "text": "Gamma Random Variable\n\nOnce again consider a Poisson process.\nWhen discussing exponential random variables, we modeled the wait time before one event occurred.\nIf \\(Y\\) represents the wait time before \\(r\\) events occur in a Poisson process with rate \\(\\lambda\\), \\(Y\\) follows a gamma distribution where\n\n\n\\[\\begin{equation}\nf(y) = \\frac{\\lambda^r}{\\Gamma(r)} y^{r-1} e^{-\\lambda y}\\quad \\textrm{for} \\quad y &gt;0.\n\\end{equation}\\]\n\nIf \\(Y \\sim \\textrm{Gamma}(r, \\lambda)\\) then \\(\\operatorname{E}(Y) = r/\\lambda\\) and \\(\\operatorname{SD}(Y) = \\sqrt{r/\\lambda^2}\\).\nNote: \\(\\Gamma(r)=(r-1)!\\) (There is more to it)"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#gamma-distribution",
    "href": "slides/03_distribution_ch3.html#gamma-distribution",
    "title": "Distribution Theory",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\nMeans increase as \\(r\\) increases, but decrease as \\(\\lambda\\) increases.\n\n\n\n\nx &lt;- seq(0, 7, by = 0.01)\n`r = 1, lambda = 1` &lt;- dgamma(x, 1, rate = 1)\n`r = 2, lambda = 1` &lt;- dgamma(x, 2, rate = 1) \n`r = 5, lambda = 5` &lt;- dgamma(x, 5, rate = 5)\n`r = 5, lambda = 7` &lt;- dgamma(x, 5, rate = 7)\n\ngammaDf &lt;- tibble(x, `r = 1, lambda = 1`, `r = 2, lambda = 1`, `r = 5, lambda = 5`, `r = 5, lambda = 7`) %&gt;%\n  gather(2:5, key = \"Distribution\", value = \"value\") %&gt;%\n  mutate(Distribution = factor(Distribution, \n                               levels = c(\"r = 2, lambda = 1\", \n                                          \"r = 1, lambda = 1\", \n                                          \"r = 5, lambda = 5\", \n                                          \"r = 5, lambda = 7\")))\n\nggplot(data = gammaDf, aes(x = x, y = value, \n                           color = Distribution)) +\n  geom_line(aes(linetype = Distribution)) +\n  xlab(\"values\") + ylab(\"density\") + \n  labs(title = \"Gamma Distributions\") +\n  theme(legend.title = element_blank())"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#gamma-vs-others",
    "href": "slides/03_distribution_ch3.html#gamma-vs-others",
    "title": "Distribution Theory",
    "section": "Gamma vs Others",
    "text": "Gamma vs Others\n\nNote that if we let \\(r = 1\\), we have the following pdf,\n\n\n\\[\\begin{align*}\nf(y) &= \\frac{\\lambda}{\\Gamma(1)} y^{1-1} e^{-\\lambda y} \\\\\n      &= \\lambda e^{-\\lambda y} \\quad \\textrm{for} \\quad y &gt; 0,\n\\end{align*}\\] an exponential distribution. - Just as how the geometric distribution was a special case of the negative binomial, exponential distributions are in fact a special case of gamma distributions!\n\nJust like negative binomial, the pdf of a gamma distribution is defined for all real, non-negative \\(r\\).\nIn R, pgamma(y, r, lambda) outputs the probability \\(P(Y &lt; y)\\) given \\(r\\) and \\(\\lambda\\)."
  },
  {
    "objectID": "slides/03_distribution_ch3.html#distributions-used-in-testing",
    "href": "slides/03_distribution_ch3.html#distributions-used-in-testing",
    "title": "Distribution Theory",
    "section": "Distributions Used in Testing",
    "text": "Distributions Used in Testing\n\nWe have spent most of this chapter discussing probability distributions that may come in handy when modeling.\nThe following distributions, while rarely used in modeling, prove useful in hypothesis testing as certain commonly used test statistics follow these distributions.\n\\(\\chi^2\\) distribution (requires a degree of freedom)\nStudent \\(t\\) distribution\n\\(F\\) distribution (need 2 different degrees of freedom)\nSince we have used these In the past, we will leave their definitions to be referenced if needed"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#distribution-table",
    "href": "slides/03_distribution_ch3.html#distribution-table",
    "title": "Distribution Theory",
    "section": "Distribution Table!",
    "text": "Distribution Table!\n\nWould not fit on a slide\nClick HERE\nThe ‚Äúweb‚Äù of distributions: https://www.acsu.buffalo.edu/~adamcunn/probability/poisson.html"
  },
  {
    "objectID": "slides/03_distribution_ch3.html#acknowledgements",
    "href": "slides/03_distribution_ch3.html#acknowledgements",
    "title": "Distribution Theory",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html",
    "href": "slides/05_glm_ch5_o.html",
    "title": "Generalized Linear Models (GLMs)",
    "section": "",
    "text": "Identify the components common to all generalized linear models\nFind the canonical link based on the distribution of the response variable\nExplain how coefficients are estimated using iteratively reweighted least squares (IWLS)"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#learning-goals",
    "href": "slides/05_glm_ch5_o.html#learning-goals",
    "title": "Generalized Linear Models (GLMs)",
    "section": "",
    "text": "Identify the components common to all generalized linear models\nFind the canonical link based on the distribution of the response variable\nExplain how coefficients are estimated using iteratively reweighted least squares (IWLS)"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#many-models-one-family",
    "href": "slides/05_glm_ch5_o.html#many-models-one-family",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Many models; one family",
    "text": "Many models; one family\nWe have studied models for a variety of response variables\n\nLeast squares (Normal)\nLogistic (Bernoulli, Binomial, Multinomial)\nLog-linear (Poisson, Negative Binomial)\n\n. . .\nThese models are all examples of generalized linear models.\nGLMs have a similar structure for their likelihoods, MLEs, variances, so we can use a generalized approach to find the model estimates and associated uncertainty."
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#components-of-a-glm",
    "href": "slides/05_glm_ch5_o.html#components-of-a-glm",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Components of a GLM",
    "text": "Components of a GLM\nNelder and Wdderburn (1972) defines a broad class of models called generalized linear models that generalizes multiple linear regression. GLMs are characterized by three components:\n. . .\n1Ô∏è‚É£ Response variable with parameter \\(\\theta\\) whose probability function can be written in exponential family form (random component)\n2Ô∏è‚É£ A linear combination of predictors, \\(\\eta = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\) (systematic component)\n3Ô∏è‚É£ A link function \\(g(\\theta)\\) that connects \\(\\theta\\) to \\(\\eta\\)\n\n\nNelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. Journal of the Royal Statistical Society: Series A (General), 135(3), 370-384."
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#exponential-family-form",
    "href": "slides/05_glm_ch5_o.html#exponential-family-form",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Exponential family form",
    "text": "Exponential family form\nSuppose a probability (mass or density) function has a parameter \\(\\theta\\). It is said to have a one-parameter exponential family form if\n. . .\n‚úÖ The support (set of possible values) does not depend on \\(\\theta\\), and\n. . .\n‚úÖ The probability function can be written in the following form\n\\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\n. . .\nUsing this form:\n\\[E(Y) = -\\frac{c'(\\theta)}{b'(\\theta)} \\hspace{20mm} Var(Y) = \\frac{b''(\\theta)c'(\\theta) - c''(\\theta)b'(\\theta)}{[b'(\\theta)]^3}\\]"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#poisson-in-exponential-family-form",
    "href": "slides/05_glm_ch5_o.html#poisson-in-exponential-family-form",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Poisson in exponential family form",
    "text": "Poisson in exponential family form\n\\[P(Y = y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y = 0, 1, 2, \\ldots, \\infty\\]\n. . .\n\\[\\begin{aligned}P(Y = y) &= e^{-\\lambda}e^{y\\log(\\lambda)}e^{-\\log(y!)}\\\\\n& = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\end{aligned}\\]\n. . .\nRecall the form: \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\), where the parameter \\(\\theta = \\lambda\\) for the Poisson distribution\n\n\n\n\\(a(y) = y\\)\n\\(b(\\lambda) = \\log(\\lambda)\\)\n\n\n\n\\(c(\\lambda) = -\\lambda\\)\n\\(d(y) = -\\log(y!)\\)"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#poisson-in-exponential-family-form-1",
    "href": "slides/05_glm_ch5_o.html#poisson-in-exponential-family-form-1",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Poisson in exponential family form",
    "text": "Poisson in exponential family form\n\nThe support for the Poisson distribution is \\(y = 0, 1, 2, \\ldots, \\infty\\). This does not depend on the parameter \\(\\lambda\\).\nThe probability mass function can be written in the form \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\n\n. . .\nThe Poisson distribution can be written in one-parameter exponential family form."
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#canonical-link",
    "href": "slides/05_glm_ch5_o.html#canonical-link",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Canonical link",
    "text": "Canonical link\nSuppose there is a response variable \\(Y\\) from a distribution with parameter \\(\\theta\\) and a set of predictors that can be written as a linear combination \\(\\eta = \\sum_{j=1}^{p}\\beta_jx_j = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\)\n\n(There does not have to be an intercept but generally we also include \\(\\beta_0\\))\n\n. . .\nA link function, \\(g()\\), is a monotonic and differentiable function that connects \\(\\theta\\) to \\(\\eta\\)\n. . .\nThe canonical link is a link function such that \\(g(\\theta) = \\eta\\)\n\nWhen working with a member of the one-parameter exponential family, the canonical link is \\(b(\\theta)\\)"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#canonical-link-for-poisson",
    "href": "slides/05_glm_ch5_o.html#canonical-link-for-poisson",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Canonical link for Poisson",
    "text": "Canonical link for Poisson\nRecall\n\\[P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\]\nthen the canonical link is \\(b(\\lambda) = \\log(\\lambda)\\)"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#glm-framework-poisson-response-variable",
    "href": "slides/05_glm_ch5_o.html#glm-framework-poisson-response-variable",
    "title": "Generalized Linear Models (GLMs)",
    "section": "GLM framework: Poisson response variable",
    "text": "GLM framework: Poisson response variable\n1Ô∏è‚É£ Response variable with parameter \\(\\theta\\) whose probability function can be written in exponential family form\n\\[P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\]\n. . .\n2Ô∏è‚É£ A linear combination of predictors, \\(\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\)\n. . .\n3Ô∏è‚É£ A function \\(g(\\lambda)\\) that connects \\(\\lambda\\) and \\(\\eta\\)\n\\[\\log(\\lambda) = \\eta =  \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\]"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#activity-identifying-canonical-link",
    "href": "slides/05_glm_ch5_o.html#activity-identifying-canonical-link",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Activity: Identifying canonical link",
    "text": "Activity: Identifying canonical link\nFor the distribution\n\nDescribe an example of a setting where this random variable may be used.\nIdentify the parameter.\nWrite the pmf or pdf in one-parameter exponential form.\nIdentify the canonical link function\nOne person from each group: Write your response on the board."
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#activity",
    "href": "slides/05_glm_ch5_o.html#activity",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Activity",
    "text": "Activity\nDistributions\n\nBinary\nExponential\nNegative binomial (with fixed \\(r\\))\nGeometric\nNormal (with fixed \\(\\sigma\\))\n\n\nIf your group finishes early, try identifying the canonical link for the other distributions.\nSee BMLR - Section 3.6 for details on the distributions."
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#data-noisy-miners",
    "href": "slides/05_glm_ch5_o.html#data-noisy-miners",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Data: Noisy Miners",
    "text": "Data: Noisy Miners\nThe dataset nminer contains information about the number of noisy miners (small Australian bird) detected in two woodland patches within the Wimmera Plains of Victoria, Australia. It was obtained from the GLMsdata R package. We will use the following variables:\n\nMinerab: The number of noisy miners (abundance) observed in three 20 minute surveys\nEucs: The number of eucalyptus trees in each 2 hectare area (about 4.94 acres)"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#noisy-miner-model",
    "href": "slides/05_glm_ch5_o.html#noisy-miner-model",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Noisy Miner Model",
    "text": "Noisy Miner Model\n\n\n\n\n\nEucs\nMinerab\n\n\n\n\n2\n0\n\n\n10\n0\n\n\n16\n3\n\n\n20\n2\n\n\n19\n8\n\n\n\n\n\n. . .\nOur goal is to use a Poisson regression model to predict the number of noisy miners observed in three 20 minute surveys based on the number of eucalyptus trees.\n\\[\\log(\\lambda_{Minearab}) = \\beta_0 + \\beta_1 ~ Euc\\]\n. . .\nWhat are the best estimates of \\(\\beta_0\\) and \\(\\beta_1\\)?"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#iteratively-reweighted-least-squares-iwls-1",
    "href": "slides/05_glm_ch5_o.html#iteratively-reweighted-least-squares-iwls-1",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Iteratively reweighted least squares (IWLS)",
    "text": "Iteratively reweighted least squares (IWLS)\n\nThe estimates of \\(\\beta_0\\) and \\(\\beta_1\\) are found using maximum likelihood estimation.\nIteratively reweighted least-squares (IWLS) is used to find the MLEs\n\nNelder and Wedderburn (1972) show that under certain specifications of the weights and a modified response variable, the estimates found using IWLS are equivalent to the MLEs."
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#iwls-set-up",
    "href": "slides/05_glm_ch5_o.html#iwls-set-up",
    "title": "Generalized Linear Models (GLMs)",
    "section": "IWLS Set up",
    "text": "IWLS Set up\nWorking response: Modified response variable at each step of the iteration.\n\\[z_i = g(\\theta) + g'(\\theta)(y_i - \\theta_i)\\]\nFor Poisson regression, this is\n\\[z_i = \\log(\\lambda) + \\frac{(y_i - \\lambda_i)}{\\lambda_i}\\]\n. . .\nWorking Weights: Weights applied to the observations at each step of the iteration\n\\[W_i = \\frac{\\theta^2}{Var(Y)} \\hspace{5mm} \\Rightarrow \\hspace{5mm}  W_i = \\frac{\\lambda^2}{\\lambda} =  \\lambda \\text{ for Poisson regression}\\]"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#iwls-procedure",
    "href": "slides/05_glm_ch5_o.html#iwls-procedure",
    "title": "Generalized Linear Models (GLMs)",
    "section": "IWLS procedure",
    "text": "IWLS procedure\n\nFind initial starting values \\(\\hat{\\theta}_i\\).\nCalculate the working response values \\(z_i\\).\nCalculate the working weights \\(W_i\\).\nFind the coefficient estimates of the weighted least squares model.\n\n. . .\n\\(z_i = \\beta_0 + \\beta_1 x \\hspace{5mm} \\text{ with weights }W_i\\)\nThe estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) are the estimates for the model coefficients.\n. . .\nUse \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) to calculate updated values of \\(\\hat{\\theta}_i\\) and repeat steps 2 - 4 until convergence.\n. . ."
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#demo-in-ch5_iwls.r-in-server-class-files",
    "href": "slides/05_glm_ch5_o.html#demo-in-ch5_iwls.r-in-server-class-files",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Demo in ch5_iwls.R in server class files",
    "text": "Demo in ch5_iwls.R in server class files"
  },
  {
    "objectID": "slides/05_glm_ch5_o.html#acknowledgements",
    "href": "slides/05_glm_ch5_o.html#acknowledgements",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\nThese slides are based on content in BMLR: Chapter 4\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\nBMLR: Chapter 5 - Generalized Linear Models: A Unifying Theory\nNelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. Journal of the Royal Statistical Society: Series A (General), 135(3), 370-384.\nGeneralized Linear Models with Examples in R\n\nChapter 5 - Generalized Linear Models: Structure\nChapter 6 - Generalized Linear Models: Estimation"
  },
  {
    "objectID": "slides/05_glm_ch5.html#learning-goals",
    "href": "slides/05_glm_ch5.html#learning-goals",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Learning goals",
    "text": "Learning goals\n\nIdentify the components common to all generalized linear models\nFind the canonical link based on the distribution of the response variable\nExplain how coefficients are estimated using iteratively reweighted least squares (IWLS)"
  },
  {
    "objectID": "slides/05_glm_ch5.html#many-models-one-family",
    "href": "slides/05_glm_ch5.html#many-models-one-family",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Many models; one family",
    "text": "Many models; one family\nWe have studied models for a variety of response variables\n\nLeast squares (Normal)\nLogistic (Bernoulli, Binomial, Multinomial)\nLog-linear (Poisson, Negative Binomial)\n\n\nThese models are all examples of generalized linear models.\nGLMs have a similar structure for their likelihoods, MLEs, variances, so we can use a generalized approach to find the model estimates and associated uncertainty."
  },
  {
    "objectID": "slides/05_glm_ch5.html#components-of-a-glm",
    "href": "slides/05_glm_ch5.html#components-of-a-glm",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Components of a GLM",
    "text": "Components of a GLM\nNelder and Wdderburn (1972) defines a broad class of models called generalized linear models that generalizes multiple linear regression. GLMs are characterized by three components:\n\n1Ô∏è‚É£ Response variable with parameter \\(\\theta\\) whose probability function can be written in exponential family form (random component)\n2Ô∏è‚É£ A linear combination of predictors, \\(\\eta = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\) (systematic component)\n3Ô∏è‚É£ A link function \\(g(\\theta)\\) that connects \\(\\theta\\) to \\(\\eta\\)\n\n\n\nNelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. Journal of the Royal Statistical Society: Series A (General), 135(3), 370-384."
  },
  {
    "objectID": "slides/05_glm_ch5.html#exponential-family-form",
    "href": "slides/05_glm_ch5.html#exponential-family-form",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Exponential family form",
    "text": "Exponential family form\nSuppose a probability (mass or density) function has a parameter \\(\\theta\\). It is said to have a one-parameter exponential family form if\n\n‚úÖ The support (set of possible values) does not depend on \\(\\theta\\), and\n\n\n‚úÖ The probability function can be written in the following form\n\\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\n\n\nUsing this form:\n\\[E(Y) = -\\frac{c'(\\theta)}{b'(\\theta)} \\hspace{20mm} Var(Y) = \\frac{b''(\\theta)c'(\\theta) - c''(\\theta)b'(\\theta)}{[b'(\\theta)]^3}\\]"
  },
  {
    "objectID": "slides/05_glm_ch5.html#poisson-in-exponential-family-form",
    "href": "slides/05_glm_ch5.html#poisson-in-exponential-family-form",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Poisson in exponential family form",
    "text": "Poisson in exponential family form\n\\[P(Y = y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y = 0, 1, 2, \\ldots, \\infty\\]\n\n\\[\\begin{aligned}P(Y = y) &= e^{-\\lambda}e^{y\\log(\\lambda)}e^{-\\log(y!)}\\\\\n& = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\end{aligned}\\]\n\n\nRecall the form: \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\), where the parameter \\(\\theta = \\lambda\\) for the Poisson distribution\n\n\n\n\\(a(y) = y\\)\n\\(b(\\lambda) = \\log(\\lambda)\\)\n\n\n\n\\(c(\\lambda) = -\\lambda\\)\n\\(d(y) = -\\log(y!)\\)"
  },
  {
    "objectID": "slides/05_glm_ch5.html#poisson-in-exponential-family-form-1",
    "href": "slides/05_glm_ch5.html#poisson-in-exponential-family-form-1",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Poisson in exponential family form",
    "text": "Poisson in exponential family form\n\nThe support for the Poisson distribution is \\(y = 0, 1, 2, \\ldots, \\infty\\). This does not depend on the parameter \\(\\lambda\\).\nThe probability mass function can be written in the form \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\n\n\nThe Poisson distribution can be written in one-parameter exponential family form."
  },
  {
    "objectID": "slides/05_glm_ch5.html#canonical-link",
    "href": "slides/05_glm_ch5.html#canonical-link",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Canonical link",
    "text": "Canonical link\nSuppose there is a response variable \\(Y\\) from a distribution with parameter \\(\\theta\\) and a set of predictors that can be written as a linear combination \\(\\eta = \\sum_{j=1}^{p}\\beta_jx_j = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\)\n\n(There does not have to be an intercept but generally we also include \\(\\beta_0\\))\n\n\nA link function, \\(g()\\), is a monotonic and differentiable function that connects \\(\\theta\\) to \\(\\eta\\)\n\n\nThe canonical link is a link function such that \\(g(\\theta) = \\eta\\)\n\nWhen working with a member of the one-parameter exponential family, the canonical link is \\(b(\\theta)\\)"
  },
  {
    "objectID": "slides/05_glm_ch5.html#canonical-link-for-poisson",
    "href": "slides/05_glm_ch5.html#canonical-link-for-poisson",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Canonical link for Poisson",
    "text": "Canonical link for Poisson\nRecall\n\\[P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\]\nthen the canonical link is \\(b(\\lambda) = \\log(\\lambda)\\)"
  },
  {
    "objectID": "slides/05_glm_ch5.html#glm-framework-poisson-response-variable",
    "href": "slides/05_glm_ch5.html#glm-framework-poisson-response-variable",
    "title": "Generalized Linear Models (GLMs)",
    "section": "GLM framework: Poisson response variable",
    "text": "GLM framework: Poisson response variable\n1Ô∏è‚É£ Response variable with parameter \\(\\theta\\) whose probability function can be written in exponential family form\n\\[P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\]\n\n2Ô∏è‚É£ A linear combination of predictors, \\(\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\)\n\n\n3Ô∏è‚É£ A function \\(g(\\lambda)\\) that connects \\(\\lambda\\) and \\(\\eta\\)\n\\[\\log(\\lambda) = \\eta =  \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\]"
  },
  {
    "objectID": "slides/05_glm_ch5.html#activity-identifying-canonical-link",
    "href": "slides/05_glm_ch5.html#activity-identifying-canonical-link",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Activity: Identifying canonical link",
    "text": "Activity: Identifying canonical link\nFor the distribution\n\nDescribe an example of a setting where this random variable may be used.\nIdentify the parameter.\nWrite the pmf or pdf in one-parameter exponential form.\nIdentify the canonical link function\nOne person from each group: Write your response on the board."
  },
  {
    "objectID": "slides/05_glm_ch5.html#activity",
    "href": "slides/05_glm_ch5.html#activity",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Activity",
    "text": "Activity\nDistributions\n\nBinary\nExponential\nNegative binomial (with fixed \\(r\\))\nGeometric\nNormal (with fixed \\(\\sigma\\))\n\n\nIf your group finishes early, try identifying the canonical link for the other distributions.\nSee BMLR - Section 3.6 for details on the distributions."
  },
  {
    "objectID": "slides/05_glm_ch5.html#data-noisy-miners",
    "href": "slides/05_glm_ch5.html#data-noisy-miners",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Data: Noisy Miners",
    "text": "Data: Noisy Miners\nThe dataset nminer contains information about the number of noisy miners (small Australian bird) detected in two woodland patches within the Wimmera Plains of Victoria, Australia. It was obtained from the GLMsdata R package. We will use the following variables:\n\nMinerab: The number of noisy miners (abundance) observed in three 20 minute surveys\nEucs: The number of eucalyptus trees in each 2 hectare area (about 4.94 acres)"
  },
  {
    "objectID": "slides/05_glm_ch5.html#noisy-miner-model",
    "href": "slides/05_glm_ch5.html#noisy-miner-model",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Noisy Miner Model",
    "text": "Noisy Miner Model\n\n\n\n\n\nEucs\nMinerab\n\n\n\n\n2\n0\n\n\n10\n0\n\n\n16\n3\n\n\n20\n2\n\n\n19\n8\n\n\n\n\n\n\nOur goal is to use a Poisson regression model to predict the number of noisy miners observed in three 20 minute surveys based on the number of eucalyptus trees.\n\\[\\log(\\lambda_{Minearab}) = \\beta_0 + \\beta_1 ~ Euc\\]\n\n\nWhat are the best estimates of \\(\\beta_0\\) and \\(\\beta_1\\)?"
  },
  {
    "objectID": "slides/05_glm_ch5.html#iteratively-reweighted-least-squares-iwls-1",
    "href": "slides/05_glm_ch5.html#iteratively-reweighted-least-squares-iwls-1",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Iteratively reweighted least squares (IWLS)",
    "text": "Iteratively reweighted least squares (IWLS)\n\nThe estimates of \\(\\beta_0\\) and \\(\\beta_1\\) are found using maximum likelihood estimation.\nIteratively reweighted least-squares (IWLS) is used to find the MLEs\n\nNelder and Wedderburn (1972) show that under certain specifications of the weights and a modified response variable, the estimates found using IWLS are equivalent to the MLEs."
  },
  {
    "objectID": "slides/05_glm_ch5.html#iwls-set-up",
    "href": "slides/05_glm_ch5.html#iwls-set-up",
    "title": "Generalized Linear Models (GLMs)",
    "section": "IWLS Set up",
    "text": "IWLS Set up\nWorking response: Modified response variable at each step of the iteration.\n\\[z_i = g(\\theta) + g'(\\theta)(y_i - \\theta_i)\\]\nFor Poisson regression, this is\n\\[z_i = \\log(\\lambda) + \\frac{(y_i - \\lambda_i)}{\\lambda_i}\\]\n\nWorking Weights: Weights applied to the observations at each step of the iteration\n\\[W_i = \\frac{\\theta^2}{Var(Y)} \\hspace{5mm} \\Rightarrow \\hspace{5mm}  W_i = \\frac{\\lambda^2}{\\lambda} =  \\lambda \\text{ for Poisson regression}\\]"
  },
  {
    "objectID": "slides/05_glm_ch5.html#iwls-procedure",
    "href": "slides/05_glm_ch5.html#iwls-procedure",
    "title": "Generalized Linear Models (GLMs)",
    "section": "IWLS procedure",
    "text": "IWLS procedure\n\nFind initial starting values \\(\\hat{\\theta}_i\\).\nCalculate the working response values \\(z_i\\).\nCalculate the working weights \\(W_i\\).\nFind the coefficient estimates of the weighted least squares model.\n\n\n\\(z_i = \\beta_0 + \\beta_1 x \\hspace{5mm} \\text{ with weights }W_i\\)\nThe estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) are the estimates for the model coefficients.\n\n\nUse \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) to calculate updated values of \\(\\hat{\\theta}_i\\) and repeat steps 2 - 4 until convergence."
  },
  {
    "objectID": "slides/05_glm_ch5.html#demo-in-ch5_iwls.r-in-server-class-files",
    "href": "slides/05_glm_ch5.html#demo-in-ch5_iwls.r-in-server-class-files",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Demo in ch5_iwls.R in server class files",
    "text": "Demo in ch5_iwls.R in server class files"
  },
  {
    "objectID": "slides/05_glm_ch5.html#acknowledgements",
    "href": "slides/05_glm_ch5.html#acknowledgements",
    "title": "Generalized Linear Models (GLMs)",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\nThese slides are based on content in BMLR: Chapter 4\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\nBMLR: Chapter 5 - Generalized Linear Models: A Unifying Theory\nNelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. Journal of the Royal Statistical Society: Series A (General), 135(3), 370-384.\nGeneralized Linear Models with Examples in R\n\nChapter 5 - Generalized Linear Models: Structure\nChapter 6 - Generalized Linear Models: Estimation\n\n\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html",
    "href": "slides/07_correlated_data_ch7_o.html",
    "title": "Correlated Data",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)\nlibrary(kableExtra)"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#setup",
    "href": "slides/07_correlated_data_ch7_o.html#setup",
    "title": "Correlated Data",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)\nlibrary(kableExtra)"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#learning-goals",
    "href": "slides/07_correlated_data_ch7_o.html#learning-goals",
    "title": "Correlated Data",
    "section": "Learning goals",
    "text": "Learning goals\n\nRecognize a potential for correlation in a data set\nIdentify observational units at varying levels\nUnderstand issues correlated data may cause in modeling\nUnderstand how random effects models can be used to take correlation into account"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#examples-of-correlated-data",
    "href": "slides/07_correlated_data_ch7_o.html#examples-of-correlated-data",
    "title": "Correlated Data",
    "section": "Examples of correlated data",
    "text": "Examples of correlated data\n\nIn an education study, scores for students from a particular teacher are typically more similar than scores of other students with a different teacher\nIn a study measuring depression indices weekly over a month, the four measures for the same patient tend to be more similar than depression indices from other patients\nIn political polling, opinions of members from the same household tend to be more similar than opinions of members from another household\n\n. . .\nCorrelation among outcomes within the same group (teacher, patient, household) is called intraclass correlation"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#multilevel-data",
    "href": "slides/07_correlated_data_ch7_o.html#multilevel-data",
    "title": "Correlated Data",
    "section": "Multilevel data",
    "text": "Multilevel data\n\nWe can think of correlated data as a multilevel structure\n\nPopulation elements are aggregated into groups\nThere are observational units and measurements at each level\n\nFor now we will focus on data with two levels:\n\nLevel one: Most basic level of observation\nLevel two: Groups formed from aggregated level-one observations\n\nExample: political polling\n\nLevel one: individual members of household\nLevel two: household"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#two-types-of-effects",
    "href": "slides/07_correlated_data_ch7_o.html#two-types-of-effects",
    "title": "Correlated Data",
    "section": "Two types of effects",
    "text": "Two types of effects\n\nFixed effects: Effects that are of interest in the study\n\nCan think of these as effects whose interpretations would be included in a write up of the study\n\nRandom effects: Effects we‚Äôre not interested in studying but whose variability we want to understand\n\nCan think of these as effects whose interpretations would not necessarily be included in a write up of the study"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#example",
    "href": "slides/07_correlated_data_ch7_o.html#example",
    "title": "Correlated Data",
    "section": "Example",
    "text": "Example\nResearchers are interested in understanding the effect social media has on opinions about a proposed economic plan. They randomly select 1000 households. They ask each adult in the household how many minutes they spend on social media daily and whether they support the proposed economic plan.\n\ndaily minutes on social media is the fixed effect\nhousehold is the random effect"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#practice",
    "href": "slides/07_correlated_data_ch7_o.html#practice",
    "title": "Correlated Data",
    "section": "Practice",
    "text": "Practice\nResearchers conducted a randomized controlled study where patients were randomly assigned to either an anti-epileptic drug or a placebo. For each patient, the number of seizures at baseline was measured over a 2-week period. For four consecutive visits the number of seizures were determined over the past 2-week period. Patient age and sex along with visit number were recorded.\n. . .\nQuestions\n\nWhat are the level one and level two observational units?\nWhat is the response variable and what is its type (normal, Poisson, etc.)?\nDescribe the within-group variation.\nWhat are the fixed effects? What are the random effects?\n\n\n\nEx. 1 from Section 7.10.1 in BMLR"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#data-teratogen-and-rat-pups",
    "href": "slides/07_correlated_data_ch7_o.html#data-teratogen-and-rat-pups",
    "title": "Correlated Data",
    "section": "Data: Teratogen and rat pups",
    "text": "Data: Teratogen and rat pups\nToday‚Äôs data are simulated results of an experiment with 24 dams (mother rats) randomly divided into four groups that received different doses of teratogen, a substance that could potentially cause harm to developing fetuses. The four groups are\n\nHigh dose (3 mg)\nMedium dose (2 mg)\nLow dose (1 mg)\nNo dose (Control)\n\n. . .\nEach dam produced 10 rat pups and the presence of a deformity was noted.\n. . .\nGoal: Understand the association between teratogen exposure and the probability a pup is born with a deformity."
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#scenario-1-no-dose-effect-1",
    "href": "slides/07_correlated_data_ch7_o.html#scenario-1-no-dose-effect-1",
    "title": "Correlated Data",
    "section": "Scenario 1: No dose effect",
    "text": "Scenario 1: No dose effect\nAssume dose has no effect on, \\(p\\), the probability of a pup born with a deformity.\n\nScenario 1a.: \\(p = 0.5\\) for each dam\nScenario 1b.: \\(p \\sim Beta(0.5, 0.5)\\) (expected value = 0.5)\n\n. . ."
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#scenario-1-no-dose-effect-2",
    "href": "slides/07_correlated_data_ch7_o.html#scenario-1-no-dose-effect-2",
    "title": "Correlated Data",
    "section": "Scenario 1: No dose effect",
    "text": "Scenario 1: No dose effect\n\nOuputCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntheoretical_pi &lt;- tibble(x = 1:250000,\n                         p1 = rbeta(x, 0.5, 0.5))\n\ntibble(x = 1:24, pi_1b) |&gt;\n  ggplot() +\n    geom_histogram(bins = 5, aes(x = pi_1b, y = ..density..),\n                   color = \"black\", fill = \"blue\", alpha = 0.2) + \n    coord_cartesian(xlim = c(0,1)) +\n    geom_density(data = theoretical_pi, aes(x = p1), \n                  linetype = 3, color = \"blue\", lwd = 2) +\n    geom_vline(xintercept = 0.5, color = \"red\", lwd = 2) +\n    labs(title = \"Probability of deformity\", \n         subtitle = \"Red = Scenario 1a, Blue dashed line  = Scenario 1b\", \n         x = \"Probability of Deformity\")\n\n\n\n\n\n\nFrom Figure 7.1 in BMLR"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#questions",
    "href": "slides/07_correlated_data_ch7_o.html#questions",
    "title": "Correlated Data",
    "section": "Questions",
    "text": "Questions\n\nWould you expect the number of pups with a deformity for dams in Scenario 1a to follow a distribution similar to the binomial distribution with \\(n=10\\) and \\(p=0.5\\)? Why or why not?\nWould you expect the number of pups with a deformity for dams in Scenario 1b to follow a distribution similar to the binomial distribution with \\(n=10\\) and \\(p=0.5\\)? Why or why not?\nWhich scenario do you think is more realistic - Scenario 1a or 1b?"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#investigating",
    "href": "slides/07_correlated_data_ch7_o.html#investigating",
    "title": "Correlated Data",
    "section": "Investigating",
    "text": "Investigating\n\nOutputCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean_1a\nsd_1a\nmean_1b\nsd_1b\n\n\n\n\n5.166667\n1.493949\n5.666667\n4.103727\n\n\n\n\n\n\n\n\n\n\npi_1a &lt;- rep(0.5, 24)\ncount_1a &lt;- rbinom(24, 10, pi_1a)\n\npi_1b &lt;- rbeta(24,.5,.5)  \ncount_1b &lt;- rbinom(24, 10, pi_1b)  \n\n\nscenario_1 &lt;- \n  tibble(pi_1a, count_1a, pi_1b, count_1b) |&gt;\n  mutate(phat_1a = count_1a / 10, \n         phat_1b = count_1b / 10)\n\nhist_1a &lt;- ggplot(data = scenario_1, aes(x = count_1a)) + \n  geom_histogram(bins = 5, color = \"black\", fill = \"steelblue\") +\n  coord_cartesian(xlim = c(0, 10)) +\n  labs(title = \"Scenario 1a: Binomial, p = 0.5\",\n       x = \"Count of deformed pups per dam\")\n\nhist_1b &lt;- ggplot(data = scenario_1, aes(x = count_1b)) + \n  geom_histogram(bins = 5, color = \"black\", fill = \"steelblue\") +\n  coord_cartesian(xlim = c(0, 10)) +\n  labs(title = \"Scenario 1b: Binomial, p ~ Beta(0.5, 0.5)\",\n       x = \"Count of deformed pups per dam\")\n\nhist_1a / hist_1b\n\n\nscenario_1 |&gt; \n  summarise(mean_1a = mean(count_1a), sd_1a = sd(count_1a),\n            mean_1b = mean(count_1b), sd_1b = sd(count_1b) ) |&gt;\n  kable()\n\n\n\n\n. . .\nLet‚Äôs take a look at a binomial and quasibinomial model for Scenarios 1a and 1b."
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#scenario-2-dose-effect-1",
    "href": "slides/07_correlated_data_ch7_o.html#scenario-2-dose-effect-1",
    "title": "Correlated Data",
    "section": "Scenario 2: Dose effect",
    "text": "Scenario 2: Dose effect\nNow we will consider the effect of the dose of teratogen on the probability of a pup born with a deformity. The 24 pups have been randomly divided into four groups:\n\nHigh dose (dose = 3)\nMedium dose (dose = 2)\nLow dose (dose = 1)\nNo dose (dose = 0)\n\n. . .\nWe will assume the true relationship between \\(p\\) and dose is the following:\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2 + 1.33 ~ dose\\]"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#scenario-2",
    "href": "slides/07_correlated_data_ch7_o.html#scenario-2",
    "title": "Correlated Data",
    "section": "Scenario 2",
    "text": "Scenario 2\nScenario 2a.\n\\[p = \\frac{e^{-2 + 1.33 ~ dose}}{1 + e^{-2 + 1.33 ~ dose}}\\]\n. . .\nScenario 2b.:\n\\[p \\sim Beta\\Big(\\frac{2p}{(1-p)}, 2\\Big)\\]\nOn average, dams who receive dose \\(x\\) have the same probability of deformed pup as dams with dose \\(x\\) under Scenario 2a."
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#distributions-under-scenario-2",
    "href": "slides/07_correlated_data_ch7_o.html#distributions-under-scenario-2",
    "title": "Correlated Data",
    "section": "Distributions under Scenario 2",
    "text": "Distributions under Scenario 2\n\n\n\n\n\n\n\n\n\n\n\nReplicated from Figure 7.3 in BMLR"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#summary-stats-under-scen.2",
    "href": "slides/07_correlated_data_ch7_o.html#summary-stats-under-scen.2",
    "title": "Correlated Data",
    "section": "Summary stats under Scen.2",
    "text": "Summary stats under Scen.2\n\nOutputCode\n\n\n\n\n\n\n\nmean_2a\nsd_2a\nmean_2b\nsd_2b\n\n\n\n\n4.791667\n3.202976\n4.666667\n3.583375\n\n\n\n\n\n\n\n\n\nSummary statistics of Scenario 2 by dose.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScenario 2a\n\n\nScenario 2b\n\n\n\nDosage\nMean p\nSD p\nMean Count\nSD Count\nMean p\nSD p\nMean Count\nSD Count\n\n\n\n\n0\n0.119\n0\n1.333\n1.366\n0.061\n0.069\n0.500\n0.837\n\n\n1\n0.339\n0\n3.167\n1.835\n0.239\n0.208\n3.500\n2.881\n\n\n2\n0.661\n0\n5.833\n1.472\n0.615\n0.195\n5.833\n1.941\n\n\n3\n0.881\n0\n8.833\n1.169\n0.872\n0.079\n8.833\n1.169\n\n\n\n\n\n\n\n\n\n\n\nscenario_2 |&gt; \n  summarise(mean_2a = mean(count_2a), sd_2a = sd(count_2a),\n            mean_2b = mean(count_2b), sd_2b = sd(count_2b) )\n\n\nscenario2Tab &lt;- scenario_2 |&gt;\n                  group_by(dose) |&gt;\n                  summarise(mean_2a_pi = round(mean(pi_2a),3), sd_2a_pi = round(sd(pi_2a),3),\n                            mean_2a_cnt = round(mean(count_2a),3), sd_2a_cnt = round(sd(count_2a),3),\n                            mean_2b_pi = round(mean(pi_2b),3), sd_2b_pi = round(sd(pi_2b),3),\n                            mean_2b_cnt = round(mean(count_2b),3), sd_2b_cnt = round(sd(count_2b),3)) |&gt;\n                  as.data.frame()\ncolnames(scenario2Tab) &lt;- c(\"Dosage\",\"Mean p\", \"SD p\",\n    \"Mean Count\", \"SD Count\", \"Mean p\", \"SD p\",\n    \"Mean Count\", \"SD Count\")\nkable(scenario2Tab, booktabs = T, \n    caption=\"Summary statistics of Scenario 2 by dose.\") |&gt;\n    add_header_above(c(\" \" = 1, \"Scenario 2a\" = 4, \n                       \"Scenario 2b\" = 4)) |&gt;\n    kable_styling(latex_options = \"scale_down\") |&gt;\n    column_spec(c(4:5,8:9), width = \"1cm\")\n\n\n\n\n\n\nFrom Table 7.2 in BMLR"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#questions-1",
    "href": "slides/07_correlated_data_ch7_o.html#questions-1",
    "title": "Correlated Data",
    "section": "Questions",
    "text": "Questions\n\nIn Scenario 2a, dams produced 4.79 deformed pups on average, with standard deviation 3.20. Scenario 2b saw an average of 4.67 with standard deviation 3.58. Why are comparisons by dose more meaningful than these overall comparisons?\nWe will use binomial and quasibinomial regression to model the relationship between dose and probability of pup born with a deformity. What can you say about the center and the width of the confidence intervals under Scenarios 2a and 2b?\n\n\n\nWhich will be similar and why?\n\nWhich will be different and how?"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#scenario-2-estimated-odds-ratio",
    "href": "slides/07_correlated_data_ch7_o.html#scenario-2-estimated-odds-ratio",
    "title": "Correlated Data",
    "section": "Scenario 2: Estimated odds ratio",
    "text": "Scenario 2: Estimated odds ratio\nThe estimated effect of dose and the 95% CI from the binomial and quasibinomial models are below:\n. . .\nScenario 2a\n\n\n\n\nOdds Ratio\n95% CI\n\n\n\n\nBinomial\n3.536\n(2.604, 4.958)\n\n\nQuasibinomial\n3.536\n(2.512, 5.186)\n\n\n\nScenario 2b\n\n\n\n\nOdds Ratio\n95% CI\n\n\n\n\nBinomial\n4.311\n(3.086, 6.271)\n\n\nQuasibinomial\n4.311\n(2.735, 7.352)"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#questions-2",
    "href": "slides/07_correlated_data_ch7_o.html#questions-2",
    "title": "Correlated Data",
    "section": "Questions",
    "text": "Questions\n\nDescribe how the quasibinomial analysis of Scenario 2b differs from the binomial analysis of the same simulated data. Do confidence intervals contain the true model parameters? Is this what you expected? Why?\nWhy are differences between quasibinomial and binomial models of Scenario 2a less noticeable than the differences in Scenario 2b?"
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#summary",
    "href": "slides/07_correlated_data_ch7_o.html#summary",
    "title": "Correlated Data",
    "section": "Summary",
    "text": "Summary\n\nThe structure of the data set may imply correlation between observations.\nCorrelated observations provide less information than independent observations; we need to account for this reduction in information.\nFailing to account for this reduction could result in underestimating standard error, thus resulting in overstating significance and the precision of the estimates.\nWe showed how we can account for this by incorporating the dispersion parameter or a random effect."
  },
  {
    "objectID": "slides/07_correlated_data_ch7_o.html#acknowledgements",
    "href": "slides/07_correlated_data_ch7_o.html#acknowledgements",
    "title": "Correlated Data",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in\n\nBMLR: Chapter 7 - Logistic Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#setup",
    "href": "slides/07_correlated_data_ch7.html#setup",
    "title": "Correlated Data",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)\nlibrary(kableExtra)"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#learning-goals",
    "href": "slides/07_correlated_data_ch7.html#learning-goals",
    "title": "Correlated Data",
    "section": "Learning goals",
    "text": "Learning goals\n\nRecognize a potential for correlation in a data set\nIdentify observational units at varying levels\nUnderstand issues correlated data may cause in modeling\nUnderstand how random effects models can be used to take correlation into account"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#examples-of-correlated-data",
    "href": "slides/07_correlated_data_ch7.html#examples-of-correlated-data",
    "title": "Correlated Data",
    "section": "Examples of correlated data",
    "text": "Examples of correlated data\n\nIn an education study, scores for students from a particular teacher are typically more similar than scores of other students with a different teacher\nIn a study measuring depression indices weekly over a month, the four measures for the same patient tend to be more similar than depression indices from other patients\nIn political polling, opinions of members from the same household tend to be more similar than opinions of members from another household\n\n\nCorrelation among outcomes within the same group (teacher, patient, household) is called intraclass correlation"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#multilevel-data",
    "href": "slides/07_correlated_data_ch7.html#multilevel-data",
    "title": "Correlated Data",
    "section": "Multilevel data",
    "text": "Multilevel data\n\nWe can think of correlated data as a multilevel structure\n\nPopulation elements are aggregated into groups\nThere are observational units and measurements at each level\n\nFor now we will focus on data with two levels:\n\nLevel one: Most basic level of observation\nLevel two: Groups formed from aggregated level-one observations\n\nExample: political polling\n\nLevel one: individual members of household\nLevel two: household"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#two-types-of-effects",
    "href": "slides/07_correlated_data_ch7.html#two-types-of-effects",
    "title": "Correlated Data",
    "section": "Two types of effects",
    "text": "Two types of effects\n\nFixed effects: Effects that are of interest in the study\n\nCan think of these as effects whose interpretations would be included in a write up of the study\n\nRandom effects: Effects we‚Äôre not interested in studying but whose variability we want to understand\n\nCan think of these as effects whose interpretations would not necessarily be included in a write up of the study"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#example",
    "href": "slides/07_correlated_data_ch7.html#example",
    "title": "Correlated Data",
    "section": "Example",
    "text": "Example\nResearchers are interested in understanding the effect social media has on opinions about a proposed economic plan. They randomly select 1000 households. They ask each adult in the household how many minutes they spend on social media daily and whether they support the proposed economic plan.\n\ndaily minutes on social media is the fixed effect\nhousehold is the random effect"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#practice",
    "href": "slides/07_correlated_data_ch7.html#practice",
    "title": "Correlated Data",
    "section": "Practice",
    "text": "Practice\nResearchers conducted a randomized controlled study where patients were randomly assigned to either an anti-epileptic drug or a placebo. For each patient, the number of seizures at baseline was measured over a 2-week period. For four consecutive visits the number of seizures were determined over the past 2-week period. Patient age and sex along with visit number were recorded.\n\nQuestions\n\nWhat are the level one and level two observational units?\nWhat is the response variable and what is its type (normal, Poisson, etc.)?\nDescribe the within-group variation.\nWhat are the fixed effects? What are the random effects?\n\n\n\n\nEx. 1 from Section 7.10.1 in BMLR"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#data-teratogen-and-rat-pups",
    "href": "slides/07_correlated_data_ch7.html#data-teratogen-and-rat-pups",
    "title": "Correlated Data",
    "section": "Data: Teratogen and rat pups",
    "text": "Data: Teratogen and rat pups\nToday‚Äôs data are simulated results of an experiment with 24 dams (mother rats) randomly divided into four groups that received different doses of teratogen, a substance that could potentially cause harm to developing fetuses. The four groups are\n\nHigh dose (3 mg)\nMedium dose (2 mg)\nLow dose (1 mg)\nNo dose (Control)\n\n\nEach dam produced 10 rat pups and the presence of a deformity was noted.\n\n\nGoal: Understand the association between teratogen exposure and the probability a pup is born with a deformity."
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#scenario-1-no-dose-effect-1",
    "href": "slides/07_correlated_data_ch7.html#scenario-1-no-dose-effect-1",
    "title": "Correlated Data",
    "section": "Scenario 1: No dose effect",
    "text": "Scenario 1: No dose effect\nAssume dose has no effect on, \\(p\\), the probability of a pup born with a deformity.\n\nScenario 1a.: \\(p = 0.5\\) for each dam\nScenario 1b.: \\(p \\sim Beta(0.5, 0.5)\\) (expected value = 0.5)"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#scenario-1-no-dose-effect-2",
    "href": "slides/07_correlated_data_ch7.html#scenario-1-no-dose-effect-2",
    "title": "Correlated Data",
    "section": "Scenario 1: No dose effect",
    "text": "Scenario 1: No dose effect\n\nOuputCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntheoretical_pi &lt;- tibble(x = 1:250000,\n                         p1 = rbeta(x, 0.5, 0.5))\n\ntibble(x = 1:24, pi_1b) |&gt;\n  ggplot() +\n    geom_histogram(bins = 5, aes(x = pi_1b, y = ..density..),\n                   color = \"black\", fill = \"blue\", alpha = 0.2) + \n    coord_cartesian(xlim = c(0,1)) +\n    geom_density(data = theoretical_pi, aes(x = p1), \n                  linetype = 3, color = \"blue\", lwd = 2) +\n    geom_vline(xintercept = 0.5, color = \"red\", lwd = 2) +\n    labs(title = \"Probability of deformity\", \n         subtitle = \"Red = Scenario 1a, Blue dashed line  = Scenario 1b\", \n         x = \"Probability of Deformity\")\n\n\n\n\n\n\nFrom Figure 7.1 in BMLR"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#questions",
    "href": "slides/07_correlated_data_ch7.html#questions",
    "title": "Correlated Data",
    "section": "Questions",
    "text": "Questions\n\nWould you expect the number of pups with a deformity for dams in Scenario 1a to follow a distribution similar to the binomial distribution with \\(n=10\\) and \\(p=0.5\\)? Why or why not?\nWould you expect the number of pups with a deformity for dams in Scenario 1b to follow a distribution similar to the binomial distribution with \\(n=10\\) and \\(p=0.5\\)? Why or why not?\nWhich scenario do you think is more realistic - Scenario 1a or 1b?"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#investigating",
    "href": "slides/07_correlated_data_ch7.html#investigating",
    "title": "Correlated Data",
    "section": "Investigating",
    "text": "Investigating\n\nOutputCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean_1a\nsd_1a\nmean_1b\nsd_1b\n\n\n\n\n5.166667\n1.493949\n5.666667\n4.103727\n\n\n\n\n\n\n\n\n\n\npi_1a &lt;- rep(0.5, 24)\ncount_1a &lt;- rbinom(24, 10, pi_1a)\n\npi_1b &lt;- rbeta(24,.5,.5)  \ncount_1b &lt;- rbinom(24, 10, pi_1b)  \n\n\nscenario_1 &lt;- \n  tibble(pi_1a, count_1a, pi_1b, count_1b) |&gt;\n  mutate(phat_1a = count_1a / 10, \n         phat_1b = count_1b / 10)\n\nhist_1a &lt;- ggplot(data = scenario_1, aes(x = count_1a)) + \n  geom_histogram(bins = 5, color = \"black\", fill = \"steelblue\") +\n  coord_cartesian(xlim = c(0, 10)) +\n  labs(title = \"Scenario 1a: Binomial, p = 0.5\",\n       x = \"Count of deformed pups per dam\")\n\nhist_1b &lt;- ggplot(data = scenario_1, aes(x = count_1b)) + \n  geom_histogram(bins = 5, color = \"black\", fill = \"steelblue\") +\n  coord_cartesian(xlim = c(0, 10)) +\n  labs(title = \"Scenario 1b: Binomial, p ~ Beta(0.5, 0.5)\",\n       x = \"Count of deformed pups per dam\")\n\nhist_1a / hist_1b\n\n\nscenario_1 |&gt; \n  summarise(mean_1a = mean(count_1a), sd_1a = sd(count_1a),\n            mean_1b = mean(count_1b), sd_1b = sd(count_1b) ) |&gt;\n  kable()\n\n\n\n\n\nLet‚Äôs take a look at a binomial and quasibinomial model for Scenarios 1a and 1b."
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#scenario-2-dose-effect-1",
    "href": "slides/07_correlated_data_ch7.html#scenario-2-dose-effect-1",
    "title": "Correlated Data",
    "section": "Scenario 2: Dose effect",
    "text": "Scenario 2: Dose effect\nNow we will consider the effect of the dose of teratogen on the probability of a pup born with a deformity. The 24 pups have been randomly divided into four groups:\n\nHigh dose (dose = 3)\nMedium dose (dose = 2)\nLow dose (dose = 1)\nNo dose (dose = 0)\n\n\nWe will assume the true relationship between \\(p\\) and dose is the following:\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2 + 1.33 ~ dose\\]"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#scenario-2",
    "href": "slides/07_correlated_data_ch7.html#scenario-2",
    "title": "Correlated Data",
    "section": "Scenario 2",
    "text": "Scenario 2\nScenario 2a.\n\\[p = \\frac{e^{-2 + 1.33 ~ dose}}{1 + e^{-2 + 1.33 ~ dose}}\\]\n\nScenario 2b.:\n\\[p \\sim Beta\\Big(\\frac{2p}{(1-p)}, 2\\Big)\\]\nOn average, dams who receive dose \\(x\\) have the same probability of deformed pup as dams with dose \\(x\\) under Scenario 2a."
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#distributions-under-scenario-2",
    "href": "slides/07_correlated_data_ch7.html#distributions-under-scenario-2",
    "title": "Correlated Data",
    "section": "Distributions under Scenario 2",
    "text": "Distributions under Scenario 2\n\n\n\n\n\n\n\n\n\n\n\nReplicated from Figure 7.3 in BMLR"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#summary-stats-under-scen.2",
    "href": "slides/07_correlated_data_ch7.html#summary-stats-under-scen.2",
    "title": "Correlated Data",
    "section": "Summary stats under Scen.2",
    "text": "Summary stats under Scen.2\n\nOutputCode\n\n\n\n\n\n\n\nmean_2a\nsd_2a\nmean_2b\nsd_2b\n\n\n\n\n4.791667\n3.202976\n4.666667\n3.583375\n\n\n\n\n\n\n\n\n\nSummary statistics of Scenario 2 by dose.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScenario 2a\n\n\nScenario 2b\n\n\n\nDosage\nMean p\nSD p\nMean Count\nSD Count\nMean p\nSD p\nMean Count\nSD Count\n\n\n\n\n0\n0.119\n0\n1.333\n1.366\n0.061\n0.069\n0.500\n0.837\n\n\n1\n0.339\n0\n3.167\n1.835\n0.239\n0.208\n3.500\n2.881\n\n\n2\n0.661\n0\n5.833\n1.472\n0.615\n0.195\n5.833\n1.941\n\n\n3\n0.881\n0\n8.833\n1.169\n0.872\n0.079\n8.833\n1.169\n\n\n\n\n\n\n\n\n\n\n\nscenario_2 |&gt; \n  summarise(mean_2a = mean(count_2a), sd_2a = sd(count_2a),\n            mean_2b = mean(count_2b), sd_2b = sd(count_2b) )\n\n\nscenario2Tab &lt;- scenario_2 |&gt;\n                  group_by(dose) |&gt;\n                  summarise(mean_2a_pi = round(mean(pi_2a),3), sd_2a_pi = round(sd(pi_2a),3),\n                            mean_2a_cnt = round(mean(count_2a),3), sd_2a_cnt = round(sd(count_2a),3),\n                            mean_2b_pi = round(mean(pi_2b),3), sd_2b_pi = round(sd(pi_2b),3),\n                            mean_2b_cnt = round(mean(count_2b),3), sd_2b_cnt = round(sd(count_2b),3)) |&gt;\n                  as.data.frame()\ncolnames(scenario2Tab) &lt;- c(\"Dosage\",\"Mean p\", \"SD p\",\n    \"Mean Count\", \"SD Count\", \"Mean p\", \"SD p\",\n    \"Mean Count\", \"SD Count\")\nkable(scenario2Tab, booktabs = T, \n    caption=\"Summary statistics of Scenario 2 by dose.\") |&gt;\n    add_header_above(c(\" \" = 1, \"Scenario 2a\" = 4, \n                       \"Scenario 2b\" = 4)) |&gt;\n    kable_styling(latex_options = \"scale_down\") |&gt;\n    column_spec(c(4:5,8:9), width = \"1cm\")\n\n\n\n\n\n\nFrom Table 7.2 in BMLR"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#questions-1",
    "href": "slides/07_correlated_data_ch7.html#questions-1",
    "title": "Correlated Data",
    "section": "Questions",
    "text": "Questions\n\nIn Scenario 2a, dams produced 4.79 deformed pups on average, with standard deviation 3.20. Scenario 2b saw an average of 4.67 with standard deviation 3.58. Why are comparisons by dose more meaningful than these overall comparisons?\nWe will use binomial and quasibinomial regression to model the relationship between dose and probability of pup born with a deformity. What can you say about the center and the width of the confidence intervals under Scenarios 2a and 2b?\n\n\n\nWhich will be similar and why?\n\nWhich will be different and how?"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#scenario-2-estimated-odds-ratio",
    "href": "slides/07_correlated_data_ch7.html#scenario-2-estimated-odds-ratio",
    "title": "Correlated Data",
    "section": "Scenario 2: Estimated odds ratio",
    "text": "Scenario 2: Estimated odds ratio\nThe estimated effect of dose and the 95% CI from the binomial and quasibinomial models are below:\n\nScenario 2a\n\n\n\n\nOdds Ratio\n95% CI\n\n\n\n\nBinomial\n3.536\n(2.604, 4.958)\n\n\nQuasibinomial\n3.536\n(2.512, 5.186)\n\n\n\nScenario 2b\n\n\n\n\nOdds Ratio\n95% CI\n\n\n\n\nBinomial\n4.311\n(3.086, 6.271)\n\n\nQuasibinomial\n4.311\n(2.735, 7.352)"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#questions-2",
    "href": "slides/07_correlated_data_ch7.html#questions-2",
    "title": "Correlated Data",
    "section": "Questions",
    "text": "Questions\n\nDescribe how the quasibinomial analysis of Scenario 2b differs from the binomial analysis of the same simulated data. Do confidence intervals contain the true model parameters? Is this what you expected? Why?\nWhy are differences between quasibinomial and binomial models of Scenario 2a less noticeable than the differences in Scenario 2b?"
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#summary",
    "href": "slides/07_correlated_data_ch7.html#summary",
    "title": "Correlated Data",
    "section": "Summary",
    "text": "Summary\n\nThe structure of the data set may imply correlation between observations.\nCorrelated observations provide less information than independent observations; we need to account for this reduction in information.\nFailing to account for this reduction could result in underestimating standard error, thus resulting in overstating significance and the precision of the estimates.\nWe showed how we can account for this by incorporating the dispersion parameter or a random effect."
  },
  {
    "objectID": "slides/07_correlated_data_ch7.html#acknowledgements",
    "href": "slides/07_correlated_data_ch7.html#acknowledgements",
    "title": "Correlated Data",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in\n\nBMLR: Chapter 7 - Logistic Regression\nInitial versions of the slides are by Dr.¬†Maria Tackett, Duke University\n\n\n\n\n\nüîó https://stats-tgeorge.github.io/STA363_AdvReg/"
  }
]